{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from datetime import datetime, timedelta\r\n",
    "import pandas as pd\r\n",
    "import pandas_bokeh\r\n",
    "pandas_bokeh.output_notebook()\r\n",
    "%matplotlib inline\r\n",
    "%config IPCompleter.greedy = True\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import cbpro\r\n",
    "import urllib.request\r\n",
    "import ssl\r\n",
    "import json\r\n",
    "import time\r\n",
    "import os\r\n",
    "from pathlib import Path\r\n",
    "import seaborn as sns\r\n",
    "\r\n",
    "sns.set(\r\n",
    "    font=\"Franklin Gothic Book\",\r\n",
    "    rc={\r\n",
    "        \"axes.axisbelow\": False,\r\n",
    "        \"axes.edgecolor\": \"lightgrey\",\r\n",
    "        \"axes.facecolor\": \"None\",\r\n",
    "        \"axes.grid\": False,\r\n",
    "        \"axes.labelcolor\": \"dimgrey\",\r\n",
    "        \"axes.spines.right\": False,\r\n",
    "        \"axes.spines.top\": False,\r\n",
    "        \"figure.facecolor\": \"white\",\r\n",
    "        \"lines.solid_capstyle\": \"round\",\r\n",
    "        \"patch.edgecolor\": \"w\",\r\n",
    "        \"patch.force_edgecolor\": True,\r\n",
    "        \"text.color\": \"dimgrey\",\r\n",
    "        \"xtick.bottom\": False,\r\n",
    "        \"xtick.color\": \"dimgrey\",\r\n",
    "        \"xtick.direction\": \"out\",\r\n",
    "        \"xtick.top\": False,\r\n",
    "        \"ytick.color\": \"dimgrey\",\r\n",
    "        \"ytick.direction\": \"out\",\r\n",
    "        \"ytick.left\": False,\r\n",
    "        \"ytick.right\": False,\r\n",
    "    },\r\n",
    ")\r\n",
    "\r\n",
    "sns.set_context(\r\n",
    "    \"notebook\", rc={\"font.size\": 16, \"axes.titlesize\": 20, \"axes.labelsize\": 18}\r\n",
    ")\r\n",
    "\r\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"\r\n",
    "os.environ[\"TF_GPU_THREAD_MODE\"] = \"gpu_private\"\r\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\r\n",
    "import tensorflow as tf\r\n",
    "\r\n",
    "tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")\r\n",
    "policy = tf.keras.mixed_precision.Policy(\"mixed_float16\")\r\n",
    "tf.keras.mixed_precision.experimental.set_policy(policy)\r\n",
    "np.set_printoptions(suppress=True)\r\n",
    "\r\n",
    "public_client = cbpro.PublicClient()\r\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1003\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.bokehjs_load.v0+json": "",
      "application/javascript": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  const JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n    // Clean up Bokeh references\n    if (id != null && id in Bokeh.index) {\n      Bokeh.index[id].model.document.clear();\n      delete Bokeh.index[id];\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim();\n            if (id in Bokeh.index) {\n              Bokeh.index[id].model.document.clear();\n              delete Bokeh.index[id];\n            }\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"1003\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.0.min.js\"];\n  const css_urls = [];\n  \n\n  const inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"1003\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "class MinerMeta(type):\r\n",
    "    def compile_historic(self, num_days=100, write_csv=False, read_csv=False):\r\n",
    "        file = Path.cwd() / f\"{self.coin}_histdata.csv\"\r\n",
    "        if read_csv is True:\r\n",
    "            df = pd.read_csv(file, index_col=\"time\", infer_datetime_format=True)\r\n",
    "            return df\r\n",
    "        else:\r\n",
    "            finish = datetime.now()\r\n",
    "            start = finish - timedelta(num_days)\r\n",
    "            delta = timedelta(hours=300)\r\n",
    "            df = pd.DataFrame()\r\n",
    "\r\n",
    "            while finish > start:\r\n",
    "                historic = public_client.get_product_historic_rates(\r\n",
    "                    f\"{self.coin}-USD\",\r\n",
    "                    granularity=3600,\r\n",
    "                    start=start,\r\n",
    "                    end=start + delta,\r\n",
    "                )\r\n",
    "                start += delta\r\n",
    "                df = df.append(historic, ignore_index=True, verify_integrity=True)\r\n",
    "            df.columns = [\"time\", \"low\", \"high\", \"open\", \"close\", \"volume\"]\r\n",
    "            date_time = pd.to_datetime(df[\"time\"], unit=\"s\")\r\n",
    "            # df.set_index(\"time\", inplace=True)\r\n",
    "            df.sort_values(by=\"time\", ascending=False, inplace=True)\r\n",
    "\r\n",
    "            timestamp_s = date_time.map(pd.Timestamp.timestamp)\r\n",
    "            day = 24 * 60 * 60\r\n",
    "            year = (365.2425) * day\r\n",
    "            df[\"Day sin\"] = np.sin(timestamp_s * (2 * np.pi / day))\r\n",
    "            df[\"Day cos\"] = np.cos(timestamp_s * (2 * np.pi / day))\r\n",
    "            df[\"Year sin\"] = np.sin(timestamp_s * (2 * np.pi / year))\r\n",
    "            df[\"Year cos\"] = np.cos(timestamp_s * (2 * np.pi / year))\r\n",
    "            df.reset_index(drop=True, inplace=True)\r\n",
    "            df[\"time\"] = pd.to_datetime(df[\"time\"], unit=\"s\")\r\n",
    "            df.set_index(\"time\", inplace=True, verify_integrity=False)\r\n",
    "            df.sort_index(ascending=False)\r\n",
    "            if write_csv is True:\r\n",
    "                df.to_csv(file, index=True)\r\n",
    "\r\n",
    "            return df\r\n",
    "\r\n",
    "    def get_day_stats(self):\r\n",
    "        result = getattr(self, \"day_stats\", None)\r\n",
    "        if result is None:\r\n",
    "            ticker = public_client.get_product_24hr_stats(f\"{self.coin}-USD\")\r\n",
    "            df = pd.DataFrame.from_dict(ticker, orient=\"index\")\r\n",
    "            self.day_stats = df\r\n",
    "        return df\r\n",
    "\r\n",
    "    def year_day_fft(self, col):\r\n",
    "        df = self.compile_historic()\r\n",
    "        today = datetime.today()\r\n",
    "        ylim = int(df[col].max())\r\n",
    "        plt.figure(figsize=(15, 10))\r\n",
    "\r\n",
    "\r\n",
    "        fft = tf.signal.rfft(df[col])\r\n",
    "        f_per_dataset = np.arange(0, len(fft))\r\n",
    "\r\n",
    "        n_samples_h = 1\r\n",
    "        hours_per_year = 24 * 365.2524\r\n",
    "        hours_per_week = 24 * 7\r\n",
    "        years_per_dataset = n_samples_h / (hours_per_year)\r\n",
    "        hours_per_dataset = n_samples_h / (hours_per_week)\r\n",
    "\r\n",
    "        f_per_year = f_per_dataset / years_per_dataset\r\n",
    "        f_per_week = f_per_dataset / hours_per_dataset\r\n",
    "        plt.step(f_per_week, np.abs(fft))\r\n",
    "        plt.xscale(\"log\")\r\n",
    "        # plt.ylim(1000, ylim)\r\n",
    "        # plt.xlim([0.1, max(plt.xlim())])\r\n",
    "        plt.xticks([1, 7], labels=[\"1/Week\", \"1/day\"])\r\n",
    "        plt.xlabel(\"Frequency (log scale)\")\r\n",
    "\r\n",
    "        return plt.show()\r\n",
    "\r\n",
    "    def ttsplit_norm(self, df, split_time=0.7, feature_plot=False):\r\n",
    "        # train_df Test Split\r\n",
    "        n = len(df)\r\n",
    "        train_df = df[0 : int(n * 0.7)]\r\n",
    "        val_df = df[int(n * 0.7) : int(n * 0.9)]\r\n",
    "        test_df = df[int(n * 0.9) :]\r\n",
    "        # Normalize the Data\r\n",
    "        train_df_mean = train_df.mean()\r\n",
    "        train_df_std = train_df.std()\r\n",
    "\r\n",
    "        train_df = (train_df - train_df_mean) / train_df_std\r\n",
    "        val_df = (val_df - train_df_mean) / train_df_std\r\n",
    "        test_df = (test_df - train_df_mean) / train_df_std\r\n",
    "\r\n",
    "        # Create Feature Plot if wanted\r\n",
    "        if feature_plot is True:\r\n",
    "            df_std = (df - train_df_mean) / train_df_std\r\n",
    "            df_std = df_std.melt(var_name=\"Column\", value_name=\"Normalized\")\r\n",
    "            plt.figure(figsize=(12, 6))\r\n",
    "            ax = sns.violinplot(x=\"Column\", y=\"Normalized\", data=df_std)\r\n",
    "            ax.set_xticklabels(df.keys(), rotation=90)\r\n",
    "            ax.set_title(\"train_dfing Data Feature Dist with whole DF Mean\")\r\n",
    "\r\n",
    "            return train_df, val_df, test_df\r\n",
    "\r\n",
    "        return train_df, val_df, test_df\r\n",
    "\r\n",
    "    def __call__(self, *args, **kwargs):\r\n",
    "\r\n",
    "        cls = type.__call__(self, *args)\r\n",
    "\r\n",
    "        # setattr(cls, \"compile_historic\", self.compile_historic)\r\n",
    "        # setattr(cls, \"year_day_fft\", self.year_day_fft)\r\n",
    "        # setattr(cls, \"ttsplit_norm\", self.ttsplit_norm)\r\n",
    "        # setattr(cls, \"get_day_stats\", self.get_day_stats)\r\n",
    "        setattr(cls, \"day_stats\", self.get_day_stats())\r\n",
    "\r\n",
    "        # for key, value in historic.items():\r\n",
    "        #     setattr(cls, \"hist_\" + key, value)\r\n",
    "        # for key, value in ticker.items():\r\n",
    "        #     setattr(cls, \"tick_\" + key, value)\r\n",
    "\r\n",
    "        return cls\r\n",
    "\r\n",
    "\r\n",
    "class eth(metaclass=MinerMeta):\r\n",
    "    coin = \"eth\"\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Lunar Crush API Key\r\n",
    "#https://lunarcrush.com/developers/docs#assets\r\n",
    "api_key = r\"ru1zaf0ssaa29394mb4ahp\"\r\n",
    "\r\n",
    "# coins = [\"BTC\", \"ETH\", \"LTC\"]\r\n",
    "coins = \"ETH\"\r\n",
    "\r\n",
    "# coins = \",\".join(coins)\r\n",
    "\r\n",
    "map = [\r\n",
    "    {\"name\": \"\"},\r\n",
    "    {\"symbol\": \"\"},\r\n",
    "    {\"price\": \" Price: \"},\r\n",
    "    {\"percent_change_24h\": \" - 24 Hour Percent Change: \"},\r\n",
    "    {\"average_sentiment\": \" Average Sentiment: \"},\r\n",
    "]\r\n",
    "\r\n",
    "\r\n",
    "def final_render(asset_coin, value, key, asset):\r\n",
    "    if key == \"symbol\":\r\n",
    "        asset_coin += \" (\" + asset[key] + \")\"\r\n",
    "    elif key == \"percent_change_24h\":\r\n",
    "        asset_coin += value + str(asset[key]) + \"%\"\r\n",
    "    else:\r\n",
    "        asset_coin += value + str(asset[key])\r\n",
    "    return asset_coin\r\n",
    "\r\n",
    "\r\n",
    "def lc_data():\r\n",
    "\r\n",
    "    assets_url = (\r\n",
    "        \"https://api.lunarcrush.com/v2?data=assets&key=\" + api_key + \"&symbol=\" + coins\r\n",
    "    )\r\n",
    "    assets = json.loads(urllib.request.urlopen(assets_url).read())\r\n",
    "    # config = pd.DataFrame.from_dict(assets[\"config\"], orient=\"index\")\r\n",
    "    # usage = pd.DataFrame.from_dict(assets[\"usage\"], orient=\"index\")\r\n",
    "    data = pd.DataFrame.from_dict(assets[\"data\"])\r\n",
    "    return data\r\n",
    "\r\n",
    "    # feeds_url = (\r\n",
    "    #     \"https://api.lunarcrush.com/v2?data=feeds&key=\" + api_key + \"&symbol=\" + coins\r\n",
    "    # )\r\n",
    "    # assets = json.loads(urllib.request.urlopen(feeds_url).read())\r\n",
    "    # print(assets)\r\n",
    "    # config = pd.DataFrame.from_dict(assets[\"config\"])\r\n",
    "\r\n",
    "    # time_series = pd.DataFrame.from_dict(assets[\"timeSeries\"])\r\n",
    "    # for asset in assets[\"data\"]:\r\n",
    "    #     asset_coin = \"\"\r\n",
    "    #     for field in map:\r\n",
    "    #         print(field)\r\n",
    "    #     key = list(field.keys())[0]\r\n",
    "    #     value = list(field.values())[0]\r\n",
    "    #     asset_coin = final_render(asset_coin, value, key, asset)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "data = lc_data()\r\n",
    "data.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>symbol</th>\n",
       "      <th>price</th>\n",
       "      <th>price_btc</th>\n",
       "      <th>market_cap</th>\n",
       "      <th>percent_change_24h</th>\n",
       "      <th>percent_change_7d</th>\n",
       "      <th>percent_change_30d</th>\n",
       "      <th>volume_24h</th>\n",
       "      <th>...</th>\n",
       "      <th>social_contributors</th>\n",
       "      <th>social_volume</th>\n",
       "      <th>social_volume_global</th>\n",
       "      <th>social_dominance</th>\n",
       "      <th>market_cap_global</th>\n",
       "      <th>market_dominance</th>\n",
       "      <th>medium</th>\n",
       "      <th>youtube</th>\n",
       "      <th>tags</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Ethereum</td>\n",
       "      <td>ETH</td>\n",
       "      <td>2845.876938</td>\n",
       "      <td>0.068726</td>\n",
       "      <td>334731187608</td>\n",
       "      <td>-5.89</td>\n",
       "      <td>-17.24</td>\n",
       "      <td>-12.21</td>\n",
       "      <td>5.421475e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>495</td>\n",
       "      <td>3139</td>\n",
       "      <td>47689</td>\n",
       "      <td>6.582231</td>\n",
       "      <td>2126364487256</td>\n",
       "      <td>15.495186</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>2845.876938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      name symbol        price  price_btc    market_cap  \\\n",
       "0   2  Ethereum    ETH  2845.876938   0.068726  334731187608   \n",
       "\n",
       "   percent_change_24h  percent_change_7d  percent_change_30d    volume_24h  \\\n",
       "0               -5.89             -17.24              -12.21  5.421475e+10   \n",
       "\n",
       "   ... social_contributors social_volume  social_volume_global  \\\n",
       "0  ...                 495          3139                 47689   \n",
       "\n",
       "   social_dominance  market_cap_global  market_dominance  medium  youtube  \\\n",
       "0          6.582231      2126364487256         15.495186       1        1   \n",
       "\n",
       "   tags        close  \n",
       "0        2845.876938  \n",
       "\n",
       "[1 rows x 94 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "df = eth.compile_historic(write_csv=True)\r\n",
    "num_features = df.shape[1]\r\n",
    "\r\n",
    "train_df, val_df, test_df = eth.ttsplit_norm(df)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class WindowGenerator:\r\n",
    "    def __init__(\r\n",
    "        self,\r\n",
    "        input_width,\r\n",
    "        label_width,\r\n",
    "        shift,\r\n",
    "        label_columns=None,\r\n",
    "        df=df,\r\n",
    "        train_df=train_df,\r\n",
    "        val_df=val_df,\r\n",
    "        test_df=test_df,\r\n",
    "    ):\r\n",
    "        # Store the raw data.\r\n",
    "        self.df = df\r\n",
    "        self.train_df = train_df\r\n",
    "        self.val_df = val_df\r\n",
    "        self.test_df = test_df\r\n",
    "\r\n",
    "        # Work out the label column indices.\r\n",
    "        self.label_columns = label_columns\r\n",
    "        if label_columns is not None:\r\n",
    "            self.label_columns_indices = {\r\n",
    "                name: i for i, name in enumerate(label_columns)\r\n",
    "            }\r\n",
    "        self.column_indices = {name: i for i, name in enumerate(train_df.columns)}\r\n",
    "\r\n",
    "        # Work out the window parameters.\r\n",
    "        self.input_width = input_width\r\n",
    "        self.label_width = label_width\r\n",
    "        self.shift = shift\r\n",
    "\r\n",
    "        self.total_window_size = input_width + shift\r\n",
    "\r\n",
    "        self.input_slice = slice(0, input_width)\r\n",
    "        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\r\n",
    "\r\n",
    "        self.label_start = self.total_window_size - self.label_width\r\n",
    "        self.labels_slice = slice(self.label_start, None)\r\n",
    "        self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\r\n",
    "\r\n",
    "    def split_window(self, features):\r\n",
    "        inputs = features[:, self.input_slice, :]\r\n",
    "        labels = features[:, self.labels_slice, :]\r\n",
    "        if self.label_columns is not None:\r\n",
    "            labels = tf.stack(\r\n",
    "                [\r\n",
    "                    labels[:, :, self.column_indices[name]]\r\n",
    "                    for name in self.label_columns\r\n",
    "                ],\r\n",
    "                axis=-1,\r\n",
    "            )\r\n",
    "\r\n",
    "        # Slicing doesn't preserve static shape information, so set the shapes\r\n",
    "        # manually. This way the `tf.data.Datasets` are easier to inspect.\r\n",
    "        inputs.set_shape([None, self.input_width, None])\r\n",
    "        labels.set_shape([None, self.label_width, None])\r\n",
    "\r\n",
    "        return inputs, labels\r\n",
    "\r\n",
    "    def make_ds(self, data):\r\n",
    "        data = np.array(data, dtype=np.float32)\r\n",
    "        ds = tf.keras.preprocessing.timeseries_dataset_from_array(\r\n",
    "            data=data,\r\n",
    "            targets=None,\r\n",
    "            sequence_length=self.total_window_size,\r\n",
    "            sequence_stride=1,\r\n",
    "            shuffle=True,\r\n",
    "            batch_size=32,\r\n",
    "        )\r\n",
    "\r\n",
    "        ds = ds.map(self.split_window)\r\n",
    "\r\n",
    "        return ds\r\n",
    "\r\n",
    "    def plot(self, model=None, plot_col=\"close\", max_subplots=3):\r\n",
    "        inputs, labels = self.example\r\n",
    "        plt.figure(figsize=(15, 10))\r\n",
    "        plot_col_index = self.column_indices[plot_col]\r\n",
    "        max_n = min(max_subplots, len(inputs))\r\n",
    "        for n in range(max_n):\r\n",
    "            plt.subplot(max_n, 1, n + 1)\r\n",
    "            plt.ylabel(f\"{plot_col} [normed]\")\r\n",
    "            plt.plot(\r\n",
    "                self.input_indices,\r\n",
    "                inputs[n, :, plot_col_index],\r\n",
    "                label=\"Inputs\",\r\n",
    "                marker=\".\",\r\n",
    "                zorder=-10,\r\n",
    "            )\r\n",
    "\r\n",
    "            if self.label_columns:\r\n",
    "                label_col_index = self.label_columns_indices.get(plot_col, None)\r\n",
    "            else:\r\n",
    "                label_col_index = plot_col_index\r\n",
    "\r\n",
    "            if label_col_index is None:\r\n",
    "                continue\r\n",
    "\r\n",
    "            plt.scatter(\r\n",
    "                self.label_indices,\r\n",
    "                labels[n, :, label_col_index],\r\n",
    "                # edgecolors=\"k\",\r\n",
    "                # label=\"Labels\",\r\n",
    "                # c=\"#2ca02c\",\r\n",
    "                s=64,\r\n",
    "            )\r\n",
    "            if model is not None:\r\n",
    "                predictions = model(inputs)\r\n",
    "                plt.scatter(\r\n",
    "                    self.label_indices,\r\n",
    "                    predictions[n, :, label_col_index],\r\n",
    "                    marker=\"X\",\r\n",
    "                    # edgecolors=\"k\",\r\n",
    "                    # label=\"Predictions\",\r\n",
    "                    # c=\"#ff7f0e\",\r\n",
    "                    s=64,\r\n",
    "                )\r\n",
    "\r\n",
    "            if n == 0:\r\n",
    "                plt.legend()\r\n",
    "\r\n",
    "        plt.xlabel(\"Time [h]\")\r\n",
    "\r\n",
    "    @property\r\n",
    "    def train(self):\r\n",
    "        return self.make_ds(self.train_df)\r\n",
    "\r\n",
    "    @property\r\n",
    "    def val(self):\r\n",
    "        return self.make_ds(self.val_df)\r\n",
    "\r\n",
    "    @property\r\n",
    "    def test(self):\r\n",
    "        return self.make_ds(self.test_df)\r\n",
    "\r\n",
    "    @property\r\n",
    "    def example(self):\r\n",
    "        \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\r\n",
    "        result = getattr(self, \"_example\", None)\r\n",
    "        if result is None:\r\n",
    "            # No example batch was found, so get one from the `.train` dataset\r\n",
    "            result = next(iter(self.train))\r\n",
    "            # And cache it for next time\r\n",
    "            self._example = result\r\n",
    "        return result\r\n",
    "\r\n",
    "    def __repr__(self):\r\n",
    "        return \"\\n\".join(\r\n",
    "            [\r\n",
    "                f\"Total window size: {self.total_window_size}\",\r\n",
    "                f\"Input indices: {self.input_indices}\",\r\n",
    "                f\"Label indices: {self.label_indices}\",\r\n",
    "                f\"Label column name(s): {self.label_columns}\",\r\n",
    "            ]\r\n",
    "        )\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "MAX_EPOCHS = 20\r\n",
    "\r\n",
    "\r\n",
    "def compile_and_fit(model, window, patience=3):\r\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\r\n",
    "        monitor=\"val_loss\", patience=patience, mode=\"min\"\r\n",
    "    )\r\n",
    "\r\n",
    "    model.compile(\r\n",
    "        loss=tf.losses.MeanSquaredError(),\r\n",
    "        optimizer=tf.optimizers.Adam(),\r\n",
    "        metrics=[tf.metrics.MeanAbsoluteError()],\r\n",
    "    )\r\n",
    "\r\n",
    "    history = model.fit(\r\n",
    "        window.train,\r\n",
    "        epochs=MAX_EPOCHS,\r\n",
    "        validation_data=window.val,\r\n",
    "        callbacks=[early_stopping],\r\n",
    "    )\r\n",
    "    return history\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class ResidualWrapper(tf.keras.Model):\r\n",
    "  def __init__(self, model):\r\n",
    "    super().__init__()\r\n",
    "    self.model = model\r\n",
    "\r\n",
    "  def call(self, inputs, *args, **kwargs):\r\n",
    "    delta = self.model(inputs, *args, **kwargs)\r\n",
    "\r\n",
    "    # The prediction for each time step is the input\r\n",
    "    # from the previous time step plus the delta\r\n",
    "    # calculated by the model.\r\n",
    "    return inputs + delta"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "OUT_STEPS = 24 * 7\r\n",
    "multi_val_performance = {}\r\n",
    "multi_performance = {}\r\n",
    "multi_window = WindowGenerator(\r\n",
    "    input_width=OUT_STEPS, label_width=OUT_STEPS, shift=OUT_STEPS\r\n",
    ")\r\n",
    "multi_window"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%%time\r\n",
    "residual_lstm = ResidualWrapper(\r\n",
    "    tf.keras.Sequential([\r\n",
    "    tf.keras.layers.LSTM(32, return_sequences=True),\r\n",
    "    tf.keras.layers.Dense(\r\n",
    "        num_features,\r\n",
    "        # The predicted deltas should start small.\r\n",
    "        # Therefore, initialize the output layer with zeros.\r\n",
    "        kernel_initializer=tf.initializers.zeros())\r\n",
    "]))\r\n",
    "\r\n",
    "history = compile_and_fit(residual_lstm, multi_window)\r\n",
    "\r\n",
    "multi_val_performance['Residual LSTM'] = residual_lstm.evaluate(multi_window.val)\r\n",
    "multi_performance['Residual LSTM'] = residual_lstm.evaluate(multi_window.test, verbose=0)\r\n",
    "multi_window.plot(residual_lstm)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "CONV_WIDTH = 3\r\n",
    "\r\n",
    "dev_model = tf.keras.models.Sequential(\r\n",
    "    [\r\n",
    "        # tf.keras.layers.Lambda(lambda x: x[:, -CONV_WIDTH:, :]),\r\n",
    "        tf.keras.layers.Conv1D(\r\n",
    "            filters=64,\r\n",
    "            kernel_size=(CONV_WIDTH),\r\n",
    "            strides=1,\r\n",
    "            padding=\"causal\",\r\n",
    "            activation=\"relu\",\r\n",
    "        ),\r\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\r\n",
    "        # tf.keras.layers.Bidirectional(\r\n",
    "        #     tf.keras.layers.LSTM(64, return_sequences=True)),\r\n",
    "        tf.keras.layers.Dense(128),\r\n",
    "        # tf.keras.layers.Dropout(.2),\r\n",
    "        tf.keras.layers.Dense(num_features),\r\n",
    "    ]\r\n",
    ")\r\n",
    "\r\n",
    "history = compile_and_fit(dev_model, multi_window)\r\n",
    "\r\n",
    "multi_val_performance[\"DEV\"] = dev_model.evaluate(multi_window.val)\r\n",
    "multi_performance[\"DEV\"] = dev_model.evaluate(multi_window.test, verbose=0)\r\n",
    "multi_window.plot(dev_model)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for name, value in multi_performance.items():\r\n",
    "    print(f\"{name:8s}: {value[1]:0.4f}\")\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "multi_dense_model = tf.keras.Sequential([\r\n",
    "    # Take the last time step.\r\n",
    "    # Shape [batch, time, features] => [batch, 1, features]\r\n",
    "    tf.keras.layers.Lambda(lambda x: x[:, -1:, :]),\r\n",
    "    # Shape => [batch, 1, dense_units]\r\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\r\n",
    "    # Shape => [batch, out_steps*features]\r\n",
    "    tf.keras.layers.Dense(OUT_STEPS*num_features,\r\n",
    "                          kernel_initializer=tf.initializers.zeros()),\r\n",
    "    # Shape => [batch, out_steps, features]\r\n",
    "    tf.keras.layers.Reshape([OUT_STEPS, num_features])\r\n",
    "])\r\n",
    "\r\n",
    "history = compile_and_fit(multi_dense_model, multi_window)\r\n",
    "\r\n",
    "multi_val_performance['Dense'] = multi_dense_model.evaluate(multi_window.val)\r\n",
    "multi_performance['Dense'] = multi_dense_model.evaluate(multi_window.test)\r\n",
    "multi_window.plot(multi_dense_model)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = multi_window.df\r\n",
    "df.plot_bokeh()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.2",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit ('env': venv)"
  },
  "interpreter": {
   "hash": "c0fa6df1989e8b1e61ca2e5a40b3f545d2b5d745ee2f55fdad9789d7961ddbf6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}