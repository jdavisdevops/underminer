{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from datetime import datetime, timedelta\r\n",
    "import pandas as pd\r\n",
    "%matplotlib inline\r\n",
    "%config IPCompleter.greedy = True\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import cbpro\r\n",
    "import os\r\n",
    "from pathlib import Path\r\n",
    "import seaborn as sns\r\n",
    "import matplotlib.dates as mdates\r\n",
    "from pandas.plotting import register_matplotlib_converters\r\n",
    "register_matplotlib_converters()\r\n",
    "\r\n",
    "sns.set_context(\"notebook\", font_scale=1.)\r\n",
    "sns.set_style(\"whitegrid\")\r\n",
    "%config InlineBackend.figure_format = 'retina'\r\n",
    "\r\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"\r\n",
    "os.environ[\"TF_GPU_THREAD_MODE\"] = \"gpu_private\"\r\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\r\n",
    "import tensorflow as tf\r\n",
    "import tensorflow_probability as tfp\r\n",
    "\r\n",
    "tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")\r\n",
    "policy = tf.keras.mixed_precision.Policy(\"mixed_float16\")\r\n",
    "tf.keras.mixed_precision.experimental.set_policy(policy)\r\n",
    "np.set_printoptions(suppress=True)\r\n",
    "\r\n",
    "public_client = cbpro.PublicClient()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(tf.__version__)\r\n",
    "if tf.test.gpu_device_name() != '/device:GPU:0':\r\n",
    "  print('WARNING: GPU device not found.')\r\n",
    "else:\r\n",
    "  print('SUCCESS: Found GPU: {}'.format(tf.test.gpu_device_name()))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class MinerMeta(type):\r\n",
    "    # def __init__(self):\r\n",
    "    #     result = getattr(self, \"df\", None)\r\n",
    "    #     if result is None:\r\n",
    "    #         self.df = self.compile_historic(read_csv=True)\r\n",
    "\r\n",
    "    def compile_historic(self, num_days=100, write_csv=False, read_csv=False):\r\n",
    "        file = Path.cwd() / f\"{self.coin}_histdata.csv\"\r\n",
    "        if read_csv is True:\r\n",
    "            df = pd.read_csv(file, index_col=\"time\", infer_datetime_format=True)\r\n",
    "            return df\r\n",
    "        else:\r\n",
    "            finish = datetime.now()\r\n",
    "            start = finish - timedelta(num_days)\r\n",
    "            delta = timedelta(hours=300)\r\n",
    "            df = pd.DataFrame()\r\n",
    "\r\n",
    "            while finish > start:\r\n",
    "                historic = public_client.get_product_historic_rates(\r\n",
    "                    f\"{self.coin}-USD\",\r\n",
    "                    granularity=3600,\r\n",
    "                    start=start,\r\n",
    "                    end=start + delta,\r\n",
    "                )\r\n",
    "                start += delta\r\n",
    "                df = df.append(historic, ignore_index=True, verify_integrity=True)\r\n",
    "            df.columns = [\"time\", \"low\", \"high\", \"open\", \"close\", \"volume\"]\r\n",
    "\r\n",
    "            # Manual Seasonality Calculation\r\n",
    "            # date_time = pd.to_datetime(df[\"time\"], unit=\"s\")\r\n",
    "            # df.set_index(\"time\", inplace=True)\r\n",
    "            # timestamp_s = date_time.map(pd.Timestamp.timestamp)\r\n",
    "            # day = 24 * 60 * 60\r\n",
    "            # year = (365.2425) * day\r\n",
    "            # df[\"Day sin\"] = np.sin(timestamp_s * (2 * np.pi / day))\r\n",
    "            # df[\"Day cos\"] = np.cos(timestamp_s * (2 * np.pi / day))\r\n",
    "            # df[\"Year sin\"] = np.sin(timestamp_s * (2 * np.pi / year))\r\n",
    "            # df[\"Year cos\"] = np.cos(timestamp_s * (2 * np.pi / year))\r\n",
    "\r\n",
    "            df.reset_index(drop=True, inplace=True)\r\n",
    "            df[\"time\"] = pd.to_datetime(df[\"time\"], unit=\"s\")\r\n",
    "            df.set_index(\"time\", inplace=True, verify_integrity=False)\r\n",
    "            df.sort_index(ascending=False)\r\n",
    "            if write_csv is True:\r\n",
    "                df.to_csv(file, index=True)\r\n",
    "\r\n",
    "            return df\r\n",
    "\r\n",
    "    def get_day_stats(self):\r\n",
    "        result = getattr(self, \"day_stats\", None)\r\n",
    "        if result is None:\r\n",
    "            ticker = public_client.get_product_24hr_stats(f\"{self.coin}-USD\")\r\n",
    "            df = pd.DataFrame.from_dict(ticker, orient=\"index\")\r\n",
    "            self.day_stats = df\r\n",
    "        return df\r\n",
    "\r\n",
    "    def year_day_fft(self, col):\r\n",
    "        df = self.compile_historic()\r\n",
    "        today = datetime.today()\r\n",
    "        ylim = int(df[col].max())\r\n",
    "        plt.figure(figsize=(15, 10))\r\n",
    "\r\n",
    "        fft = tf.signal.rfft(df[col])\r\n",
    "        f_per_dataset = np.arange(0, len(fft))\r\n",
    "\r\n",
    "        n_samples_h = 1\r\n",
    "        hours_per_year = 24 * 365.2524\r\n",
    "        hours_per_week = 24 * 7\r\n",
    "        years_per_dataset = n_samples_h / (hours_per_year)\r\n",
    "        hours_per_dataset = n_samples_h / (hours_per_week)\r\n",
    "\r\n",
    "        f_per_year = f_per_dataset / years_per_dataset\r\n",
    "        f_per_week = f_per_dataset / hours_per_dataset\r\n",
    "        plt.step(f_per_week, np.abs(fft))\r\n",
    "        plt.xscale(\"log\")\r\n",
    "        # plt.ylim(1000, ylim)\r\n",
    "        # plt.xlim([0.1, max(plt.xlim())])\r\n",
    "        plt.xticks([1, 7], labels=[\"1/Week\", \"1/day\"])\r\n",
    "        plt.xlabel(\"Frequency (log scale)\")\r\n",
    "\r\n",
    "        return plt.show()\r\n",
    "\r\n",
    "    def ttsplit_norm(self, df, split_time=0.7, feature_plot=False):\r\n",
    "        # train_df Test Split\r\n",
    "        n = len(df)\r\n",
    "        train_df = df[0 : int(n * 0.7)]\r\n",
    "        val_df = df[int(n * 0.7) : int(n * 0.9)]\r\n",
    "        test_df = df[int(n * 0.9) :]\r\n",
    "        # Normalize the Data\r\n",
    "        train_df_mean = train_df.mean()\r\n",
    "        train_df_std = train_df.std()\r\n",
    "\r\n",
    "        train_df = (train_df - train_df_mean) / train_df_std\r\n",
    "        val_df = (val_df - train_df_mean) / train_df_std\r\n",
    "        test_df = (test_df - train_df_mean) / train_df_std\r\n",
    "\r\n",
    "        # Create Feature Plot if wanted\r\n",
    "        if feature_plot is True:\r\n",
    "            df_std = (df - train_df_mean) / train_df_std\r\n",
    "            df_std = df_std.melt(var_name=\"Column\", value_name=\"Normalized\")\r\n",
    "            plt.figure(figsize=(12, 6))\r\n",
    "            ax = sns.violinplot(x=\"Column\", y=\"Normalized\", data=df_std)\r\n",
    "            ax.set_xticklabels(df.keys(), rotation=90)\r\n",
    "            ax.set_title(\"train_dfing Data Feature Dist with whole DF Mean\")\r\n",
    "\r\n",
    "            return train_df, val_df, test_df\r\n",
    "\r\n",
    "        return train_df, val_df, test_df\r\n",
    "\r\n",
    "    def __call__(self, *args, **kwargs):\r\n",
    "\r\n",
    "        cls = type.__call__(self, *args)\r\n",
    "\r\n",
    "        # setattr(cls, \"compile_historic\", self.compile_historic)\r\n",
    "        # setattr(cls, \"year_day_fft\", self.year_day_fft)\r\n",
    "        # setattr(cls, \"ttsplit_norm\", self.ttsplit_norm)\r\n",
    "        # setattr(cls, \"get_day_stats\", self.get_day_stats)\r\n",
    "        # setattr(cls, \"day_stats\", self.get_day_stats())\r\n",
    "\r\n",
    "        # for key, value in historic.items():\r\n",
    "        #     setattr(cls, \"hist_\" + key, value)\r\n",
    "        # for key, value in ticker.items():\r\n",
    "        #     setattr(cls, \"tick_\" + key, value)\r\n",
    "\r\n",
    "        return cls\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class eth(metaclass=MinerMeta):\r\n",
    "    coin = \"eth\"\r\n",
    "\r\n",
    "\r\n",
    "df = eth.compile_historic(read_csv=True)\r\n",
    "\r\n",
    "df = df[:500]\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def plot_preds(index, scatter_y, y2):\r\n",
    "    mean = y2.mean()\r\n",
    "    fig = plt.figure()\r\n",
    "    ax = fig.add_subplot(111, label=\"1\")\r\n",
    "    ax2 = fig.add_subplot(111, label=\"2\", frame_on=False)\r\n",
    "\r\n",
    "    ax.scatter(x=index, y=scatter_y.T, c=\"C1\")\r\n",
    "    # ax.set_xlabel(\"x label 1\", color=\"C0\")\r\n",
    "    # ax.tick_params(axis=\"x\", colors=\"C0\")\r\n",
    "\r\n",
    "    ax2.plot(y2)\r\n",
    "    ax2.plot(mean, c=\"red\", label=\"Mean\", linestyle=\"--\")\r\n",
    "    # ax2.plot(mean)\r\n",
    "    ax2.xaxis.tick_top()\r\n",
    "    ax2.yaxis.tick_right()\r\n",
    "    ax2.set_xlabel(\"x label 2\", color=\"C1\")\r\n",
    "    ax2.set_ylabel(\"y label 2\", color=\"C1\")\r\n",
    "    ax2.xaxis.set_label_position(\"top\")\r\n",
    "    ax2.yaxis.set_label_position(\"right\")\r\n",
    "    ax2.tick_params(axis=\"x\", colors=\"C1\")\r\n",
    "    ax2.tick_params(axis=\"y\", colors=\"C1\")\r\n",
    "    # fmt_month = mdates.MonthLocator()\r\n",
    "    # ax.xaxis.set_minor_locator(fmt_month)\r\n",
    "    fig.autofmt_xdate()\r\n",
    "    return plt.show(), print(mean)\r\n",
    "\r\n",
    "\r\n",
    "# plot_preds(test.index, y_test, y_hat)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Start Date\")\r\n",
    "print(min(df.index))\r\n",
    "\r\n",
    "print(\"End Date\")\r\n",
    "print(max(df.index))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def tt_split(df, train_percent=0.6, val_percent=0.2):\r\n",
    "    m = len(df.index)\r\n",
    "    train_end = int(train_percent * m)\r\n",
    "    val_end = int(val_percent * m) + train_end\r\n",
    "    train = df.iloc[:train_end]\r\n",
    "    val = df.iloc[train_end:val_end]\r\n",
    "    test = df.iloc[val_end:]\r\n",
    "    train = train / train.mean()\r\n",
    "    return train, val, test\r\n",
    "\r\n",
    "\r\n",
    "train, val, test = tt_split(df)\r\n",
    "\r\n",
    "y_train = train.pop(\"close\").values\r\n",
    "x_train = train.values\r\n",
    "\r\n",
    "y_val = val.pop(\"close\").values\r\n",
    "x_val = val.values\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fft = tf.signal.rfft(df[\"close\"])\r\n",
    "f_per_dataset = np.arange(0, len(fft))\r\n",
    "\r\n",
    "n_samples_h = len(df[\"close\"])\r\n",
    "hours_per_year = 24 * 365.2524\r\n",
    "years_per_dataset = n_samples_h / (hours_per_year)\r\n",
    "\r\n",
    "f_per_year = f_per_dataset / years_per_dataset\r\n",
    "plt.step(f_per_year, np.abs(fft))\r\n",
    "plt.xscale(\"log\")\r\n",
    "plt.ylim(0, 700000)\r\n",
    "plt.xlim([0.1, max(plt.xlim())])\r\n",
    "plt.xticks([1, 365.2524], labels=[\"1/Year\", \"1/day\"])\r\n",
    "_ = plt.xlabel(\"Frequency (log scale)\")\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# negloglik = lambda y, p_y: -p_y.log_prob(y)\r\n",
    "\r\n",
    "\r\n",
    "# tfd = tfp.distributions\r\n",
    "\r\n",
    "# model = tf.keras.Sequential(\r\n",
    "#     [\r\n",
    "#         # tf.keras.layers.Dense(64),\r\n",
    "#         # tf.keras.layers.Dense(32),\r\n",
    "#         tf.keras.layers.Dense(1),\r\n",
    "#         tfp.layers.DistributionLambda(lambda t: tfd.Normal(loc=t, scale=1)),\r\n",
    "#     ]\r\n",
    "# )\r\n",
    "\r\n",
    "# model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.05), loss=negloglik)\r\n",
    "# model.fit(x_train, y_train, epochs=500, validation_data=(x_val, y_val))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# # test = test[:10]\r\n",
    "# try:\r\n",
    "#     y_test = test.pop(\"close\").values\r\n",
    "# except:\r\n",
    "#     pass\r\n",
    "# x_test = test.values\r\n",
    "\r\n",
    "# print(len(test.index))\r\n",
    "# print(len(x_test))\r\n",
    "\r\n",
    "# y_hat = abs(model.predict(x_test))\r\n",
    "\r\n",
    "# print(\"data\", x_test[:5])\r\n",
    "# print()\r\n",
    "# print(\"preds\", y_hat[:5])\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "time_series = train\r\n",
    "\r\n",
    "\r\n",
    "def build_linear_model(time_series):\r\n",
    "    trend = tfp.sts.LocalLinearTrend(observed_time_series=time_series)\r\n",
    "    day_of_week = tfp.sts.Seasonal(\r\n",
    "        num_seasons=7,\r\n",
    "        num_steps_per_season=24,\r\n",
    "        observed_time_series=time_series,\r\n",
    "        name=\"day_of_week\",\r\n",
    "    )\r\n",
    "    time_of_day = tfp.sts.Seasonal(\r\n",
    "        num_seasons=24,\r\n",
    "        num_steps_per_season=1,\r\n",
    "        observed_time_series=time_series,\r\n",
    "        name=\"time_of_day\",\r\n",
    "    )\r\n",
    "    model = tfp.sts.Sum(\r\n",
    "        [trend, day_of_week, time_of_day], observed_time_series=time_series\r\n",
    "    )\r\n",
    "    return model\r\n",
    "\r\n",
    "\r\n",
    "model = build_linear_model(time_series)\r\n",
    "var_posteriors = tfp.sts.build_factored_surrogate_posterior(model=model)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "num_var_steps = 200\r\n",
    "\r\n",
    "\r\n",
    "# @tf.function(experimental_compile=True)\r\n",
    "def train():\r\n",
    "    elbo_loss_curve = tfp.vi.fit_surrogate_posterior(\r\n",
    "        target_log_prob_fn=model.joint_log_prob(observed_time_series=time_series),\r\n",
    "        surrogate_posterior=var_posteriors,\r\n",
    "        optimizer=tf.optimizers.Adam(learning_rate=0.1),\r\n",
    "        num_steps=num_var_steps,\r\n",
    "    )\r\n",
    "    return elbo_loss_curve\r\n",
    "\r\n",
    "\r\n",
    "elbo_loss_curve = train()\r\n",
    "plt.plot(elbo_loss_curve)\r\n",
    "plt.show()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "q_samples = var_posteriors.sample(50)\r\n",
    "\r\n",
    "for param in model.parameters:\r\n",
    "    print(\r\n",
    "        \"{}: {} +- {}\".format(\r\n",
    "            param.name,\r\n",
    "            np.mean(q_samples[param.name], axis=0),\r\n",
    "            np.std(q_samples[param.name], axis=0),\r\n",
    "        )\r\n",
    "    )\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "forecast = tfp.sts.forecast(\r\n",
    "    model,\r\n",
    "    observed_time_series=time_series,\r\n",
    "    parameter_samples=q_samples,\r\n",
    "    num_steps_forecast=24,\r\n",
    ")\r\n",
    "\r\n",
    "\r\n",
    "def plot_forecast(\r\n",
    "    x,\r\n",
    "    y,\r\n",
    "    forecast_mean,\r\n",
    "    forecast_scale,\r\n",
    "    forecast_samples,\r\n",
    "    title=None,\r\n",
    "    x_locator=None,\r\n",
    "    x_formatter=None,\r\n",
    "):\r\n",
    "    \"\"\"Plot a forecast distribution against the 'true' time series.\"\"\"\r\n",
    "    colors = sns.color_palette()\r\n",
    "    c1, c2 = colors[0], colors[1]\r\n",
    "    fig = plt.figure(figsize=(12, 6))\r\n",
    "    ax = fig.add_subplot(1, 1, 1)\r\n",
    "\r\n",
    "    num_steps = len(y)\r\n",
    "    num_steps_forecast = forecast_mean.shape[-1]\r\n",
    "    num_steps_train = num_steps - num_steps_forecast\r\n",
    "\r\n",
    "    ax.plot(x, y, lw=2, color=c1, label=\"ground truth\")\r\n",
    "\r\n",
    "    forecast_steps = np.arange(\r\n",
    "        x[num_steps_train],\r\n",
    "        int(x[num_steps_train]) + int(num_steps_forecast),\r\n",
    "        dtype=x.dtype,\r\n",
    "    )\r\n",
    "\r\n",
    "    ax.plot(forecast_steps, forecast_samples.T, lw=1, color=c2, alpha=0.1)\r\n",
    "\r\n",
    "    ax.plot(forecast_steps, forecast_mean, lw=2, ls=\"--\", color=c2, label=\"forecast\")\r\n",
    "    ax.fill_between(\r\n",
    "        forecast_steps,\r\n",
    "        forecast_mean - 2 * forecast_scale,\r\n",
    "        forecast_mean + 2 * forecast_scale,\r\n",
    "        color=c2,\r\n",
    "        alpha=0.2,\r\n",
    "    )\r\n",
    "\r\n",
    "    ymin, ymax = min(np.min(forecast_samples), np.min(y)), max(\r\n",
    "        np.max(forecast_samples), np.max(y)\r\n",
    "    )\r\n",
    "    yrange = ymax - ymin\r\n",
    "    ax.set_ylim([ymin - yrange * 0.1, ymax + yrange * 0.1])\r\n",
    "    ax.set_title(\"{}\".format(title))\r\n",
    "    ax.legend()\r\n",
    "\r\n",
    "    if x_locator is not None:\r\n",
    "        ax.xaxis.set_major_locator(x_locator)\r\n",
    "        ax.xaxis.set_major_formatter(x_formatter)\r\n",
    "        fig.autofmt_xdate()\r\n",
    "\r\n",
    "    return fig, ax\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "num_samples = int(10)\r\n",
    "\r\n",
    "forecast_mean, forecast_scale, forecast_samples = (\r\n",
    "    forecast.mean().numpy()[..., 0],\r\n",
    "    forecast.stddev().numpy()[..., 0],\r\n",
    "    forecast.sample(num_samples).numpy()[..., 0],\r\n",
    ")\r\n",
    "\r\n",
    "x_loc = mdates.YearLocator(3)\r\n",
    "fmt = mdates.DateFormatter(\"%Y\")\r\n",
    "\r\n",
    "fig, ax = plot_forecast(\r\n",
    "    time_series.index,\r\n",
    "    time_series.values,\r\n",
    "    forecast_mean,\r\n",
    "    forecast_scale,\r\n",
    "    forecast_samples,\r\n",
    "    # title=\"Eth Close Forecast\",\r\n",
    "    # x_locator=x_loc,\r\n",
    "    # x_formatter=fmt,\r\n",
    ")\r\n",
    "# ax.axvline(dates[-num_forecast_steps], linestyle=\"--\")\r\n",
    "fig.autofmt_xdate()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.2",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit ('env': venv)"
  },
  "interpreter": {
   "hash": "c0fa6df1989e8b1e61ca2e5a40b3f545d2b5d745ee2f55fdad9789d7961ddbf6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}