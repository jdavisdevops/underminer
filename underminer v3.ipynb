{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import pandas as pd\r\n",
    "from datetime import datetime, timedelta\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import tensorflow as tf\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import cbpro\r\n",
    "\r\n",
    "public_client = cbpro.PublicClient()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "class MinerMeta(type):\r\n",
    "    def compile_historic(self, timestamp=False):\r\n",
    "        start_date = datetime(2020, 1, 1)\r\n",
    "        end_date = datetime.today()\r\n",
    "        delta = timedelta(hours=300)\r\n",
    "        df = pd.DataFrame()\r\n",
    "\r\n",
    "        while start_date <= end_date:\r\n",
    "            historic = public_client.get_product_historic_rates(\r\n",
    "                f\"{self.coin}-USD\",\r\n",
    "                granularity=3600,\r\n",
    "                start=start_date,\r\n",
    "                end=start_date + delta,\r\n",
    "            )\r\n",
    "            start_date += delta\r\n",
    "            df = df.append(historic, ignore_index=True)\r\n",
    "        df.columns = [\"time\", \"low\", \"high\", \"open\", \"close\", \"volume\"]\r\n",
    "        date_time = pd.to_datetime(df[\"time\"], unit=\"s\")\r\n",
    "\r\n",
    "        timestamp_s = date_time.map(pd.Timestamp.timestamp)\r\n",
    "        day = 24 * 60 * 60\r\n",
    "        year = (365.2425) * day\r\n",
    "        df[\"Day sin\"] = np.sin(timestamp_s * (2 * np.pi / day))\r\n",
    "        df[\"Day cos\"] = np.cos(timestamp_s * (2 * np.pi / day))\r\n",
    "        df[\"Year sin\"] = np.sin(timestamp_s * (2 * np.pi / year))\r\n",
    "        df[\"Year cos\"] = np.cos(timestamp_s * (2 * np.pi / year))\r\n",
    "        df.reset_index(drop=True, inplace=True)\r\n",
    "\r\n",
    "        if timestamp is True:\r\n",
    "            pass\r\n",
    "        else:\r\n",
    "            df[\"time\"] = pd.to_datetime(df[\"time\"], unit=\"s\")\r\n",
    "        # df[\"time\"] = pd.to_datetime(df[\"time\"], unit=\"s\")\r\n",
    "        # df[\"time\"] = date_time.map(pd.Timestamp.timestamp)\r\n",
    "\r\n",
    "        # data = np.array(df, dtype=np.float32)\r\n",
    "        # ds = tf.keras.preprocessing.timeseries_dataset_from_array(\r\n",
    "        #     data=df,\r\n",
    "        #     targets=\"close\",\r\n",
    "        #     sequence_length=10,\r\n",
    "        #     sequence_stride=1,\r\n",
    "        #     shuffle=False,\r\n",
    "        #     batch_size=64,\r\n",
    "        # )\r\n",
    "\r\n",
    "        return df\r\n",
    "\r\n",
    "    def plot_cols(self, df, cols=None):\r\n",
    "        if cols == None:\r\n",
    "            plot_features = df[list(df.columns)]\r\n",
    "        else:\r\n",
    "            plot_features = df[cols]\r\n",
    "\r\n",
    "        index = df[\"time\"]\r\n",
    "        fig, axs = plt.subplots(len(plot_features))\r\n",
    "\r\n",
    "        for x in len(plot_features):\r\n",
    "            axs[x].plot(df[\"time\"], plot_features[x])\r\n",
    "        # fft = tf.signal.rfft(df[cols])\r\n",
    "\r\n",
    "    def do_fft(self):\r\n",
    "        df = self.compile_historic()\r\n",
    "        today = datetime.today()\r\n",
    "\r\n",
    "        fft = tf.signal.rfft(df[\"close\"])\r\n",
    "        f_per_dataset = np.arange(0, len(fft))\r\n",
    "\r\n",
    "        n_samples_h = len(df[\"close\"])\r\n",
    "        hours_per_year = 24 * 365.2524\r\n",
    "        years_per_dataset = n_samples_h / (hours_per_year)\r\n",
    "\r\n",
    "        f_per_year = f_per_dataset / years_per_dataset\r\n",
    "        plt.step(f_per_year, np.abs(fft))\r\n",
    "        plt.xscale(\"log\")\r\n",
    "        plt.ylim(0, 400000)\r\n",
    "        plt.xlim([0.1, max(plt.xlim())])\r\n",
    "        plt.xticks([1, 365.2524], labels=[\"1/Year\", \"1/day\"])\r\n",
    "        _ = plt.xlabel(\"Frequency (log scale)\")\r\n",
    "\r\n",
    "        return plt.show()\r\n",
    "\r\n",
    "    # def make_dataset(data):\r\n",
    "    #     data = np.array(data, dtype=np.float32)\r\n",
    "    #     ds = tf.keras.preprocessing.timeseries_dataset_from_array(\r\n",
    "    #         data=data,\r\n",
    "    #         targets=\"close\",\r\n",
    "    #         sequence_length=10,\r\n",
    "    #         sequence_stride=1,\r\n",
    "    #         shuffle=False,\r\n",
    "    #         batch_size=64,\r\n",
    "    #     )\r\n",
    "\r\n",
    "    #     return ds\r\n",
    "\r\n",
    "    def __call__(self, *args, **kwargs):\r\n",
    "\r\n",
    "        cls = type.__call__(self, *args)\r\n",
    "\r\n",
    "        setattr(cls, \"compile_historic\", self.compile_historic)\r\n",
    "        setattr(cls, \"plot_cols\", self.plot_cols)\r\n",
    "        setattr(cls, \"do_fft\", self.do_fft)\r\n",
    "        # setattr(cls, \"make_dataset\", self.compile_historic)\r\n",
    "\r\n",
    "        # for key, value in historic.items():\r\n",
    "        #     setattr(cls, \"hist_\" + key, value)\r\n",
    "        # for key, value in ticker.items():\r\n",
    "        #     setattr(cls, \"tick_\" + key, value)\r\n",
    "\r\n",
    "        return cls\r\n",
    "\r\n",
    "\r\n",
    "class eth(metaclass=MinerMeta):\r\n",
    "    coin = \"eth\"\r\n",
    "\r\n",
    "\r\n",
    "class btc(metaclass=MinerMeta):\r\n",
    "    coin = \"btc\"\r\n",
    "\r\n",
    "\r\n",
    "class FeedBack(tf.keras.Model):\r\n",
    "    def __init__(self, units, out_steps):\r\n",
    "        super().__init__()\r\n",
    "        self.out_steps = out_steps\r\n",
    "        self.units = units\r\n",
    "        self.lstm_cell = tf.keras.layers.LSTMCell(units)\r\n",
    "        # Also wrap the LSTMCell in an RNN to simplify the `warmup` method.\r\n",
    "        self.lstm_rnn = tf.keras.layers.RNN(self.lstm_cell, return_state=True)\r\n",
    "        self.dense = tf.keras.layers\r\n",
    "\r\n",
    "    def warmup(self, inputs):\r\n",
    "        # inputs.shape => (batch, time, features)\r\n",
    "        # x.shape => (batch, lstm_units)\r\n",
    "        x, *state = self.lstm_rnn(inputs)\r\n",
    "\r\n",
    "        # predictions.shape => (batch, features)\r\n",
    "        prediction = self.dense(x)\r\n",
    "        return prediction, state\r\n",
    "\r\n",
    "    def call(self, inputs, training=None):\r\n",
    "        # Use a TensorArray to capture dynamically unrolled outputs.\r\n",
    "        predictions = []\r\n",
    "        # Initialize the LSTM state.\r\n",
    "        prediction, state = self.warmup(inputs)\r\n",
    "\r\n",
    "        # Insert the first prediction.\r\n",
    "        predictions.append(prediction)\r\n",
    "\r\n",
    "        # Run the rest of the prediction steps.\r\n",
    "        for n in range(1, self.out_steps):\r\n",
    "            # Use the last prediction as input.\r\n",
    "            x = prediction\r\n",
    "            # Execute one lstm step.\r\n",
    "            x, state = self.lstm_cell(x, states=state, training=training)\r\n",
    "            # Convert the lstm output to a prediction.\r\n",
    "            prediction = self.dense(x)\r\n",
    "            # Add the prediction to the output.\r\n",
    "            predictions.append(prediction)\r\n",
    "\r\n",
    "        # predictions.shape => (time, batch, features)\r\n",
    "        predictions = tf.stack(predictions)\r\n",
    "        # predictions.shape => (batch, time, features)\r\n",
    "        predictions = tf.transpose(predictions, [1, 0, 2])\r\n",
    "        return predictions\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from pathlib import Path\r\n",
    "\r\n",
    "file = Path.cwd() / \"ethdata.json\"\r\n",
    "\r\n",
    "\r\n",
    "def plot_cols(self, df, cols=None):\r\n",
    "    if cols == None:\r\n",
    "        plot_features = df[list(df.columns)]\r\n",
    "    else:\r\n",
    "        plot_features = df[cols]\r\n",
    "\r\n",
    "    index = df[\"time\"]\r\n",
    "    plots = len(plot_features)\r\n",
    "    fig, axs = plt.subplots(plots)\r\n",
    "\r\n",
    "    for x in plots:\r\n",
    "        print(x)\r\n",
    "        # axs[x].plot(index, plot_features[x])\r\n",
    "    # fft = tf.signal.rfft(df[cols])\r\n",
    "\r\n",
    "\r\n",
    "df = eth.compile_historic()\r\n",
    "\r\n",
    "df.to_json(df)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "argument of type 'method' is not iterable",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21744/2155513230.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile_historic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\josephdavis\\Desktop\\underminer\\env\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_json\u001b[1;34m(self, path_or_buf, orient, date_format, double_precision, force_ascii, date_unit, default_handler, lines, compression, index, indent, storage_options)\u001b[0m\n\u001b[0;32m   2556\u001b[0m         \u001b[0mindent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindent\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2558\u001b[1;33m         return json.to_json(\n\u001b[0m\u001b[0;32m   2559\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2560\u001b[0m             \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\josephdavis\\Desktop\\underminer\\env\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001b[0m in \u001b[0;36mto_json\u001b[1;34m(path_or_buf, obj, orient, date_format, double_precision, force_ascii, date_unit, default_handler, lines, compression, index, indent, storage_options)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[1;31m# apply compression and byte/text conversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m         with get_handle(\n\u001b[0m\u001b[0;32m    131\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"w\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         ) as handles:\n",
      "\u001b[1;32mc:\\Users\\josephdavis\\Desktop\\underminer\\env\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    582\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m     \u001b[1;31m# read_csv does not know whether the buffer is opened in binary/text mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 584\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0m_is_binary_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    585\u001b[0m         \u001b[0mmode\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\"b\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\josephdavis\\Desktop\\underminer\\env\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_is_binary_mode\u001b[1;34m(handle, mode)\u001b[0m\n\u001b[0;32m    951\u001b[0m     \u001b[1;31m# classes that expect bytes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m     \u001b[0mbinary_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mBufferedIOBase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRawIOBase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 953\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary_classes\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"mode\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: argument of type 'method' is not iterable"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class WindowGenerator:\r\n",
    "    def __init__(\r\n",
    "        self,\r\n",
    "        input_width,\r\n",
    "        label_width,\r\n",
    "        shift,\r\n",
    "        train_df=train_df,\r\n",
    "        val_df=val_df,\r\n",
    "        test_df=test_df,\r\n",
    "        label_columns=None,\r\n",
    "    ):\r\n",
    "        # Store the raw data.\r\n",
    "        self.train_df = train_df\r\n",
    "        self.val_df = val_df\r\n",
    "        self.test_df = test_df\r\n",
    "\r\n",
    "        # Work out the label column indices.\r\n",
    "        self.label_columns = label_columns\r\n",
    "        if label_columns is not None:\r\n",
    "            self.label_columns_indices = {\r\n",
    "                name: i for i, name in enumerate(label_columns)\r\n",
    "            }\r\n",
    "        self.column_indices = {name: i for i, name in enumerate(train_df.columns)}\r\n",
    "\r\n",
    "        # Work out the window parameters.\r\n",
    "        self.input_width = input_width\r\n",
    "        self.label_width = label_width\r\n",
    "        self.shift = shift\r\n",
    "\r\n",
    "        self.total_window_size = input_width + shift\r\n",
    "\r\n",
    "        self.input_slice = slice(0, input_width)\r\n",
    "        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\r\n",
    "\r\n",
    "        self.label_start = self.total_window_size - self.label_width\r\n",
    "        self.labels_slice = slice(self.label_start, None)\r\n",
    "        self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\r\n",
    "\r\n",
    "    def __repr__(self):\r\n",
    "        return \"\\n\".join(\r\n",
    "            [\r\n",
    "                f\"Total window size: {self.total_window_size}\",\r\n",
    "                f\"Input indices: {self.input_indices}\",\r\n",
    "                f\"Label indices: {self.label_indices}\",\r\n",
    "                f\"Label column name(s): {self.label_columns}\",\r\n",
    "            ]\r\n",
    "        )\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.2",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit ('env': venv)"
  },
  "interpreter": {
   "hash": "c0fa6df1989e8b1e61ca2e5a40b3f545d2b5d745ee2f55fdad9789d7961ddbf6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}