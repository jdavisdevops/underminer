{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.distribute.one_device_strategy.OneDeviceStrategy at 0x1ce79e5aa20>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "%matplotlib inline\n",
    "%config IPCompleter.greedy = True\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "\n",
    "sns.set(\n",
    "    font=\"Franklin Gothic Book\",\n",
    "    rc={\n",
    "        \"axes.axisbelow\": False,\n",
    "        \"axes.edgecolor\": \"lightgrey\",\n",
    "        \"axes.facecolor\": \"None\",\n",
    "        \"axes.grid\": False,\n",
    "        \"axes.labelcolor\": \"dimgrey\",\n",
    "        \"axes.spines.right\": False,\n",
    "        \"axes.spines.top\": False,\n",
    "        \"figure.facecolor\": \"white\",\n",
    "        \"lines.solid_capstyle\": \"round\",\n",
    "        \"patch.edgecolor\": \"w\",\n",
    "        \"patch.force_edgecolor\": True,\n",
    "        \"text.color\": \"dimgrey\",\n",
    "        \"xtick.bottom\": False,\n",
    "        \"xtick.color\": \"dimgrey\",\n",
    "        \"xtick.direction\": \"out\",\n",
    "        \"xtick.top\": False,\n",
    "        \"ytick.color\": \"dimgrey\",\n",
    "        \"ytick.direction\": \"out\",\n",
    "        \"ytick.left\": False,\n",
    "        \"ytick.right\": False,\n",
    "    },\n",
    ")\n",
    "\n",
    "sns.set_context(\n",
    "    \"notebook\", rc={\"font.size\": 16, \"axes.titlesize\": 20, \"axes.labelsize\": 18}\n",
    ")\n",
    "import requests\n",
    "from creds import api_key\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from pandasgui import show\n",
    "\n",
    "tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN Check \n",
      "0\n",
      "2021-10-27 17:00:00\n",
      "2021-04-30 18:00:00\n",
      "4320\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>volume</th>\n",
       "      <th>market_cap</th>\n",
       "      <th>url_shares</th>\n",
       "      <th>unique_url_shares</th>\n",
       "      <th>reddit_posts</th>\n",
       "      <th>reddit_posts_score</th>\n",
       "      <th>...</th>\n",
       "      <th>social_volume</th>\n",
       "      <th>price_btc</th>\n",
       "      <th>social_volume_global</th>\n",
       "      <th>social_dominance</th>\n",
       "      <th>market_cap_global</th>\n",
       "      <th>market_dominance</th>\n",
       "      <th>percent_change_24h</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-10-27 13:00:00</th>\n",
       "      <td>4017.771623</td>\n",
       "      <td>3999.375920</td>\n",
       "      <td>4026.983646</td>\n",
       "      <td>3997.305227</td>\n",
       "      <td>1.194754e+09</td>\n",
       "      <td>472689468151</td>\n",
       "      <td>744</td>\n",
       "      <td>407</td>\n",
       "      <td>37.567529</td>\n",
       "      <td>468.939655</td>\n",
       "      <td>...</td>\n",
       "      <td>4618</td>\n",
       "      <td>0.067604</td>\n",
       "      <td>103925</td>\n",
       "      <td>4.443589</td>\n",
       "      <td>2706433014518</td>\n",
       "      <td>17.465404</td>\n",
       "      <td>-4.568263</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-27 14:00:00</th>\n",
       "      <td>3999.166344</td>\n",
       "      <td>4021.947489</td>\n",
       "      <td>4041.576430</td>\n",
       "      <td>3982.374095</td>\n",
       "      <td>1.509966e+09</td>\n",
       "      <td>474989598384</td>\n",
       "      <td>937</td>\n",
       "      <td>459</td>\n",
       "      <td>37.567529</td>\n",
       "      <td>468.939655</td>\n",
       "      <td>...</td>\n",
       "      <td>5950</td>\n",
       "      <td>0.067774</td>\n",
       "      <td>121854</td>\n",
       "      <td>4.882893</td>\n",
       "      <td>2722139672515</td>\n",
       "      <td>17.449127</td>\n",
       "      <td>-3.212382</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-27 15:00:00</th>\n",
       "      <td>4021.248990</td>\n",
       "      <td>4001.185048</td>\n",
       "      <td>4035.149027</td>\n",
       "      <td>3996.347556</td>\n",
       "      <td>1.203626e+09</td>\n",
       "      <td>471876484833</td>\n",
       "      <td>1026</td>\n",
       "      <td>439</td>\n",
       "      <td>37.567529</td>\n",
       "      <td>468.939655</td>\n",
       "      <td>...</td>\n",
       "      <td>5798</td>\n",
       "      <td>0.067809</td>\n",
       "      <td>130519</td>\n",
       "      <td>4.442265</td>\n",
       "      <td>2708389913267</td>\n",
       "      <td>17.422768</td>\n",
       "      <td>-4.554406</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-27 16:00:00</th>\n",
       "      <td>4002.454009</td>\n",
       "      <td>3985.971390</td>\n",
       "      <td>4011.179803</td>\n",
       "      <td>3960.514271</td>\n",
       "      <td>1.518369e+09</td>\n",
       "      <td>471412791739</td>\n",
       "      <td>1070</td>\n",
       "      <td>527</td>\n",
       "      <td>37.567529</td>\n",
       "      <td>468.939655</td>\n",
       "      <td>...</td>\n",
       "      <td>6216</td>\n",
       "      <td>0.067478</td>\n",
       "      <td>135228</td>\n",
       "      <td>4.596681</td>\n",
       "      <td>2708682760745</td>\n",
       "      <td>17.403765</td>\n",
       "      <td>-4.470943</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-27 17:00:00</th>\n",
       "      <td>3987.241219</td>\n",
       "      <td>3992.361146</td>\n",
       "      <td>4009.138146</td>\n",
       "      <td>3987.241219</td>\n",
       "      <td>4.311580e+08</td>\n",
       "      <td>471499670053</td>\n",
       "      <td>1092</td>\n",
       "      <td>511</td>\n",
       "      <td>37.567529</td>\n",
       "      <td>468.939655</td>\n",
       "      <td>...</td>\n",
       "      <td>5883</td>\n",
       "      <td>0.067599</td>\n",
       "      <td>113985</td>\n",
       "      <td>5.161205</td>\n",
       "      <td>2713845456123</td>\n",
       "      <td>17.373859</td>\n",
       "      <td>-5.490000</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            open        close         high          low  \\\n",
       "time                                                                      \n",
       "2021-10-27 13:00:00  4017.771623  3999.375920  4026.983646  3997.305227   \n",
       "2021-10-27 14:00:00  3999.166344  4021.947489  4041.576430  3982.374095   \n",
       "2021-10-27 15:00:00  4021.248990  4001.185048  4035.149027  3996.347556   \n",
       "2021-10-27 16:00:00  4002.454009  3985.971390  4011.179803  3960.514271   \n",
       "2021-10-27 17:00:00  3987.241219  3992.361146  4009.138146  3987.241219   \n",
       "\n",
       "                           volume    market_cap  url_shares  \\\n",
       "time                                                          \n",
       "2021-10-27 13:00:00  1.194754e+09  472689468151         744   \n",
       "2021-10-27 14:00:00  1.509966e+09  474989598384         937   \n",
       "2021-10-27 15:00:00  1.203626e+09  471876484833        1026   \n",
       "2021-10-27 16:00:00  1.518369e+09  471412791739        1070   \n",
       "2021-10-27 17:00:00  4.311580e+08  471499670053        1092   \n",
       "\n",
       "                     unique_url_shares  reddit_posts  reddit_posts_score  ...  \\\n",
       "time                                                                      ...   \n",
       "2021-10-27 13:00:00                407     37.567529          468.939655  ...   \n",
       "2021-10-27 14:00:00                459     37.567529          468.939655  ...   \n",
       "2021-10-27 15:00:00                439     37.567529          468.939655  ...   \n",
       "2021-10-27 16:00:00                527     37.567529          468.939655  ...   \n",
       "2021-10-27 17:00:00                511     37.567529          468.939655  ...   \n",
       "\n",
       "                     social_volume  price_btc  social_volume_global  \\\n",
       "time                                                                  \n",
       "2021-10-27 13:00:00           4618   0.067604                103925   \n",
       "2021-10-27 14:00:00           5950   0.067774                121854   \n",
       "2021-10-27 15:00:00           5798   0.067809                130519   \n",
       "2021-10-27 16:00:00           6216   0.067478                135228   \n",
       "2021-10-27 17:00:00           5883   0.067599                113985   \n",
       "\n",
       "                     social_dominance  market_cap_global  market_dominance  \\\n",
       "time                                                                         \n",
       "2021-10-27 13:00:00          4.443589      2706433014518         17.465404   \n",
       "2021-10-27 14:00:00          4.882893      2722139672515         17.449127   \n",
       "2021-10-27 15:00:00          4.442265      2708389913267         17.422768   \n",
       "2021-10-27 16:00:00          4.596681      2708682760745         17.403765   \n",
       "2021-10-27 17:00:00          5.161205      2713845456123         17.373859   \n",
       "\n",
       "                     percent_change_24h  month  day  hour  \n",
       "time                                                       \n",
       "2021-10-27 13:00:00           -4.568263     10   27    13  \n",
       "2021-10-27 14:00:00           -3.212382     10   27    14  \n",
       "2021-10-27 15:00:00           -4.554406     10   27    15  \n",
       "2021-10-27 16:00:00           -4.470943     10   27    16  \n",
       "2021-10-27 17:00:00           -5.490000     10   27    17  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compile_lc_data(num_days=180, read_csv=False, write_csv=False, coins=\"ETH\"):\n",
    "    file = Path.cwd() / \"lunar_histdata.csv\"\n",
    "    if read_csv is True:\n",
    "        df = pd.read_csv(file, index_col=0)\n",
    "        return df\n",
    "    intervals = [\"1d\", \"1w\", \"1m\", \"3m\", \"6m\", \"1y\", \"2y\"]\n",
    "    finish = datetime.now()\n",
    "    start = finish - timedelta(days=num_days)\n",
    "    delta = timedelta(hours=720)\n",
    "    df = pd.DataFrame()\n",
    "    while finish > start:\n",
    "        payload = {\n",
    "            \"key\": api_key,\n",
    "            \"symbol\": coins,\n",
    "            \"change\": intervals,\n",
    "            \"data_points\": \"720\",\n",
    "            \"start\": datetime.timestamp(start),\n",
    "        }\n",
    "\n",
    "        r = requests.get(\"https://api.lunarcrush.com/v2?data=assets\", params=payload)\n",
    "\n",
    "        data = pd.DataFrame.from_dict(r.json()[\"data\"][0])\n",
    "        ts = data.timeSeries.to_dict()\n",
    "        new = pd.DataFrame.from_dict(ts, orient=\"index\")\n",
    "        new.pop(\"asset_id\")\n",
    "        new.pop(\"search_average\")\n",
    "        new[\"time\"] = pd.to_datetime(new[\"time\"], unit=\"s\")\n",
    "        new.set_index(\"time\", inplace=True)\n",
    "        new.sort_index(ascending=True, inplace=True)\n",
    "        new[\"month\"] = [new.index[i].month for i in range(len(new))]\n",
    "        new[\"day\"] = [new.index[i].day for i in range(len(new))]\n",
    "        new[\"hour\"] = [new.index[i].hour for i in range(len(new))]\n",
    "        new.fillna(new.mean(), inplace=True)\n",
    "\n",
    "        df = df.append(new, ignore_index=False, verify_integrity=True)\n",
    "        start = start + delta\n",
    "\n",
    "    if write_csv is True:\n",
    "        df.to_csv(file)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = compile_lc_data(read_csv=True)\n",
    "print(\"NaN Check \")\n",
    "print(df.isna().sum().sum())\n",
    "print(df.index.max())\n",
    "print(df.index.min())\n",
    "print(len(df))\n",
    "df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = df.sample(frac=0.8, random_state=0)\n",
    "test_ds = df.drop(train_ds.index)\n",
    "\n",
    "train_features = train_ds.copy()\n",
    "test_features = test_ds.copy()\n",
    "\n",
    "train_label = train_features.pop(\"close\")\n",
    "test_label = test_features.pop(\"close\")\n",
    "\n",
    "\n",
    "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "normalizer.adapt(np.array(train_features).astype(\"float32\"))\n",
    "\n",
    "linear_model = tf.keras.models.Sequential([normalizer, tf.keras.layers.Dense(1)])\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "linear_model.compile(optimizer=optimizer, loss=\"mse\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'dense/kernel:0' shape=(58, 1) dtype=float32, numpy=\n",
       "array([[-0.13431363],\n",
       "       [-0.02248627],\n",
       "       [ 0.05850875],\n",
       "       [-0.13471758],\n",
       "       [ 0.08368614],\n",
       "       [-0.10091648],\n",
       "       [ 0.00964206],\n",
       "       [ 0.11618438],\n",
       "       [-0.30137998],\n",
       "       [ 0.27318376],\n",
       "       [-0.30507225],\n",
       "       [ 0.13857165],\n",
       "       [ 0.28252894],\n",
       "       [ 0.12130484],\n",
       "       [ 0.02262798],\n",
       "       [-0.16682859],\n",
       "       [-0.01923132],\n",
       "       [ 0.13068065],\n",
       "       [ 0.11038408],\n",
       "       [ 0.13377091],\n",
       "       [-0.12102017],\n",
       "       [-0.26626864],\n",
       "       [-0.00827885],\n",
       "       [ 0.279858  ],\n",
       "       [-0.2836768 ],\n",
       "       [-0.01773137],\n",
       "       [-0.15258011],\n",
       "       [ 0.274929  ],\n",
       "       [ 0.02859876],\n",
       "       [ 0.09423283],\n",
       "       [-0.16087621],\n",
       "       [-0.3114479 ],\n",
       "       [ 0.1895346 ],\n",
       "       [-0.16268004],\n",
       "       [ 0.07192153],\n",
       "       [-0.0808714 ],\n",
       "       [ 0.13420665],\n",
       "       [ 0.1959303 ],\n",
       "       [ 0.2027371 ],\n",
       "       [ 0.3054061 ],\n",
       "       [ 0.1912502 ],\n",
       "       [ 0.22121489],\n",
       "       [-0.22870393],\n",
       "       [ 0.24305731],\n",
       "       [-0.16379124],\n",
       "       [-0.03099138],\n",
       "       [ 0.12770548],\n",
       "       [-0.18061519],\n",
       "       [-0.31108654],\n",
       "       [ 0.14981443],\n",
       "       [ 0.10301828],\n",
       "       [-0.00563252],\n",
       "       [-0.28961048],\n",
       "       [ 0.08260515],\n",
       "       [-0.13239537],\n",
       "       [ 0.30245483],\n",
       "       [-0.1500536 ],\n",
       "       [ 0.2081061 ]], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.layers[1].kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "87/87 [==============================] - 2s 8ms/step - loss: 9061316.0000 - val_loss: 9292571.0000\n",
      "Epoch 2/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 9060112.0000 - val_loss: 9291086.0000\n",
      "Epoch 3/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 9058895.0000 - val_loss: 9289721.0000\n",
      "Epoch 4/2000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 9057686.0000 - val_loss: 9288300.0000\n",
      "Epoch 5/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 9056479.0000 - val_loss: 9286889.0000\n",
      "Epoch 6/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 9055273.0000 - val_loss: 9285459.0000\n",
      "Epoch 7/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 9054068.0000 - val_loss: 9284027.0000\n",
      "Epoch 8/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 9052865.0000 - val_loss: 9282596.0000\n",
      "Epoch 9/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 9051663.0000 - val_loss: 9281193.0000\n",
      "Epoch 10/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 9050457.0000 - val_loss: 9279814.0000\n",
      "Epoch 11/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 9049264.0000 - val_loss: 9278354.0000\n",
      "Epoch 12/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 9048057.0000 - val_loss: 9276989.0000\n",
      "Epoch 13/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 9046884.0000 - val_loss: 9275573.0000\n",
      "Epoch 14/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 9045694.0000 - val_loss: 9274253.0000\n",
      "Epoch 15/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 9044513.0000 - val_loss: 9272801.0000\n",
      "Epoch 16/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 9043323.0000 - val_loss: 9271406.0000\n",
      "Epoch 17/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 9042145.0000 - val_loss: 9270020.0000\n",
      "Epoch 18/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 9040963.0000 - val_loss: 9268664.0000\n",
      "Epoch 19/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 9039786.0000 - val_loss: 9267241.0000\n",
      "Epoch 20/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 9038602.0000 - val_loss: 9265888.0000\n",
      "Epoch 21/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 9037418.0000 - val_loss: 9264489.0000\n",
      "Epoch 22/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 9036249.0000 - val_loss: 9263134.0000\n",
      "Epoch 23/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 9035081.0000 - val_loss: 9261760.0000\n",
      "Epoch 24/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 9033901.0000 - val_loss: 9260376.0000\n",
      "Epoch 25/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 9032738.0000 - val_loss: 9258990.0000\n",
      "Epoch 26/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 9031553.0000 - val_loss: 9257620.0000\n",
      "Epoch 27/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 9030392.0000 - val_loss: 9256230.0000\n",
      "Epoch 28/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 9029215.0000 - val_loss: 9254891.0000\n",
      "Epoch 29/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 9028052.0000 - val_loss: 9253530.0000\n",
      "Epoch 30/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 9026894.0000 - val_loss: 9252143.0000\n",
      "Epoch 31/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 9025721.0000 - val_loss: 9250750.0000\n",
      "Epoch 32/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 9024545.0000 - val_loss: 9249400.0000\n",
      "Epoch 33/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 9023386.0000 - val_loss: 9248018.0000\n",
      "Epoch 34/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 9022228.0000 - val_loss: 9246677.0000\n",
      "Epoch 35/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 9021059.0000 - val_loss: 9245313.0000\n",
      "Epoch 36/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 9019912.0000 - val_loss: 9243984.0000\n",
      "Epoch 37/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 9018748.0000 - val_loss: 9242577.0000\n",
      "Epoch 38/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 9017591.0000 - val_loss: 9241191.0000\n",
      "Epoch 39/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 9016422.0000 - val_loss: 9239868.0000\n",
      "Epoch 40/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 9015269.0000 - val_loss: 9238501.0000\n",
      "Epoch 41/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 9014119.0000 - val_loss: 9237144.0000\n",
      "Epoch 42/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 9012970.0000 - val_loss: 9235808.0000\n",
      "Epoch 43/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 9011824.0000 - val_loss: 9234447.0000\n",
      "Epoch 44/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 9010669.0000 - val_loss: 9233119.0000\n",
      "Epoch 45/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 9009516.0000 - val_loss: 9231748.0000\n",
      "Epoch 46/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 9008364.0000 - val_loss: 9230422.0000\n",
      "Epoch 47/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 9007211.0000 - val_loss: 9229070.0000\n",
      "Epoch 48/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 9006061.0000 - val_loss: 9227686.0000\n",
      "Epoch 49/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 9004906.0000 - val_loss: 9226341.0000\n",
      "Epoch 50/2000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 9003766.0000 - val_loss: 9225002.0000\n",
      "Epoch 51/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 9002633.0000 - val_loss: 9223678.0000\n",
      "Epoch 52/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 9001499.0000 - val_loss: 9222326.0000\n",
      "Epoch 53/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 9000362.0000 - val_loss: 9221004.0000\n",
      "Epoch 54/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8999230.0000 - val_loss: 9219661.0000\n",
      "Epoch 55/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8998087.0000 - val_loss: 9218336.0000\n",
      "Epoch 56/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8996963.0000 - val_loss: 9217030.0000\n",
      "Epoch 57/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8995835.0000 - val_loss: 9215708.0000\n",
      "Epoch 58/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8994705.0000 - val_loss: 9214390.0000\n",
      "Epoch 59/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8993583.0000 - val_loss: 9213078.0000\n",
      "Epoch 60/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8992449.0000 - val_loss: 9211784.0000\n",
      "Epoch 61/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8991314.0000 - val_loss: 9210370.0000\n",
      "Epoch 62/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8990183.0000 - val_loss: 9209094.0000\n",
      "Epoch 63/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8989066.0000 - val_loss: 9207778.0000\n",
      "Epoch 64/2000\n",
      "87/87 [==============================] - 1s 8ms/step - loss: 8987948.0000 - val_loss: 9206492.0000\n",
      "Epoch 65/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 8986819.0000 - val_loss: 9205147.0000\n",
      "Epoch 66/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8985690.0000 - val_loss: 9203812.0000\n",
      "Epoch 67/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8984569.0000 - val_loss: 9202496.0000\n",
      "Epoch 68/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8983455.0000 - val_loss: 9201196.0000\n",
      "Epoch 69/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8982332.0000 - val_loss: 9199907.0000\n",
      "Epoch 70/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8981226.0000 - val_loss: 9198634.0000\n",
      "Epoch 71/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8980097.0000 - val_loss: 9197291.0000\n",
      "Epoch 72/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8978977.0000 - val_loss: 9195962.0000\n",
      "Epoch 73/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8977866.0000 - val_loss: 9194673.0000\n",
      "Epoch 74/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8976753.0000 - val_loss: 9193353.0000\n",
      "Epoch 75/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8975639.0000 - val_loss: 9192068.0000\n",
      "Epoch 76/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8974535.0000 - val_loss: 9190760.0000\n",
      "Epoch 77/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8973420.0000 - val_loss: 9189446.0000\n",
      "Epoch 78/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8972325.0000 - val_loss: 9188129.0000\n",
      "Epoch 79/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8971214.0000 - val_loss: 9186847.0000\n",
      "Epoch 80/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8970124.0000 - val_loss: 9185554.0000\n",
      "Epoch 81/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8969017.0000 - val_loss: 9184284.0000\n",
      "Epoch 82/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8967916.0000 - val_loss: 9183012.0000\n",
      "Epoch 83/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8966829.0000 - val_loss: 9181702.0000\n",
      "Epoch 84/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8965734.0000 - val_loss: 9180464.0000\n",
      "Epoch 85/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8964627.0000 - val_loss: 9179160.0000\n",
      "Epoch 86/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8963514.0000 - val_loss: 9177846.0000\n",
      "Epoch 87/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8962423.0000 - val_loss: 9176536.0000\n",
      "Epoch 88/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8961316.0000 - val_loss: 9175263.0000\n",
      "Epoch 89/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8960221.0000 - val_loss: 9173965.0000\n",
      "Epoch 90/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8959129.0000 - val_loss: 9172703.0000\n",
      "Epoch 91/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8958039.0000 - val_loss: 9171401.0000\n",
      "Epoch 92/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8956943.0000 - val_loss: 9170146.0000\n",
      "Epoch 93/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8955863.0000 - val_loss: 9168849.0000\n",
      "Epoch 94/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8954770.0000 - val_loss: 9167579.0000\n",
      "Epoch 95/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8953678.0000 - val_loss: 9166286.0000\n",
      "Epoch 96/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8952605.0000 - val_loss: 9165037.0000\n",
      "Epoch 97/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8951520.0000 - val_loss: 9163772.0000\n",
      "Epoch 98/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8950433.0000 - val_loss: 9162491.0000\n",
      "Epoch 99/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8949340.0000 - val_loss: 9161219.0000\n",
      "Epoch 100/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8948260.0000 - val_loss: 9159929.0000\n",
      "Epoch 101/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8947167.0000 - val_loss: 9158646.0000\n",
      "Epoch 102/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8946076.0000 - val_loss: 9157394.0000\n",
      "Epoch 103/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8944999.0000 - val_loss: 9156082.0000\n",
      "Epoch 104/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8943909.0000 - val_loss: 9154795.0000\n",
      "Epoch 105/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8942829.0000 - val_loss: 9153591.0000\n",
      "Epoch 106/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8941761.0000 - val_loss: 9152343.0000\n",
      "Epoch 107/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8940687.0000 - val_loss: 9151052.0000\n",
      "Epoch 108/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8939616.0000 - val_loss: 9149796.0000\n",
      "Epoch 109/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8938548.0000 - val_loss: 9148564.0000\n",
      "Epoch 110/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8937457.0000 - val_loss: 9147299.0000\n",
      "Epoch 111/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8936396.0000 - val_loss: 9146024.0000\n",
      "Epoch 112/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8935321.0000 - val_loss: 9144777.0000\n",
      "Epoch 113/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8934251.0000 - val_loss: 9143498.0000\n",
      "Epoch 114/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8933176.0000 - val_loss: 9142253.0000\n",
      "Epoch 115/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8932116.0000 - val_loss: 9141036.0000\n",
      "Epoch 116/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8931061.0000 - val_loss: 9139774.0000\n",
      "Epoch 117/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8930005.0000 - val_loss: 9138587.0000\n",
      "Epoch 118/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8928947.0000 - val_loss: 9137329.0000\n",
      "Epoch 119/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8927884.0000 - val_loss: 9136016.0000\n",
      "Epoch 120/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8926824.0000 - val_loss: 9134806.0000\n",
      "Epoch 121/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8925782.0000 - val_loss: 9133599.0000\n",
      "Epoch 122/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8924731.0000 - val_loss: 9132331.0000\n",
      "Epoch 123/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8923672.0000 - val_loss: 9131130.0000\n",
      "Epoch 124/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8922604.0000 - val_loss: 9129855.0000\n",
      "Epoch 125/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8921564.0000 - val_loss: 9128674.0000\n",
      "Epoch 126/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8920511.0000 - val_loss: 9127429.0000\n",
      "Epoch 127/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8919460.0000 - val_loss: 9126192.0000\n",
      "Epoch 128/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8918405.0000 - val_loss: 9124950.0000\n",
      "Epoch 129/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8917362.0000 - val_loss: 9123741.0000\n",
      "Epoch 130/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8916306.0000 - val_loss: 9122534.0000\n",
      "Epoch 131/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8915271.0000 - val_loss: 9121307.0000\n",
      "Epoch 132/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8914230.0000 - val_loss: 9120081.0000\n",
      "Epoch 133/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8913182.0000 - val_loss: 9118881.0000\n",
      "Epoch 134/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8912142.0000 - val_loss: 9117622.0000\n",
      "Epoch 135/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8911089.0000 - val_loss: 9116401.0000\n",
      "Epoch 136/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8910055.0000 - val_loss: 9115220.0000\n",
      "Epoch 137/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8909002.0000 - val_loss: 9113923.0000\n",
      "Epoch 138/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8907952.0000 - val_loss: 9112731.0000\n",
      "Epoch 139/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8906931.0000 - val_loss: 9111548.0000\n",
      "Epoch 140/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8905901.0000 - val_loss: 9110299.0000\n",
      "Epoch 141/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8904881.0000 - val_loss: 9109120.0000\n",
      "Epoch 142/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8903850.0000 - val_loss: 9107937.0000\n",
      "Epoch 143/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8902826.0000 - val_loss: 9106769.0000\n",
      "Epoch 144/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8901800.0000 - val_loss: 9105538.0000\n",
      "Epoch 145/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8900768.0000 - val_loss: 9104316.0000\n",
      "Epoch 146/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8899737.0000 - val_loss: 9103125.0000\n",
      "Epoch 147/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8898699.0000 - val_loss: 9101897.0000\n",
      "Epoch 148/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8897676.0000 - val_loss: 9100736.0000\n",
      "Epoch 149/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8896652.0000 - val_loss: 9099521.0000\n",
      "Epoch 150/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8895625.0000 - val_loss: 9098309.0000\n",
      "Epoch 151/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8894595.0000 - val_loss: 9097104.0000\n",
      "Epoch 152/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8893565.0000 - val_loss: 9095881.0000\n",
      "Epoch 153/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8892543.0000 - val_loss: 9094689.0000\n",
      "Epoch 154/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8891520.0000 - val_loss: 9093485.0000\n",
      "Epoch 155/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8890500.0000 - val_loss: 9092317.0000\n",
      "Epoch 156/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8889476.0000 - val_loss: 9091082.0000\n",
      "Epoch 157/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8888442.0000 - val_loss: 9089874.0000\n",
      "Epoch 158/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8887420.0000 - val_loss: 9088714.0000\n",
      "Epoch 159/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8886417.0000 - val_loss: 9087495.0000\n",
      "Epoch 160/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8885390.0000 - val_loss: 9086307.0000\n",
      "Epoch 161/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8884356.0000 - val_loss: 9085138.0000\n",
      "Epoch 162/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8883333.0000 - val_loss: 9083928.0000\n",
      "Epoch 163/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8882338.0000 - val_loss: 9082736.0000\n",
      "Epoch 164/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8881334.0000 - val_loss: 9081602.0000\n",
      "Epoch 165/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8880318.0000 - val_loss: 9080396.0000\n",
      "Epoch 166/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8879322.0000 - val_loss: 9079226.0000\n",
      "Epoch 167/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8878313.0000 - val_loss: 9078052.0000\n",
      "Epoch 168/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8877317.0000 - val_loss: 9076858.0000\n",
      "Epoch 169/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8876312.0000 - val_loss: 9075719.0000\n",
      "Epoch 170/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8875318.0000 - val_loss: 9074564.0000\n",
      "Epoch 171/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8874317.0000 - val_loss: 9073378.0000\n",
      "Epoch 172/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8873310.0000 - val_loss: 9072195.0000\n",
      "Epoch 173/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8872304.0000 - val_loss: 9071048.0000\n",
      "Epoch 174/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8871305.0000 - val_loss: 9069860.0000\n",
      "Epoch 175/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8870299.0000 - val_loss: 9068703.0000\n",
      "Epoch 176/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8869289.0000 - val_loss: 9067529.0000\n",
      "Epoch 177/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8868291.0000 - val_loss: 9066338.0000\n",
      "Epoch 178/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8867279.0000 - val_loss: 9065178.0000\n",
      "Epoch 179/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8866291.0000 - val_loss: 9064020.0000\n",
      "Epoch 180/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8865290.0000 - val_loss: 9062833.0000\n",
      "Epoch 181/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8864289.0000 - val_loss: 9061670.0000\n",
      "Epoch 182/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8863289.0000 - val_loss: 9060515.0000\n",
      "Epoch 183/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8862294.0000 - val_loss: 9059391.0000\n",
      "Epoch 184/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8861285.0000 - val_loss: 9058153.0000\n",
      "Epoch 185/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8860300.0000 - val_loss: 9057052.0000\n",
      "Epoch 186/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8859320.0000 - val_loss: 9055902.0000\n",
      "Epoch 187/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8858325.0000 - val_loss: 9054718.0000\n",
      "Epoch 188/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8857337.0000 - val_loss: 9053586.0000\n",
      "Epoch 189/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8856341.0000 - val_loss: 9052427.0000\n",
      "Epoch 190/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8855356.0000 - val_loss: 9051224.0000\n",
      "Epoch 191/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8854361.0000 - val_loss: 9050083.0000\n",
      "Epoch 192/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8853384.0000 - val_loss: 9048965.0000\n",
      "Epoch 193/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8852398.0000 - val_loss: 9047770.0000\n",
      "Epoch 194/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8851405.0000 - val_loss: 9046669.0000\n",
      "Epoch 195/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8850422.0000 - val_loss: 9045475.0000\n",
      "Epoch 196/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8849436.0000 - val_loss: 9044382.0000\n",
      "Epoch 197/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8848463.0000 - val_loss: 9043199.0000\n",
      "Epoch 198/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8847479.0000 - val_loss: 9042038.0000\n",
      "Epoch 199/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8846499.0000 - val_loss: 9040930.0000\n",
      "Epoch 200/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8845528.0000 - val_loss: 9039789.0000\n",
      "Epoch 201/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8844553.0000 - val_loss: 9038625.0000\n",
      "Epoch 202/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8843581.0000 - val_loss: 9037538.0000\n",
      "Epoch 203/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8842598.0000 - val_loss: 9036362.0000\n",
      "Epoch 204/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8841615.0000 - val_loss: 9035214.0000\n",
      "Epoch 205/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8840643.0000 - val_loss: 9034104.0000\n",
      "Epoch 206/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8839668.0000 - val_loss: 9032931.0000\n",
      "Epoch 207/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8838682.0000 - val_loss: 9031794.0000\n",
      "Epoch 208/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8837711.0000 - val_loss: 9030655.0000\n",
      "Epoch 209/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8836739.0000 - val_loss: 9029500.0000\n",
      "Epoch 210/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8835757.0000 - val_loss: 9028366.0000\n",
      "Epoch 211/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8834779.0000 - val_loss: 9027204.0000\n",
      "Epoch 212/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8833809.0000 - val_loss: 9026098.0000\n",
      "Epoch 213/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8832847.0000 - val_loss: 9024980.0000\n",
      "Epoch 214/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8831878.0000 - val_loss: 9023824.0000\n",
      "Epoch 215/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8830922.0000 - val_loss: 9022688.0000\n",
      "Epoch 216/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8829959.0000 - val_loss: 9021598.0000\n",
      "Epoch 217/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8828994.0000 - val_loss: 9020452.0000\n",
      "Epoch 218/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8828031.0000 - val_loss: 9019349.0000\n",
      "Epoch 219/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8827072.0000 - val_loss: 9018244.0000\n",
      "Epoch 220/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8826117.0000 - val_loss: 9017118.0000\n",
      "Epoch 221/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8825162.0000 - val_loss: 9016011.0000\n",
      "Epoch 222/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8824194.0000 - val_loss: 9014871.0000\n",
      "Epoch 223/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8823235.0000 - val_loss: 9013756.0000\n",
      "Epoch 224/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8822282.0000 - val_loss: 9012673.0000\n",
      "Epoch 225/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8821318.0000 - val_loss: 9011539.0000\n",
      "Epoch 226/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8820363.0000 - val_loss: 9010411.0000\n",
      "Epoch 227/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8819412.0000 - val_loss: 9009313.0000\n",
      "Epoch 228/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8818461.0000 - val_loss: 9008191.0000\n",
      "Epoch 229/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8817496.0000 - val_loss: 9007104.0000\n",
      "Epoch 230/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8816542.0000 - val_loss: 9005956.0000\n",
      "Epoch 231/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8815583.0000 - val_loss: 9004810.0000\n",
      "Epoch 232/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8814637.0000 - val_loss: 9003769.0000\n",
      "Epoch 233/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8813684.0000 - val_loss: 9002648.0000\n",
      "Epoch 234/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8812749.0000 - val_loss: 9001553.0000\n",
      "Epoch 235/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8811802.0000 - val_loss: 9000442.0000\n",
      "Epoch 236/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8810851.0000 - val_loss: 8999339.0000\n",
      "Epoch 237/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8809907.0000 - val_loss: 8998249.0000\n",
      "Epoch 238/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8808963.0000 - val_loss: 8997131.0000\n",
      "Epoch 239/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8808019.0000 - val_loss: 8996007.0000\n",
      "Epoch 240/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8807081.0000 - val_loss: 8994937.0000\n",
      "Epoch 241/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8806144.0000 - val_loss: 8993864.0000\n",
      "Epoch 242/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8805209.0000 - val_loss: 8992744.0000\n",
      "Epoch 243/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8804260.0000 - val_loss: 8991632.0000\n",
      "Epoch 244/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8803316.0000 - val_loss: 8990512.0000\n",
      "Epoch 245/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8802365.0000 - val_loss: 8989438.0000\n",
      "Epoch 246/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8801421.0000 - val_loss: 8988306.0000\n",
      "Epoch 247/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8800486.0000 - val_loss: 8987205.0000\n",
      "Epoch 248/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8799548.0000 - val_loss: 8986128.0000\n",
      "Epoch 249/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8798614.0000 - val_loss: 8985049.0000\n",
      "Epoch 250/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8797682.0000 - val_loss: 8983969.0000\n",
      "Epoch 251/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8796749.0000 - val_loss: 8982836.0000\n",
      "Epoch 252/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8795811.0000 - val_loss: 8981787.0000\n",
      "Epoch 253/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8794874.0000 - val_loss: 8980717.0000\n",
      "Epoch 254/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8793939.0000 - val_loss: 8979614.0000\n",
      "Epoch 255/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8793000.0000 - val_loss: 8978510.0000\n",
      "Epoch 256/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8792069.0000 - val_loss: 8977407.0000\n",
      "Epoch 257/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8791136.0000 - val_loss: 8976333.0000\n",
      "Epoch 258/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8790199.0000 - val_loss: 8975250.0000\n",
      "Epoch 259/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8789277.0000 - val_loss: 8974164.0000\n",
      "Epoch 260/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8788350.0000 - val_loss: 8973098.0000\n",
      "Epoch 261/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8787434.0000 - val_loss: 8972042.0000\n",
      "Epoch 262/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8786488.0000 - val_loss: 8970932.0000\n",
      "Epoch 263/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8785555.0000 - val_loss: 8969853.0000\n",
      "Epoch 264/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8784624.0000 - val_loss: 8968753.0000\n",
      "Epoch 265/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8783690.0000 - val_loss: 8967687.0000\n",
      "Epoch 266/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8782767.0000 - val_loss: 8966578.0000\n",
      "Epoch 267/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8781837.0000 - val_loss: 8965495.0000\n",
      "Epoch 268/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8780909.0000 - val_loss: 8964407.0000\n",
      "Epoch 269/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8779995.0000 - val_loss: 8963339.0000\n",
      "Epoch 270/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8779074.0000 - val_loss: 8962268.0000\n",
      "Epoch 271/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8778155.0000 - val_loss: 8961215.0000\n",
      "Epoch 272/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8777234.0000 - val_loss: 8960162.0000\n",
      "Epoch 273/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8776328.0000 - val_loss: 8959077.0000\n",
      "Epoch 274/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8775416.0000 - val_loss: 8958028.0000\n",
      "Epoch 275/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8774509.0000 - val_loss: 8956978.0000\n",
      "Epoch 276/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8773584.0000 - val_loss: 8955911.0000\n",
      "Epoch 277/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8772684.0000 - val_loss: 8954868.0000\n",
      "Epoch 278/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8771777.0000 - val_loss: 8953791.0000\n",
      "Epoch 279/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8770873.0000 - val_loss: 8952747.0000\n",
      "Epoch 280/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8769953.0000 - val_loss: 8951694.0000\n",
      "Epoch 281/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8769045.0000 - val_loss: 8950632.0000\n",
      "Epoch 282/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8768137.0000 - val_loss: 8949594.0000\n",
      "Epoch 283/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8767234.0000 - val_loss: 8948541.0000\n",
      "Epoch 284/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8766333.0000 - val_loss: 8947491.0000\n",
      "Epoch 285/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8765424.0000 - val_loss: 8946435.0000\n",
      "Epoch 286/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8764508.0000 - val_loss: 8945378.0000\n",
      "Epoch 287/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8763594.0000 - val_loss: 8944330.0000\n",
      "Epoch 288/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8762688.0000 - val_loss: 8943248.0000\n",
      "Epoch 289/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8761777.0000 - val_loss: 8942216.0000\n",
      "Epoch 290/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8760867.0000 - val_loss: 8941140.0000\n",
      "Epoch 291/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8759949.0000 - val_loss: 8940102.0000\n",
      "Epoch 292/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8759034.0000 - val_loss: 8939001.0000\n",
      "Epoch 293/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8758128.0000 - val_loss: 8937948.0000\n",
      "Epoch 294/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8757234.0000 - val_loss: 8936930.0000\n",
      "Epoch 295/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8756332.0000 - val_loss: 8935895.0000\n",
      "Epoch 296/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8755447.0000 - val_loss: 8934843.0000\n",
      "Epoch 297/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8754558.0000 - val_loss: 8933811.0000\n",
      "Epoch 298/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8753665.0000 - val_loss: 8932794.0000\n",
      "Epoch 299/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8752770.0000 - val_loss: 8931742.0000\n",
      "Epoch 300/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8751875.0000 - val_loss: 8930688.0000\n",
      "Epoch 301/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8750991.0000 - val_loss: 8929700.0000\n",
      "Epoch 302/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8750096.0000 - val_loss: 8928616.0000\n",
      "Epoch 303/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8749198.0000 - val_loss: 8927611.0000\n",
      "Epoch 304/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8748307.0000 - val_loss: 8926529.0000\n",
      "Epoch 305/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8747406.0000 - val_loss: 8925540.0000\n",
      "Epoch 306/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8746516.0000 - val_loss: 8924487.0000\n",
      "Epoch 307/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8745628.0000 - val_loss: 8923469.0000\n",
      "Epoch 308/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8744735.0000 - val_loss: 8922445.0000\n",
      "Epoch 309/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8743843.0000 - val_loss: 8921423.0000\n",
      "Epoch 310/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8742941.0000 - val_loss: 8920338.0000\n",
      "Epoch 311/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8742050.0000 - val_loss: 8919303.0000\n",
      "Epoch 312/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8741159.0000 - val_loss: 8918276.0000\n",
      "Epoch 313/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8740270.0000 - val_loss: 8917235.0000\n",
      "Epoch 314/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8739387.0000 - val_loss: 8916220.0000\n",
      "Epoch 315/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8738508.0000 - val_loss: 8915179.0000\n",
      "Epoch 316/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8737625.0000 - val_loss: 8914158.0000\n",
      "Epoch 317/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8736744.0000 - val_loss: 8913152.0000\n",
      "Epoch 318/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8735862.0000 - val_loss: 8912137.0000\n",
      "Epoch 319/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8734967.0000 - val_loss: 8911088.0000\n",
      "Epoch 320/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8734084.0000 - val_loss: 8910070.0000\n",
      "Epoch 321/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8733204.0000 - val_loss: 8909066.0000\n",
      "Epoch 322/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8732321.0000 - val_loss: 8908012.0000\n",
      "Epoch 323/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8731442.0000 - val_loss: 8907040.0000\n",
      "Epoch 324/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8730565.0000 - val_loss: 8905969.0000\n",
      "Epoch 325/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8729679.0000 - val_loss: 8904991.0000\n",
      "Epoch 326/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8728794.0000 - val_loss: 8903940.0000\n",
      "Epoch 327/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8727914.0000 - val_loss: 8902918.0000\n",
      "Epoch 328/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8727036.0000 - val_loss: 8901904.0000\n",
      "Epoch 329/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8726169.0000 - val_loss: 8900873.0000\n",
      "Epoch 330/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8725293.0000 - val_loss: 8899910.0000\n",
      "Epoch 331/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8724430.0000 - val_loss: 8898903.0000\n",
      "Epoch 332/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8723557.0000 - val_loss: 8897898.0000\n",
      "Epoch 333/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8722687.0000 - val_loss: 8896856.0000\n",
      "Epoch 334/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8721813.0000 - val_loss: 8895871.0000\n",
      "Epoch 335/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8720953.0000 - val_loss: 8894912.0000\n",
      "Epoch 336/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8720079.0000 - val_loss: 8893851.0000\n",
      "Epoch 337/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8719216.0000 - val_loss: 8892851.0000\n",
      "Epoch 338/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8718334.0000 - val_loss: 8891846.0000\n",
      "Epoch 339/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8717463.0000 - val_loss: 8890871.0000\n",
      "Epoch 340/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8716604.0000 - val_loss: 8889880.0000\n",
      "Epoch 341/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8715736.0000 - val_loss: 8888862.0000\n",
      "Epoch 342/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8714865.0000 - val_loss: 8887826.0000\n",
      "Epoch 343/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8713998.0000 - val_loss: 8886813.0000\n",
      "Epoch 344/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8713138.0000 - val_loss: 8885815.0000\n",
      "Epoch 345/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8712265.0000 - val_loss: 8884832.0000\n",
      "Epoch 346/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8711403.0000 - val_loss: 8883844.0000\n",
      "Epoch 347/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8710543.0000 - val_loss: 8882863.0000\n",
      "Epoch 348/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8709689.0000 - val_loss: 8881842.0000\n",
      "Epoch 349/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8708818.0000 - val_loss: 8880865.0000\n",
      "Epoch 350/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8707953.0000 - val_loss: 8879872.0000\n",
      "Epoch 351/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8707096.0000 - val_loss: 8878887.0000\n",
      "Epoch 352/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8706238.0000 - val_loss: 8877837.0000\n",
      "Epoch 353/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8705377.0000 - val_loss: 8876873.0000\n",
      "Epoch 354/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8704525.0000 - val_loss: 8875917.0000\n",
      "Epoch 355/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8703659.0000 - val_loss: 8874883.0000\n",
      "Epoch 356/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8702792.0000 - val_loss: 8873872.0000\n",
      "Epoch 357/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8701939.0000 - val_loss: 8872915.0000\n",
      "Epoch 358/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8701091.0000 - val_loss: 8871937.0000\n",
      "Epoch 359/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8700238.0000 - val_loss: 8870951.0000\n",
      "Epoch 360/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8699385.0000 - val_loss: 8869970.0000\n",
      "Epoch 361/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8698530.0000 - val_loss: 8868988.0000\n",
      "Epoch 362/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8697671.0000 - val_loss: 8868012.0000\n",
      "Epoch 363/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8696822.0000 - val_loss: 8867004.0000\n",
      "Epoch 364/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8695978.0000 - val_loss: 8866043.0000\n",
      "Epoch 365/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8695124.0000 - val_loss: 8865047.0000\n",
      "Epoch 366/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8694273.0000 - val_loss: 8864034.0000\n",
      "Epoch 367/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8693431.0000 - val_loss: 8863082.0000\n",
      "Epoch 368/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8692598.0000 - val_loss: 8862135.0000\n",
      "Epoch 369/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8691758.0000 - val_loss: 8861156.0000\n",
      "Epoch 370/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8690918.0000 - val_loss: 8860195.0000\n",
      "Epoch 371/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8690081.0000 - val_loss: 8859237.0000\n",
      "Epoch 372/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8689235.0000 - val_loss: 8858257.0000\n",
      "Epoch 373/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8688381.0000 - val_loss: 8857264.0000\n",
      "Epoch 374/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8687543.0000 - val_loss: 8856318.0000\n",
      "Epoch 375/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8686724.0000 - val_loss: 8855364.0000\n",
      "Epoch 376/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8685885.0000 - val_loss: 8854410.0000\n",
      "Epoch 377/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8685049.0000 - val_loss: 8853451.0000\n",
      "Epoch 378/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8684206.0000 - val_loss: 8852518.0000\n",
      "Epoch 379/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8683380.0000 - val_loss: 8851497.0000\n",
      "Epoch 380/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8682532.0000 - val_loss: 8850548.0000\n",
      "Epoch 381/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8681700.0000 - val_loss: 8849574.0000\n",
      "Epoch 382/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8680862.0000 - val_loss: 8848676.0000\n",
      "Epoch 383/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8680024.0000 - val_loss: 8847637.0000\n",
      "Epoch 384/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8679184.0000 - val_loss: 8846676.0000\n",
      "Epoch 385/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8678350.0000 - val_loss: 8845737.0000\n",
      "Epoch 386/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8677504.0000 - val_loss: 8844765.0000\n",
      "Epoch 387/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8676662.0000 - val_loss: 8843806.0000\n",
      "Epoch 388/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8675825.0000 - val_loss: 8842853.0000\n",
      "Epoch 389/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8674992.0000 - val_loss: 8841896.0000\n",
      "Epoch 390/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8674151.0000 - val_loss: 8840902.0000\n",
      "Epoch 391/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8673315.0000 - val_loss: 8839954.0000\n",
      "Epoch 392/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8672486.0000 - val_loss: 8839000.0000\n",
      "Epoch 393/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8671650.0000 - val_loss: 8838041.0000\n",
      "Epoch 394/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8670814.0000 - val_loss: 8837064.0000\n",
      "Epoch 395/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8669972.0000 - val_loss: 8836128.0000\n",
      "Epoch 396/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8669137.0000 - val_loss: 8835145.0000\n",
      "Epoch 397/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8668299.0000 - val_loss: 8834196.0000\n",
      "Epoch 398/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8667475.0000 - val_loss: 8833242.0000\n",
      "Epoch 399/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8666645.0000 - val_loss: 8832276.0000\n",
      "Epoch 400/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8665819.0000 - val_loss: 8831314.0000\n",
      "Epoch 401/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8664989.0000 - val_loss: 8830376.0000\n",
      "Epoch 402/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8664165.0000 - val_loss: 8829376.0000\n",
      "Epoch 403/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8663331.0000 - val_loss: 8828471.0000\n",
      "Epoch 404/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8662505.0000 - val_loss: 8827543.0000\n",
      "Epoch 405/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8661674.0000 - val_loss: 8826544.0000\n",
      "Epoch 406/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8660848.0000 - val_loss: 8825608.0000\n",
      "Epoch 407/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8660024.0000 - val_loss: 8824660.0000\n",
      "Epoch 408/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8659197.0000 - val_loss: 8823716.0000\n",
      "Epoch 409/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8658377.0000 - val_loss: 8822770.0000\n",
      "Epoch 410/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8657557.0000 - val_loss: 8821819.0000\n",
      "Epoch 411/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8656743.0000 - val_loss: 8820880.0000\n",
      "Epoch 412/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8655920.0000 - val_loss: 8819956.0000\n",
      "Epoch 413/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8655107.0000 - val_loss: 8819020.0000\n",
      "Epoch 414/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8654290.0000 - val_loss: 8818070.0000\n",
      "Epoch 415/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8653475.0000 - val_loss: 8817169.0000\n",
      "Epoch 416/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8652643.0000 - val_loss: 8816182.0000\n",
      "Epoch 417/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8651835.0000 - val_loss: 8815245.0000\n",
      "Epoch 418/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8651022.0000 - val_loss: 8814315.0000\n",
      "Epoch 419/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8650210.0000 - val_loss: 8813405.0000\n",
      "Epoch 420/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8649387.0000 - val_loss: 8812432.0000\n",
      "Epoch 421/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8648565.0000 - val_loss: 8811489.0000\n",
      "Epoch 422/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8647749.0000 - val_loss: 8810573.0000\n",
      "Epoch 423/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8646931.0000 - val_loss: 8809611.0000\n",
      "Epoch 424/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8646120.0000 - val_loss: 8808697.0000\n",
      "Epoch 425/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8645310.0000 - val_loss: 8807788.0000\n",
      "Epoch 426/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8644509.0000 - val_loss: 8806886.0000\n",
      "Epoch 427/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8643695.0000 - val_loss: 8805858.0000\n",
      "Epoch 428/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8642867.0000 - val_loss: 8804990.0000\n",
      "Epoch 429/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8642065.0000 - val_loss: 8804018.0000\n",
      "Epoch 430/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8641257.0000 - val_loss: 8803119.0000\n",
      "Epoch 431/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8640449.0000 - val_loss: 8802166.0000\n",
      "Epoch 432/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8639650.0000 - val_loss: 8801253.0000\n",
      "Epoch 433/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8638849.0000 - val_loss: 8800360.0000\n",
      "Epoch 434/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8638042.0000 - val_loss: 8799458.0000\n",
      "Epoch 435/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8637235.0000 - val_loss: 8798500.0000\n",
      "Epoch 436/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8636431.0000 - val_loss: 8797567.0000\n",
      "Epoch 437/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8635617.0000 - val_loss: 8796666.0000\n",
      "Epoch 438/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8634817.0000 - val_loss: 8795754.0000\n",
      "Epoch 439/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8634020.0000 - val_loss: 8794820.0000\n",
      "Epoch 440/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8633208.0000 - val_loss: 8793909.0000\n",
      "Epoch 441/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8632415.0000 - val_loss: 8792984.0000\n",
      "Epoch 442/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8631612.0000 - val_loss: 8792074.0000\n",
      "Epoch 443/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8630808.0000 - val_loss: 8791127.0000\n",
      "Epoch 444/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8629998.0000 - val_loss: 8790234.0000\n",
      "Epoch 445/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8629208.0000 - val_loss: 8789306.0000\n",
      "Epoch 446/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8628398.0000 - val_loss: 8788432.0000\n",
      "Epoch 447/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8627599.0000 - val_loss: 8787471.0000\n",
      "Epoch 448/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8626791.0000 - val_loss: 8786560.0000\n",
      "Epoch 449/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8625989.0000 - val_loss: 8785637.0000\n",
      "Epoch 450/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8625181.0000 - val_loss: 8784763.0000\n",
      "Epoch 451/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8624384.0000 - val_loss: 8783808.0000\n",
      "Epoch 452/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8623582.0000 - val_loss: 8782924.0000\n",
      "Epoch 453/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8622785.0000 - val_loss: 8782013.0000\n",
      "Epoch 454/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8621982.0000 - val_loss: 8781046.0000\n",
      "Epoch 455/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8621180.0000 - val_loss: 8780145.0000\n",
      "Epoch 456/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8620377.0000 - val_loss: 8779241.0000\n",
      "Epoch 457/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8619585.0000 - val_loss: 8778343.0000\n",
      "Epoch 458/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8618783.0000 - val_loss: 8777386.0000\n",
      "Epoch 459/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8617989.0000 - val_loss: 8776466.0000\n",
      "Epoch 460/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8617185.0000 - val_loss: 8775568.0000\n",
      "Epoch 461/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8616398.0000 - val_loss: 8774641.0000\n",
      "Epoch 462/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8615597.0000 - val_loss: 8773783.0000\n",
      "Epoch 463/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8614805.0000 - val_loss: 8772813.0000\n",
      "Epoch 464/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8614010.0000 - val_loss: 8771952.0000\n",
      "Epoch 465/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8613216.0000 - val_loss: 8771048.0000\n",
      "Epoch 466/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8612429.0000 - val_loss: 8770118.0000\n",
      "Epoch 467/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8611639.0000 - val_loss: 8769234.0000\n",
      "Epoch 468/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8610849.0000 - val_loss: 8768335.0000\n",
      "Epoch 469/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8610056.0000 - val_loss: 8767421.0000\n",
      "Epoch 470/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8609271.0000 - val_loss: 8766545.0000\n",
      "Epoch 471/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8608483.0000 - val_loss: 8765610.0000\n",
      "Epoch 472/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8607693.0000 - val_loss: 8764746.0000\n",
      "Epoch 473/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8606899.0000 - val_loss: 8763854.0000\n",
      "Epoch 474/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8606109.0000 - val_loss: 8762953.0000\n",
      "Epoch 475/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8605323.0000 - val_loss: 8762051.0000\n",
      "Epoch 476/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8604539.0000 - val_loss: 8761102.0000\n",
      "Epoch 477/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8603744.0000 - val_loss: 8760234.0000\n",
      "Epoch 478/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8602957.0000 - val_loss: 8759290.0000\n",
      "Epoch 479/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8602168.0000 - val_loss: 8758397.0000\n",
      "Epoch 480/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8601386.0000 - val_loss: 8757539.0000\n",
      "Epoch 481/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8600603.0000 - val_loss: 8756635.0000\n",
      "Epoch 482/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8599821.0000 - val_loss: 8755740.0000\n",
      "Epoch 483/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8599046.0000 - val_loss: 8754839.0000\n",
      "Epoch 484/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8598266.0000 - val_loss: 8753998.0000\n",
      "Epoch 485/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8597477.0000 - val_loss: 8753097.0000\n",
      "Epoch 486/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8596696.0000 - val_loss: 8752205.0000\n",
      "Epoch 487/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8595903.0000 - val_loss: 8751289.0000\n",
      "Epoch 488/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8595122.0000 - val_loss: 8750363.0000\n",
      "Epoch 489/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8594337.0000 - val_loss: 8749527.0000\n",
      "Epoch 490/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8593569.0000 - val_loss: 8748635.0000\n",
      "Epoch 491/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8592791.0000 - val_loss: 8747735.0000\n",
      "Epoch 492/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8592011.0000 - val_loss: 8746883.0000\n",
      "Epoch 493/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8591239.0000 - val_loss: 8745944.0000\n",
      "Epoch 494/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8590463.0000 - val_loss: 8745067.0000\n",
      "Epoch 495/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8589681.0000 - val_loss: 8744212.0000\n",
      "Epoch 496/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8588902.0000 - val_loss: 8743295.0000\n",
      "Epoch 497/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8588115.0000 - val_loss: 8742433.0000\n",
      "Epoch 498/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8587346.0000 - val_loss: 8741555.0000\n",
      "Epoch 499/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8586567.0000 - val_loss: 8740704.0000\n",
      "Epoch 500/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8585789.0000 - val_loss: 8739792.0000\n",
      "Epoch 501/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8585014.0000 - val_loss: 8738880.0000\n",
      "Epoch 502/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8584239.0000 - val_loss: 8738007.0000\n",
      "Epoch 503/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8583473.0000 - val_loss: 8737112.0000\n",
      "Epoch 504/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8582703.0000 - val_loss: 8736268.0000\n",
      "Epoch 505/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8581928.0000 - val_loss: 8735418.0000\n",
      "Epoch 506/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8581161.0000 - val_loss: 8734523.0000\n",
      "Epoch 507/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8580386.0000 - val_loss: 8733632.0000\n",
      "Epoch 508/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8579617.0000 - val_loss: 8732799.0000\n",
      "Epoch 509/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8578852.0000 - val_loss: 8731901.0000\n",
      "Epoch 510/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8578082.0000 - val_loss: 8731055.0000\n",
      "Epoch 511/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8577318.0000 - val_loss: 8730162.0000\n",
      "Epoch 512/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8576548.0000 - val_loss: 8729274.0000\n",
      "Epoch 513/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8575787.0000 - val_loss: 8728446.0000\n",
      "Epoch 514/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8575025.0000 - val_loss: 8727536.0000\n",
      "Epoch 515/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8574262.0000 - val_loss: 8726723.0000\n",
      "Epoch 516/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8573497.0000 - val_loss: 8725892.0000\n",
      "Epoch 517/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8572732.0000 - val_loss: 8724971.0000\n",
      "Epoch 518/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8571978.0000 - val_loss: 8724082.0000\n",
      "Epoch 519/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8571212.0000 - val_loss: 8723230.0000\n",
      "Epoch 520/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8570447.0000 - val_loss: 8722393.0000\n",
      "Epoch 521/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8569686.0000 - val_loss: 8721536.0000\n",
      "Epoch 522/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8568916.0000 - val_loss: 8720643.0000\n",
      "Epoch 523/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8568147.0000 - val_loss: 8719752.0000\n",
      "Epoch 524/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8567378.0000 - val_loss: 8718884.0000\n",
      "Epoch 525/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8566631.0000 - val_loss: 8718026.0000\n",
      "Epoch 526/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8565854.0000 - val_loss: 8717171.0000\n",
      "Epoch 527/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8565092.0000 - val_loss: 8716302.0000\n",
      "Epoch 528/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8564339.0000 - val_loss: 8715464.0000\n",
      "Epoch 529/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8563579.0000 - val_loss: 8714603.0000\n",
      "Epoch 530/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8562817.0000 - val_loss: 8713738.0000\n",
      "Epoch 531/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8562058.0000 - val_loss: 8712818.0000\n",
      "Epoch 532/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8561285.0000 - val_loss: 8711946.0000\n",
      "Epoch 533/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8560525.0000 - val_loss: 8711131.0000\n",
      "Epoch 534/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8559766.0000 - val_loss: 8710279.0000\n",
      "Epoch 535/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8559028.0000 - val_loss: 8709420.0000\n",
      "Epoch 536/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8558269.0000 - val_loss: 8708578.0000\n",
      "Epoch 537/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8557512.0000 - val_loss: 8707731.0000\n",
      "Epoch 538/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8556763.0000 - val_loss: 8706864.0000\n",
      "Epoch 539/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8555999.0000 - val_loss: 8706033.0000\n",
      "Epoch 540/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8555245.0000 - val_loss: 8705161.0000\n",
      "Epoch 541/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8554491.0000 - val_loss: 8704289.0000\n",
      "Epoch 542/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8553739.0000 - val_loss: 8703459.0000\n",
      "Epoch 543/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8552999.0000 - val_loss: 8702588.0000\n",
      "Epoch 544/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8552238.0000 - val_loss: 8701751.0000\n",
      "Epoch 545/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8551487.0000 - val_loss: 8700938.0000\n",
      "Epoch 546/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8550736.0000 - val_loss: 8700084.0000\n",
      "Epoch 547/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8549990.0000 - val_loss: 8699225.0000\n",
      "Epoch 548/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8549240.0000 - val_loss: 8698378.0000\n",
      "Epoch 549/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8548491.0000 - val_loss: 8697514.0000\n",
      "Epoch 550/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8547740.0000 - val_loss: 8696656.0000\n",
      "Epoch 551/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8546984.0000 - val_loss: 8695849.0000\n",
      "Epoch 552/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8546238.0000 - val_loss: 8694987.0000\n",
      "Epoch 553/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8545483.0000 - val_loss: 8694121.0000\n",
      "Epoch 554/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8544733.0000 - val_loss: 8693273.0000\n",
      "Epoch 555/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8543983.0000 - val_loss: 8692462.0000\n",
      "Epoch 556/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8543244.0000 - val_loss: 8691576.0000\n",
      "Epoch 557/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8542498.0000 - val_loss: 8690757.0000\n",
      "Epoch 558/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8541747.0000 - val_loss: 8689915.0000\n",
      "Epoch 559/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8541005.0000 - val_loss: 8689095.0000\n",
      "Epoch 560/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8540256.0000 - val_loss: 8688241.0000\n",
      "Epoch 561/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8539517.0000 - val_loss: 8687371.0000\n",
      "Epoch 562/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8538767.0000 - val_loss: 8686545.0000\n",
      "Epoch 563/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8538015.0000 - val_loss: 8685706.0000\n",
      "Epoch 564/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8537272.0000 - val_loss: 8684856.0000\n",
      "Epoch 565/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8536535.0000 - val_loss: 8684004.0000\n",
      "Epoch 566/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8535782.0000 - val_loss: 8683186.0000\n",
      "Epoch 567/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8535045.0000 - val_loss: 8682364.0000\n",
      "Epoch 568/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8534309.0000 - val_loss: 8681516.0000\n",
      "Epoch 569/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8533567.0000 - val_loss: 8680705.0000\n",
      "Epoch 570/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8532827.0000 - val_loss: 8679871.0000\n",
      "Epoch 571/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8532083.0000 - val_loss: 8679028.0000\n",
      "Epoch 572/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8531343.0000 - val_loss: 8678216.0000\n",
      "Epoch 573/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8530607.0000 - val_loss: 8677355.0000\n",
      "Epoch 574/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8529861.0000 - val_loss: 8676538.0000\n",
      "Epoch 575/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8529118.0000 - val_loss: 8675685.0000\n",
      "Epoch 576/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8528380.0000 - val_loss: 8674809.0000\n",
      "Epoch 577/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8527640.0000 - val_loss: 8673996.0000\n",
      "Epoch 578/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8526895.0000 - val_loss: 8673174.0000\n",
      "Epoch 579/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8526158.0000 - val_loss: 8672334.0000\n",
      "Epoch 580/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8525431.0000 - val_loss: 8671509.0000\n",
      "Epoch 581/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8524688.0000 - val_loss: 8670676.0000\n",
      "Epoch 582/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8523952.0000 - val_loss: 8669868.0000\n",
      "Epoch 583/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8523210.0000 - val_loss: 8669005.0000\n",
      "Epoch 584/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8522467.0000 - val_loss: 8668176.0000\n",
      "Epoch 585/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8521731.0000 - val_loss: 8667362.0000\n",
      "Epoch 586/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8520994.0000 - val_loss: 8666512.0000\n",
      "Epoch 587/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8520248.0000 - val_loss: 8665657.0000\n",
      "Epoch 588/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8519516.0000 - val_loss: 8664859.0000\n",
      "Epoch 589/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8518774.0000 - val_loss: 8664006.0000\n",
      "Epoch 590/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8518040.0000 - val_loss: 8663179.0000\n",
      "Epoch 591/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8517302.0000 - val_loss: 8662376.0000\n",
      "Epoch 592/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8516564.0000 - val_loss: 8661530.0000\n",
      "Epoch 593/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8515831.0000 - val_loss: 8660709.0000\n",
      "Epoch 594/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8515095.0000 - val_loss: 8659892.0000\n",
      "Epoch 595/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8514350.0000 - val_loss: 8659049.0000\n",
      "Epoch 596/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8513621.0000 - val_loss: 8658215.0000\n",
      "Epoch 597/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8512896.0000 - val_loss: 8657415.0000\n",
      "Epoch 598/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8512170.0000 - val_loss: 8656613.0000\n",
      "Epoch 599/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8511442.0000 - val_loss: 8655770.0000\n",
      "Epoch 600/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8510705.0000 - val_loss: 8654940.0000\n",
      "Epoch 601/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8509972.0000 - val_loss: 8654134.0000\n",
      "Epoch 602/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8509254.0000 - val_loss: 8653326.0000\n",
      "Epoch 603/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8508524.0000 - val_loss: 8652500.0000\n",
      "Epoch 604/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8507793.0000 - val_loss: 8651709.0000\n",
      "Epoch 605/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8507071.0000 - val_loss: 8650874.0000\n",
      "Epoch 606/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8506344.0000 - val_loss: 8650059.0000\n",
      "Epoch 607/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8505614.0000 - val_loss: 8649254.0000\n",
      "Epoch 608/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8504888.0000 - val_loss: 8648392.0000\n",
      "Epoch 609/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8504153.0000 - val_loss: 8647610.0000\n",
      "Epoch 610/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8503433.0000 - val_loss: 8646807.0000\n",
      "Epoch 611/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8502699.0000 - val_loss: 8645975.0000\n",
      "Epoch 612/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8501973.0000 - val_loss: 8645152.0000\n",
      "Epoch 613/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8501247.0000 - val_loss: 8644355.0000\n",
      "Epoch 614/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8500534.0000 - val_loss: 8643548.0000\n",
      "Epoch 615/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8499811.0000 - val_loss: 8642746.0000\n",
      "Epoch 616/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8499092.0000 - val_loss: 8641926.0000\n",
      "Epoch 617/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8498361.0000 - val_loss: 8641145.0000\n",
      "Epoch 618/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8497642.0000 - val_loss: 8640307.0000\n",
      "Epoch 619/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8496911.0000 - val_loss: 8639489.0000\n",
      "Epoch 620/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8496185.0000 - val_loss: 8638668.0000\n",
      "Epoch 621/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8495467.0000 - val_loss: 8637868.0000\n",
      "Epoch 622/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8494745.0000 - val_loss: 8637069.0000\n",
      "Epoch 623/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8494027.0000 - val_loss: 8636275.0000\n",
      "Epoch 624/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8493301.0000 - val_loss: 8635454.0000\n",
      "Epoch 625/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8492577.0000 - val_loss: 8634660.0000\n",
      "Epoch 626/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8491865.0000 - val_loss: 8633856.0000\n",
      "Epoch 627/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8491142.0000 - val_loss: 8633062.0000\n",
      "Epoch 628/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8490426.0000 - val_loss: 8632237.0000\n",
      "Epoch 629/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8489700.0000 - val_loss: 8631452.0000\n",
      "Epoch 630/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8488984.0000 - val_loss: 8630652.0000\n",
      "Epoch 631/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8488262.0000 - val_loss: 8629818.0000\n",
      "Epoch 632/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8487550.0000 - val_loss: 8629003.0000\n",
      "Epoch 633/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8486826.0000 - val_loss: 8628238.0000\n",
      "Epoch 634/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8486112.0000 - val_loss: 8627448.0000\n",
      "Epoch 635/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8485392.0000 - val_loss: 8626633.0000\n",
      "Epoch 636/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8484677.0000 - val_loss: 8625829.0000\n",
      "Epoch 637/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8483964.0000 - val_loss: 8625008.0000\n",
      "Epoch 638/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8483244.0000 - val_loss: 8624247.0000\n",
      "Epoch 639/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8482529.0000 - val_loss: 8623414.0000\n",
      "Epoch 640/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8481819.0000 - val_loss: 8622656.0000\n",
      "Epoch 641/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8481099.0000 - val_loss: 8621828.0000\n",
      "Epoch 642/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8480378.0000 - val_loss: 8621029.0000\n",
      "Epoch 643/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8479661.0000 - val_loss: 8620196.0000\n",
      "Epoch 644/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8478941.0000 - val_loss: 8619395.0000\n",
      "Epoch 645/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8478229.0000 - val_loss: 8618627.0000\n",
      "Epoch 646/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8477520.0000 - val_loss: 8617831.0000\n",
      "Epoch 647/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8476802.0000 - val_loss: 8617010.0000\n",
      "Epoch 648/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8476098.0000 - val_loss: 8616216.0000\n",
      "Epoch 649/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8475389.0000 - val_loss: 8615446.0000\n",
      "Epoch 650/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8474672.0000 - val_loss: 8614649.0000\n",
      "Epoch 651/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8473966.0000 - val_loss: 8613856.0000\n",
      "Epoch 652/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8473264.0000 - val_loss: 8613102.0000\n",
      "Epoch 653/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8472554.0000 - val_loss: 8612324.0000\n",
      "Epoch 654/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8471845.0000 - val_loss: 8611507.0000\n",
      "Epoch 655/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8471144.0000 - val_loss: 8610772.0000\n",
      "Epoch 656/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8470435.0000 - val_loss: 8609950.0000\n",
      "Epoch 657/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8469730.0000 - val_loss: 8609187.0000\n",
      "Epoch 658/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8469016.0000 - val_loss: 8608376.0000\n",
      "Epoch 659/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8468316.0000 - val_loss: 8607590.0000\n",
      "Epoch 660/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8467612.0000 - val_loss: 8606812.0000\n",
      "Epoch 661/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8466911.0000 - val_loss: 8606025.0000\n",
      "Epoch 662/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8466221.0000 - val_loss: 8605248.0000\n",
      "Epoch 663/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8465510.0000 - val_loss: 8604504.0000\n",
      "Epoch 664/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8464814.0000 - val_loss: 8603731.0000\n",
      "Epoch 665/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8464102.0000 - val_loss: 8602922.0000\n",
      "Epoch 666/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8463399.0000 - val_loss: 8602136.0000\n",
      "Epoch 667/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8462700.0000 - val_loss: 8601378.0000\n",
      "Epoch 668/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8461997.0000 - val_loss: 8600603.0000\n",
      "Epoch 669/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8461308.0000 - val_loss: 8599826.0000\n",
      "Epoch 670/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8460598.0000 - val_loss: 8599036.0000\n",
      "Epoch 671/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8459903.0000 - val_loss: 8598281.0000\n",
      "Epoch 672/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8459202.0000 - val_loss: 8597500.0000\n",
      "Epoch 673/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8458488.0000 - val_loss: 8596721.0000\n",
      "Epoch 674/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8457786.0000 - val_loss: 8595918.0000\n",
      "Epoch 675/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8457079.0000 - val_loss: 8595105.0000\n",
      "Epoch 676/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8456382.0000 - val_loss: 8594348.0000\n",
      "Epoch 677/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8455682.0000 - val_loss: 8593559.0000\n",
      "Epoch 678/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8454971.0000 - val_loss: 8592790.0000\n",
      "Epoch 679/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8454280.0000 - val_loss: 8592000.0000\n",
      "Epoch 680/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8453575.0000 - val_loss: 8591236.0000\n",
      "Epoch 681/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8452885.0000 - val_loss: 8590475.0000\n",
      "Epoch 682/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8452185.0000 - val_loss: 8589700.0000\n",
      "Epoch 683/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8451482.0000 - val_loss: 8588923.0000\n",
      "Epoch 684/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8450773.0000 - val_loss: 8588139.0000\n",
      "Epoch 685/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8450083.0000 - val_loss: 8587355.0000\n",
      "Epoch 686/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8449386.0000 - val_loss: 8586573.0000\n",
      "Epoch 687/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8448691.0000 - val_loss: 8585793.0000\n",
      "Epoch 688/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8447994.0000 - val_loss: 8585033.0000\n",
      "Epoch 689/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8447302.0000 - val_loss: 8584256.0000\n",
      "Epoch 690/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8446599.0000 - val_loss: 8583505.0000\n",
      "Epoch 691/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8445901.0000 - val_loss: 8582737.0000\n",
      "Epoch 692/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8445202.0000 - val_loss: 8581935.0000\n",
      "Epoch 693/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8444498.0000 - val_loss: 8581172.0000\n",
      "Epoch 694/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8443799.0000 - val_loss: 8580399.0000\n",
      "Epoch 695/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8443102.0000 - val_loss: 8579607.0000\n",
      "Epoch 696/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8442398.0000 - val_loss: 8578829.0000\n",
      "Epoch 697/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8441704.0000 - val_loss: 8578049.0000\n",
      "Epoch 698/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8441007.0000 - val_loss: 8577316.0000\n",
      "Epoch 699/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8440316.0000 - val_loss: 8576511.0000\n",
      "Epoch 700/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8439621.0000 - val_loss: 8575724.0000\n",
      "Epoch 701/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8438923.0000 - val_loss: 8574982.0000\n",
      "Epoch 702/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8438231.0000 - val_loss: 8574228.0000\n",
      "Epoch 703/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8437541.0000 - val_loss: 8573434.0000\n",
      "Epoch 704/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8436838.0000 - val_loss: 8572637.0000\n",
      "Epoch 705/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8436146.0000 - val_loss: 8571886.0000\n",
      "Epoch 706/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8435452.0000 - val_loss: 8571125.0000\n",
      "Epoch 707/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8434760.0000 - val_loss: 8570318.0000\n",
      "Epoch 708/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8434068.0000 - val_loss: 8569567.0000\n",
      "Epoch 709/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8433380.0000 - val_loss: 8568817.0000\n",
      "Epoch 710/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8432684.0000 - val_loss: 8568030.0000\n",
      "Epoch 711/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8431989.0000 - val_loss: 8567278.0000\n",
      "Epoch 712/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8431297.0000 - val_loss: 8566532.0000\n",
      "Epoch 713/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8430605.0000 - val_loss: 8565748.0000\n",
      "Epoch 714/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8429907.0000 - val_loss: 8564951.0000\n",
      "Epoch 715/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8429222.0000 - val_loss: 8564215.0000\n",
      "Epoch 716/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8428516.0000 - val_loss: 8563426.0000\n",
      "Epoch 717/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8427827.0000 - val_loss: 8562659.0000\n",
      "Epoch 718/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8427137.0000 - val_loss: 8561924.0000\n",
      "Epoch 719/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8426446.0000 - val_loss: 8561151.0000\n",
      "Epoch 720/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8425754.0000 - val_loss: 8560352.0000\n",
      "Epoch 721/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8425067.0000 - val_loss: 8559595.0000\n",
      "Epoch 722/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8424381.0000 - val_loss: 8558856.0000\n",
      "Epoch 723/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8423698.0000 - val_loss: 8558125.0000\n",
      "Epoch 724/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8423009.0000 - val_loss: 8557336.0000\n",
      "Epoch 725/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8422324.0000 - val_loss: 8556598.0000\n",
      "Epoch 726/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8421646.0000 - val_loss: 8555857.0000\n",
      "Epoch 727/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8420958.0000 - val_loss: 8555098.0000\n",
      "Epoch 728/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8420287.0000 - val_loss: 8554338.0000\n",
      "Epoch 729/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8419598.0000 - val_loss: 8553593.0000\n",
      "Epoch 730/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8418919.0000 - val_loss: 8552815.0000\n",
      "Epoch 731/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8418233.0000 - val_loss: 8552077.0000\n",
      "Epoch 732/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8417546.0000 - val_loss: 8551296.0000\n",
      "Epoch 733/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8416864.0000 - val_loss: 8550550.0000\n",
      "Epoch 734/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 8416181.0000 - val_loss: 8549845.0000\n",
      "Epoch 735/2000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 8415506.0000 - val_loss: 8549082.0000\n",
      "Epoch 736/2000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 8414818.0000 - val_loss: 8548307.0000\n",
      "Epoch 737/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 8414135.0000 - val_loss: 8547565.0000\n",
      "Epoch 738/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 8413453.0000 - val_loss: 8546789.0000\n",
      "Epoch 739/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8412768.0000 - val_loss: 8546069.0000\n",
      "Epoch 740/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8412090.0000 - val_loss: 8545327.0000\n",
      "Epoch 741/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8411407.0000 - val_loss: 8544574.0000\n",
      "Epoch 742/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8410728.0000 - val_loss: 8543823.0000\n",
      "Epoch 743/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8410063.0000 - val_loss: 8543084.0000\n",
      "Epoch 744/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8409384.0000 - val_loss: 8542340.0000\n",
      "Epoch 745/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8408706.0000 - val_loss: 8541601.0000\n",
      "Epoch 746/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8408029.0000 - val_loss: 8540878.0000\n",
      "Epoch 747/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8407343.0000 - val_loss: 8540122.0000\n",
      "Epoch 748/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8406672.0000 - val_loss: 8539373.0000\n",
      "Epoch 749/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8405992.0000 - val_loss: 8538624.0000\n",
      "Epoch 750/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8405310.0000 - val_loss: 8537903.0000\n",
      "Epoch 751/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8404638.0000 - val_loss: 8537152.0000\n",
      "Epoch 752/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8403964.0000 - val_loss: 8536410.0000\n",
      "Epoch 753/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8403296.0000 - val_loss: 8535656.0000\n",
      "Epoch 754/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8402623.0000 - val_loss: 8534933.0000\n",
      "Epoch 755/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8401950.0000 - val_loss: 8534203.0000\n",
      "Epoch 756/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8401286.0000 - val_loss: 8533463.0000\n",
      "Epoch 757/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8400603.0000 - val_loss: 8532718.0000\n",
      "Epoch 758/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8399928.0000 - val_loss: 8531984.0000\n",
      "Epoch 759/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8399253.0000 - val_loss: 8531243.0000\n",
      "Epoch 760/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8398586.0000 - val_loss: 8530496.0000\n",
      "Epoch 761/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8397912.0000 - val_loss: 8529779.0000\n",
      "Epoch 762/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8397247.0000 - val_loss: 8529045.0000\n",
      "Epoch 763/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8396570.0000 - val_loss: 8528288.0000\n",
      "Epoch 764/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8395901.0000 - val_loss: 8527555.0000\n",
      "Epoch 765/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8395233.0000 - val_loss: 8526824.0000\n",
      "Epoch 766/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8394560.0000 - val_loss: 8526117.0000\n",
      "Epoch 767/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8393897.0000 - val_loss: 8525355.0000\n",
      "Epoch 768/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8393222.0000 - val_loss: 8524626.0000\n",
      "Epoch 769/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8392547.0000 - val_loss: 8523886.0000\n",
      "Epoch 770/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8391876.0000 - val_loss: 8523159.0000\n",
      "Epoch 771/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8391207.0000 - val_loss: 8522389.0000\n",
      "Epoch 772/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8390538.0000 - val_loss: 8521681.0000\n",
      "Epoch 773/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8389868.0000 - val_loss: 8520918.0000\n",
      "Epoch 774/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8389199.0000 - val_loss: 8520223.0000\n",
      "Epoch 775/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8388534.5000 - val_loss: 8519460.0000\n",
      "Epoch 776/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8387861.0000 - val_loss: 8518731.0000\n",
      "Epoch 777/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8387193.0000 - val_loss: 8518003.0000\n",
      "Epoch 778/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8386533.5000 - val_loss: 8517278.0000\n",
      "Epoch 779/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8385863.0000 - val_loss: 8516541.0000\n",
      "Epoch 780/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8385199.5000 - val_loss: 8515818.0000\n",
      "Epoch 781/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8384536.5000 - val_loss: 8515087.0000\n",
      "Epoch 782/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8383875.0000 - val_loss: 8514337.0000\n",
      "Epoch 783/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8383216.0000 - val_loss: 8513646.0000\n",
      "Epoch 784/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8382552.0000 - val_loss: 8512926.0000\n",
      "Epoch 785/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8381888.5000 - val_loss: 8512227.0000\n",
      "Epoch 786/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8381226.0000 - val_loss: 8511495.0000\n",
      "Epoch 787/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8380562.0000 - val_loss: 8510784.0000\n",
      "Epoch 788/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8379899.5000 - val_loss: 8510053.0000\n",
      "Epoch 789/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8379241.0000 - val_loss: 8509335.0000\n",
      "Epoch 790/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8378569.0000 - val_loss: 8508598.0000\n",
      "Epoch 791/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8377909.5000 - val_loss: 8507862.0000\n",
      "Epoch 792/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8377246.0000 - val_loss: 8507159.0000\n",
      "Epoch 793/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8376598.5000 - val_loss: 8506464.0000\n",
      "Epoch 794/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8375940.0000 - val_loss: 8505692.0000\n",
      "Epoch 795/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8375268.5000 - val_loss: 8504982.0000\n",
      "Epoch 796/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8374604.5000 - val_loss: 8504248.0000\n",
      "Epoch 797/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8373941.0000 - val_loss: 8503540.0000\n",
      "Epoch 798/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8373279.0000 - val_loss: 8502832.0000\n",
      "Epoch 799/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8372627.0000 - val_loss: 8502086.0000\n",
      "Epoch 800/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8371956.5000 - val_loss: 8501354.0000\n",
      "Epoch 801/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8371295.0000 - val_loss: 8500650.0000\n",
      "Epoch 802/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8370629.5000 - val_loss: 8499915.0000\n",
      "Epoch 803/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8369975.0000 - val_loss: 8499212.0000\n",
      "Epoch 804/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8369312.0000 - val_loss: 8498478.0000\n",
      "Epoch 805/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8368657.0000 - val_loss: 8497785.0000\n",
      "Epoch 806/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8367990.0000 - val_loss: 8497068.0000\n",
      "Epoch 807/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8367330.0000 - val_loss: 8496276.0000\n",
      "Epoch 808/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8366671.5000 - val_loss: 8495604.0000\n",
      "Epoch 809/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8366015.0000 - val_loss: 8494887.0000\n",
      "Epoch 810/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8365354.0000 - val_loss: 8494149.0000\n",
      "Epoch 811/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8364697.5000 - val_loss: 8493407.0000\n",
      "Epoch 812/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8364041.0000 - val_loss: 8492703.0000\n",
      "Epoch 813/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8363378.5000 - val_loss: 8492011.0000\n",
      "Epoch 814/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8362731.5000 - val_loss: 8491284.0000\n",
      "Epoch 815/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8362073.5000 - val_loss: 8490574.0000\n",
      "Epoch 816/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8361421.0000 - val_loss: 8489868.0000\n",
      "Epoch 817/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8360757.0000 - val_loss: 8489150.0000\n",
      "Epoch 818/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8360097.5000 - val_loss: 8488421.0000\n",
      "Epoch 819/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8359448.5000 - val_loss: 8487733.0000\n",
      "Epoch 820/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8358792.0000 - val_loss: 8487030.0000\n",
      "Epoch 821/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8358135.5000 - val_loss: 8486302.0000\n",
      "Epoch 822/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8357477.0000 - val_loss: 8485602.0000\n",
      "Epoch 823/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8356820.5000 - val_loss: 8484878.0000\n",
      "Epoch 824/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8356161.5000 - val_loss: 8484153.0000\n",
      "Epoch 825/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8355512.5000 - val_loss: 8483438.0000\n",
      "Epoch 826/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8354862.5000 - val_loss: 8482735.0000\n",
      "Epoch 827/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8354208.5000 - val_loss: 8482024.0000\n",
      "Epoch 828/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8353547.5000 - val_loss: 8481301.0000\n",
      "Epoch 829/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8352894.5000 - val_loss: 8480614.0000\n",
      "Epoch 830/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8352234.0000 - val_loss: 8479899.0000\n",
      "Epoch 831/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8351579.0000 - val_loss: 8479165.0000\n",
      "Epoch 832/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8350932.5000 - val_loss: 8478447.0000\n",
      "Epoch 833/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8350277.5000 - val_loss: 8477756.0000\n",
      "Epoch 834/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8349622.5000 - val_loss: 8477050.0000\n",
      "Epoch 835/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8348976.0000 - val_loss: 8476338.0000\n",
      "Epoch 836/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8348321.0000 - val_loss: 8475652.0000\n",
      "Epoch 837/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8347670.0000 - val_loss: 8474903.0000\n",
      "Epoch 838/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8347014.5000 - val_loss: 8474239.0000\n",
      "Epoch 839/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8346367.5000 - val_loss: 8473518.0000\n",
      "Epoch 840/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8345707.5000 - val_loss: 8472773.0000\n",
      "Epoch 841/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8345059.0000 - val_loss: 8472080.0000\n",
      "Epoch 842/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8344410.0000 - val_loss: 8471374.0000\n",
      "Epoch 843/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8343755.0000 - val_loss: 8470670.0000\n",
      "Epoch 844/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8343108.0000 - val_loss: 8469956.0000\n",
      "Epoch 845/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8342456.0000 - val_loss: 8469238.0000\n",
      "Epoch 846/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8341802.0000 - val_loss: 8468507.0000\n",
      "Epoch 847/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8341154.5000 - val_loss: 8467811.0000\n",
      "Epoch 848/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8340498.5000 - val_loss: 8467116.0000\n",
      "Epoch 849/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8339850.0000 - val_loss: 8466427.0000\n",
      "Epoch 850/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8339209.5000 - val_loss: 8465674.0000\n",
      "Epoch 851/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8338544.0000 - val_loss: 8464991.0000\n",
      "Epoch 852/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8337898.5000 - val_loss: 8464280.0000\n",
      "Epoch 853/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8337253.0000 - val_loss: 8463581.0000\n",
      "Epoch 854/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8336610.0000 - val_loss: 8462865.0000\n",
      "Epoch 855/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8335965.5000 - val_loss: 8462172.0000\n",
      "Epoch 856/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8335309.5000 - val_loss: 8461470.0000\n",
      "Epoch 857/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8334669.5000 - val_loss: 8460749.0000\n",
      "Epoch 858/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8334013.5000 - val_loss: 8460056.0000\n",
      "Epoch 859/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8333365.5000 - val_loss: 8459384.0000\n",
      "Epoch 860/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8332725.0000 - val_loss: 8458656.0000\n",
      "Epoch 861/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8332076.0000 - val_loss: 8457960.0000\n",
      "Epoch 862/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8331428.5000 - val_loss: 8457291.0000\n",
      "Epoch 863/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8330775.5000 - val_loss: 8456571.0000\n",
      "Epoch 864/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8330126.0000 - val_loss: 8455866.0000\n",
      "Epoch 865/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8329486.5000 - val_loss: 8455158.0000\n",
      "Epoch 866/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8328830.5000 - val_loss: 8454439.0000\n",
      "Epoch 867/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8328193.5000 - val_loss: 8453768.0000\n",
      "Epoch 868/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8327543.5000 - val_loss: 8453072.0000\n",
      "Epoch 869/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8326878.5000 - val_loss: 8452349.0000\n",
      "Epoch 870/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8326234.5000 - val_loss: 8451629.0000\n",
      "Epoch 871/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8325595.5000 - val_loss: 8450928.0000\n",
      "Epoch 872/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8324943.5000 - val_loss: 8450221.0000\n",
      "Epoch 873/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8324301.0000 - val_loss: 8449509.0000\n",
      "Epoch 874/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8323644.0000 - val_loss: 8448823.0000\n",
      "Epoch 875/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8322999.5000 - val_loss: 8448101.0000\n",
      "Epoch 876/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8322354.0000 - val_loss: 8447400.0000\n",
      "Epoch 877/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8321705.5000 - val_loss: 8446698.0000\n",
      "Epoch 878/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8321054.5000 - val_loss: 8445989.0000\n",
      "Epoch 879/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8320418.0000 - val_loss: 8445316.0000\n",
      "Epoch 880/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8319775.5000 - val_loss: 8444625.0000\n",
      "Epoch 881/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8319135.5000 - val_loss: 8443922.0000\n",
      "Epoch 882/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8318492.0000 - val_loss: 8443253.0000\n",
      "Epoch 883/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8317847.5000 - val_loss: 8442509.0000\n",
      "Epoch 884/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8317201.5000 - val_loss: 8441834.0000\n",
      "Epoch 885/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8316554.0000 - val_loss: 8441120.0000\n",
      "Epoch 886/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8315915.0000 - val_loss: 8440436.0000\n",
      "Epoch 887/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8315269.5000 - val_loss: 8439743.0000\n",
      "Epoch 888/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8314629.0000 - val_loss: 8439070.0000\n",
      "Epoch 889/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8313988.0000 - val_loss: 8438372.0000\n",
      "Epoch 890/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8313347.0000 - val_loss: 8437696.0000\n",
      "Epoch 891/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8312713.5000 - val_loss: 8437001.0000\n",
      "Epoch 892/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8312069.0000 - val_loss: 8436280.0000\n",
      "Epoch 893/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8311431.5000 - val_loss: 8435597.0000\n",
      "Epoch 894/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8310796.5000 - val_loss: 8434923.0000\n",
      "Epoch 895/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8310160.0000 - val_loss: 8434218.0000\n",
      "Epoch 896/2000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 8309514.5000 - val_loss: 8433557.0000\n",
      "Epoch 897/2000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 8308886.5000 - val_loss: 8432826.0000\n",
      "Epoch 898/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8308246.0000 - val_loss: 8432152.0000\n",
      "Epoch 899/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8307609.5000 - val_loss: 8431472.0000\n",
      "Epoch 900/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8306977.0000 - val_loss: 8430798.0000\n",
      "Epoch 901/2000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 8306331.5000 - val_loss: 8430090.0000\n",
      "Epoch 902/2000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 8305696.0000 - val_loss: 8429395.0000\n",
      "Epoch 903/2000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 8305055.5000 - val_loss: 8428695.0000\n",
      "Epoch 904/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8304417.5000 - val_loss: 8428031.0000\n",
      "Epoch 905/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8303781.0000 - val_loss: 8427351.0000\n",
      "Epoch 906/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8303139.5000 - val_loss: 8426654.0000\n",
      "Epoch 907/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8302501.5000 - val_loss: 8425974.0000\n",
      "Epoch 908/2000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 8301870.5000 - val_loss: 8425291.0000\n",
      "Epoch 909/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8301232.5000 - val_loss: 8424613.0000\n",
      "Epoch 910/2000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 8300593.0000 - val_loss: 8423924.0000\n",
      "Epoch 911/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8299961.0000 - val_loss: 8423236.0000\n",
      "Epoch 912/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8299320.5000 - val_loss: 8422526.0000\n",
      "Epoch 913/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8298680.0000 - val_loss: 8421865.0000\n",
      "Epoch 914/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8298041.0000 - val_loss: 8421165.0000\n",
      "Epoch 915/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8297410.0000 - val_loss: 8420510.0000\n",
      "Epoch 916/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8296766.0000 - val_loss: 8419779.0000\n",
      "Epoch 917/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8296128.0000 - val_loss: 8419108.0000\n",
      "Epoch 918/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8295489.0000 - val_loss: 8418417.0000\n",
      "Epoch 919/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8294851.0000 - val_loss: 8417718.0000\n",
      "Epoch 920/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8294215.0000 - val_loss: 8417030.0000\n",
      "Epoch 921/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8293575.5000 - val_loss: 8416334.0000\n",
      "Epoch 922/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8292936.0000 - val_loss: 8415651.0000\n",
      "Epoch 923/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8292304.5000 - val_loss: 8414969.0000\n",
      "Epoch 924/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8291669.5000 - val_loss: 8414275.0000\n",
      "Epoch 925/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8291035.5000 - val_loss: 8413586.0000\n",
      "Epoch 926/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8290396.5000 - val_loss: 8412882.0000\n",
      "Epoch 927/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8289770.0000 - val_loss: 8412221.0000\n",
      "Epoch 928/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8289130.5000 - val_loss: 8411558.0000\n",
      "Epoch 929/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8288505.0000 - val_loss: 8410887.0000\n",
      "Epoch 930/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8287873.0000 - val_loss: 8410210.0000\n",
      "Epoch 931/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8287233.5000 - val_loss: 8409505.0000\n",
      "Epoch 932/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8286609.5000 - val_loss: 8408845.0000\n",
      "Epoch 933/2000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 8285980.5000 - val_loss: 8408162.0000\n",
      "Epoch 934/2000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 8285348.5000 - val_loss: 8407505.0000\n",
      "Epoch 935/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8284717.0000 - val_loss: 8406821.0000\n",
      "Epoch 936/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8284093.5000 - val_loss: 8406129.0000\n",
      "Epoch 937/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8283465.0000 - val_loss: 8405450.0000\n",
      "Epoch 938/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8282833.5000 - val_loss: 8404794.0000\n",
      "Epoch 939/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8282206.0000 - val_loss: 8404100.0000\n",
      "Epoch 940/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8281569.5000 - val_loss: 8403398.0000\n",
      "Epoch 941/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8280941.5000 - val_loss: 8402726.0000\n",
      "Epoch 942/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8280313.5000 - val_loss: 8402058.0000\n",
      "Epoch 943/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8279691.5000 - val_loss: 8401395.0000\n",
      "Epoch 944/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8279063.0000 - val_loss: 8400728.0000\n",
      "Epoch 945/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8278429.5000 - val_loss: 8400049.0000\n",
      "Epoch 946/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8277805.0000 - val_loss: 8399376.0000\n",
      "Epoch 947/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8277181.0000 - val_loss: 8398694.0000\n",
      "Epoch 948/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8276548.0000 - val_loss: 8398027.0000\n",
      "Epoch 949/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8275919.0000 - val_loss: 8397357.0000\n",
      "Epoch 950/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8275296.0000 - val_loss: 8396697.0000\n",
      "Epoch 951/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8274678.0000 - val_loss: 8396038.0000\n",
      "Epoch 952/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8274046.5000 - val_loss: 8395365.0000\n",
      "Epoch 953/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8273422.0000 - val_loss: 8394690.0000\n",
      "Epoch 954/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8272792.5000 - val_loss: 8393995.0000\n",
      "Epoch 955/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8272175.0000 - val_loss: 8393329.0000\n",
      "Epoch 956/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8271552.5000 - val_loss: 8392663.0000\n",
      "Epoch 957/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8270926.5000 - val_loss: 8392020.0000\n",
      "Epoch 958/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8270302.0000 - val_loss: 8391348.0000\n",
      "Epoch 959/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8269677.5000 - val_loss: 8390667.0000\n",
      "Epoch 960/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8269052.0000 - val_loss: 8389984.0000\n",
      "Epoch 961/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8268425.0000 - val_loss: 8389321.0000\n",
      "Epoch 962/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8267802.5000 - val_loss: 8388644.0000\n",
      "Epoch 963/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8267173.5000 - val_loss: 8387973.0000\n",
      "Epoch 964/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8266547.5000 - val_loss: 8387314.0000\n",
      "Epoch 965/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8265917.5000 - val_loss: 8386633.0000\n",
      "Epoch 966/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8265300.5000 - val_loss: 8385943.5000\n",
      "Epoch 967/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8264678.0000 - val_loss: 8385297.0000\n",
      "Epoch 968/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8264038.5000 - val_loss: 8384622.0000\n",
      "Epoch 969/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8263420.0000 - val_loss: 8383972.5000\n",
      "Epoch 970/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8262793.0000 - val_loss: 8383284.5000\n",
      "Epoch 971/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8262173.5000 - val_loss: 8382623.0000\n",
      "Epoch 972/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8261547.5000 - val_loss: 8381955.0000\n",
      "Epoch 973/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8260926.5000 - val_loss: 8381280.0000\n",
      "Epoch 974/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8260302.0000 - val_loss: 8380609.0000\n",
      "Epoch 975/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8259677.5000 - val_loss: 8379945.5000\n",
      "Epoch 976/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8259051.5000 - val_loss: 8379296.0000\n",
      "Epoch 977/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8258433.5000 - val_loss: 8378653.5000\n",
      "Epoch 978/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8257813.0000 - val_loss: 8377959.0000\n",
      "Epoch 979/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8257179.5000 - val_loss: 8377285.0000\n",
      "Epoch 980/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8256555.5000 - val_loss: 8376608.5000\n",
      "Epoch 981/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8255929.0000 - val_loss: 8375918.0000\n",
      "Epoch 982/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8255308.5000 - val_loss: 8375265.5000\n",
      "Epoch 983/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8254686.5000 - val_loss: 8374625.5000\n",
      "Epoch 984/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8254067.0000 - val_loss: 8373938.5000\n",
      "Epoch 985/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8253435.5000 - val_loss: 8373248.5000\n",
      "Epoch 986/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8252820.0000 - val_loss: 8372611.5000\n",
      "Epoch 987/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8252201.0000 - val_loss: 8371956.0000\n",
      "Epoch 988/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8251584.5000 - val_loss: 8371323.0000\n",
      "Epoch 989/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8250961.5000 - val_loss: 8370653.0000\n",
      "Epoch 990/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8250345.0000 - val_loss: 8369997.0000\n",
      "Epoch 991/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8249725.0000 - val_loss: 8369313.5000\n",
      "Epoch 992/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8249106.0000 - val_loss: 8368665.0000\n",
      "Epoch 993/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8248493.5000 - val_loss: 8368020.0000\n",
      "Epoch 994/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8247877.0000 - val_loss: 8367346.0000\n",
      "Epoch 995/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8247257.5000 - val_loss: 8366723.5000\n",
      "Epoch 996/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8246644.0000 - val_loss: 8366037.0000\n",
      "Epoch 997/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8246023.0000 - val_loss: 8365399.5000\n",
      "Epoch 998/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8245414.5000 - val_loss: 8364709.5000\n",
      "Epoch 999/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8244799.0000 - val_loss: 8364081.0000\n",
      "Epoch 1000/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8244182.5000 - val_loss: 8363428.5000\n",
      "Epoch 1001/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8243567.5000 - val_loss: 8362778.0000\n",
      "Epoch 1002/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8242953.5000 - val_loss: 8362133.5000\n",
      "Epoch 1003/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8242337.0000 - val_loss: 8361436.5000\n",
      "Epoch 1004/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8241719.5000 - val_loss: 8360809.0000\n",
      "Epoch 1005/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8241112.0000 - val_loss: 8360174.0000\n",
      "Epoch 1006/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8240500.0000 - val_loss: 8359511.5000\n",
      "Epoch 1007/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8239889.5000 - val_loss: 8358896.5000\n",
      "Epoch 1008/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8239282.0000 - val_loss: 8358225.5000\n",
      "Epoch 1009/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8238665.5000 - val_loss: 8357605.5000\n",
      "Epoch 1010/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8238055.0000 - val_loss: 8356943.0000\n",
      "Epoch 1011/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8237445.0000 - val_loss: 8356284.5000\n",
      "Epoch 1012/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8236828.5000 - val_loss: 8355625.5000\n",
      "Epoch 1013/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8236216.0000 - val_loss: 8354971.5000\n",
      "Epoch 1014/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8235603.0000 - val_loss: 8354302.5000\n",
      "Epoch 1015/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8234986.5000 - val_loss: 8353668.5000\n",
      "Epoch 1016/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8234374.5000 - val_loss: 8353000.5000\n",
      "Epoch 1017/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8233759.5000 - val_loss: 8352360.5000\n",
      "Epoch 1018/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8233146.0000 - val_loss: 8351693.5000\n",
      "Epoch 1019/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8232528.0000 - val_loss: 8351026.5000\n",
      "Epoch 1020/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8231917.5000 - val_loss: 8350392.0000\n",
      "Epoch 1021/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8231316.0000 - val_loss: 8349731.0000\n",
      "Epoch 1022/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8230707.0000 - val_loss: 8349135.0000\n",
      "Epoch 1023/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8230089.0000 - val_loss: 8348459.5000\n",
      "Epoch 1024/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8229484.0000 - val_loss: 8347796.0000\n",
      "Epoch 1025/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8228864.0000 - val_loss: 8347154.5000\n",
      "Epoch 1026/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8228256.5000 - val_loss: 8346508.5000\n",
      "Epoch 1027/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8227645.0000 - val_loss: 8345854.5000\n",
      "Epoch 1028/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8227036.0000 - val_loss: 8345216.5000\n",
      "Epoch 1029/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8226436.0000 - val_loss: 8344571.5000\n",
      "Epoch 1030/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8225817.0000 - val_loss: 8343908.5000\n",
      "Epoch 1031/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8225210.5000 - val_loss: 8343263.5000\n",
      "Epoch 1032/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8224600.0000 - val_loss: 8342634.5000\n",
      "Epoch 1033/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8223998.0000 - val_loss: 8341957.5000\n",
      "Epoch 1034/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8223382.5000 - val_loss: 8341314.5000\n",
      "Epoch 1035/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8222779.5000 - val_loss: 8340668.5000\n",
      "Epoch 1036/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8222163.5000 - val_loss: 8340023.0000\n",
      "Epoch 1037/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8221557.5000 - val_loss: 8339365.5000\n",
      "Epoch 1038/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8220944.0000 - val_loss: 8338713.0000\n",
      "Epoch 1039/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8220341.5000 - val_loss: 8338077.5000\n",
      "Epoch 1040/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8219735.5000 - val_loss: 8337454.0000\n",
      "Epoch 1041/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8219122.5000 - val_loss: 8336795.5000\n",
      "Epoch 1042/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8218519.0000 - val_loss: 8336137.0000\n",
      "Epoch 1043/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8217906.0000 - val_loss: 8335479.0000\n",
      "Epoch 1044/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8217300.5000 - val_loss: 8334853.0000\n",
      "Epoch 1045/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8216684.0000 - val_loss: 8334206.5000\n",
      "Epoch 1046/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8216078.0000 - val_loss: 8333549.0000\n",
      "Epoch 1047/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8215466.0000 - val_loss: 8332897.5000\n",
      "Epoch 1048/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8214863.0000 - val_loss: 8332286.5000\n",
      "Epoch 1049/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8214253.0000 - val_loss: 8331631.0000\n",
      "Epoch 1050/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8213639.0000 - val_loss: 8330958.5000\n",
      "Epoch 1051/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8213033.5000 - val_loss: 8330328.0000\n",
      "Epoch 1052/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8212425.0000 - val_loss: 8329691.0000\n",
      "Epoch 1053/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8211823.5000 - val_loss: 8329054.5000\n",
      "Epoch 1054/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8211216.0000 - val_loss: 8328384.5000\n",
      "Epoch 1055/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8210604.0000 - val_loss: 8327747.5000\n",
      "Epoch 1056/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8209999.5000 - val_loss: 8327103.5000\n",
      "Epoch 1057/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8209386.0000 - val_loss: 8326454.0000\n",
      "Epoch 1058/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8208781.0000 - val_loss: 8325810.5000\n",
      "Epoch 1059/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8208180.0000 - val_loss: 8325155.5000\n",
      "Epoch 1060/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8207573.5000 - val_loss: 8324510.5000\n",
      "Epoch 1061/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8206973.0000 - val_loss: 8323879.0000\n",
      "Epoch 1062/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8206372.5000 - val_loss: 8323270.5000\n",
      "Epoch 1063/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8205770.5000 - val_loss: 8322606.0000\n",
      "Epoch 1064/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8205164.5000 - val_loss: 8322017.5000\n",
      "Epoch 1065/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8204562.0000 - val_loss: 8321369.5000\n",
      "Epoch 1066/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8203961.0000 - val_loss: 8320731.0000\n",
      "Epoch 1067/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8203354.5000 - val_loss: 8320084.5000\n",
      "Epoch 1068/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8202747.0000 - val_loss: 8319451.5000\n",
      "Epoch 1069/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8202143.5000 - val_loss: 8318791.0000\n",
      "Epoch 1070/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8201530.0000 - val_loss: 8318150.5000\n",
      "Epoch 1071/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8200933.5000 - val_loss: 8317543.5000\n",
      "Epoch 1072/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8200335.0000 - val_loss: 8316882.0000\n",
      "Epoch 1073/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8199719.5000 - val_loss: 8316237.0000\n",
      "Epoch 1074/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8199112.5000 - val_loss: 8315598.5000\n",
      "Epoch 1075/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8198514.5000 - val_loss: 8314954.5000\n",
      "Epoch 1076/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8197915.0000 - val_loss: 8314323.5000\n",
      "Epoch 1077/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8197312.5000 - val_loss: 8313686.5000\n",
      "Epoch 1078/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8196716.0000 - val_loss: 8313070.0000\n",
      "Epoch 1079/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8196113.0000 - val_loss: 8312417.0000\n",
      "Epoch 1080/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8195510.0000 - val_loss: 8311791.5000\n",
      "Epoch 1081/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8194915.5000 - val_loss: 8311183.0000\n",
      "Epoch 1082/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8194316.0000 - val_loss: 8310529.5000\n",
      "Epoch 1083/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8193721.0000 - val_loss: 8309885.0000\n",
      "Epoch 1084/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8193123.5000 - val_loss: 8309288.5000\n",
      "Epoch 1085/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8192524.0000 - val_loss: 8308657.5000\n",
      "Epoch 1086/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8191927.5000 - val_loss: 8308042.0000\n",
      "Epoch 1087/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8191330.0000 - val_loss: 8307387.0000\n",
      "Epoch 1088/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8190729.5000 - val_loss: 8306758.5000\n",
      "Epoch 1089/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8190127.5000 - val_loss: 8306142.5000\n",
      "Epoch 1090/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8189538.5000 - val_loss: 8305477.5000\n",
      "Epoch 1091/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8188936.0000 - val_loss: 8304902.5000\n",
      "Epoch 1092/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8188330.0000 - val_loss: 8304227.0000\n",
      "Epoch 1093/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8187724.0000 - val_loss: 8303610.0000\n",
      "Epoch 1094/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8187129.5000 - val_loss: 8302962.0000\n",
      "Epoch 1095/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8186523.5000 - val_loss: 8302344.0000\n",
      "Epoch 1096/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8185928.0000 - val_loss: 8301716.5000\n",
      "Epoch 1097/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8185330.5000 - val_loss: 8301074.5000\n",
      "Epoch 1098/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8184732.5000 - val_loss: 8300451.5000\n",
      "Epoch 1099/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8184140.0000 - val_loss: 8299825.5000\n",
      "Epoch 1100/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8183534.5000 - val_loss: 8299207.0000\n",
      "Epoch 1101/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8182939.5000 - val_loss: 8298555.0000\n",
      "Epoch 1102/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8182336.5000 - val_loss: 8297935.0000\n",
      "Epoch 1103/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8181745.0000 - val_loss: 8297319.0000\n",
      "Epoch 1104/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8181151.0000 - val_loss: 8296691.5000\n",
      "Epoch 1105/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8180555.0000 - val_loss: 8296076.5000\n",
      "Epoch 1106/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8179959.5000 - val_loss: 8295456.0000\n",
      "Epoch 1107/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8179372.5000 - val_loss: 8294835.0000\n",
      "Epoch 1108/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8178772.5000 - val_loss: 8294196.0000\n",
      "Epoch 1109/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8178180.5000 - val_loss: 8293579.5000\n",
      "Epoch 1110/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8177584.0000 - val_loss: 8292961.0000\n",
      "Epoch 1111/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8176987.0000 - val_loss: 8292310.5000\n",
      "Epoch 1112/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8176394.5000 - val_loss: 8291702.5000\n",
      "Epoch 1113/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8175799.0000 - val_loss: 8291066.0000\n",
      "Epoch 1114/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8175203.5000 - val_loss: 8290439.5000\n",
      "Epoch 1115/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8174612.5000 - val_loss: 8289808.5000\n",
      "Epoch 1116/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8174016.5000 - val_loss: 8289190.5000\n",
      "Epoch 1117/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8173425.5000 - val_loss: 8288589.0000\n",
      "Epoch 1118/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8172830.5000 - val_loss: 8287949.0000\n",
      "Epoch 1119/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8172232.0000 - val_loss: 8287325.0000\n",
      "Epoch 1120/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8171643.5000 - val_loss: 8286730.5000\n",
      "Epoch 1121/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8171050.0000 - val_loss: 8286083.5000\n",
      "Epoch 1122/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8170459.5000 - val_loss: 8285449.0000\n",
      "Epoch 1123/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8169859.5000 - val_loss: 8284850.5000\n",
      "Epoch 1124/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8169273.5000 - val_loss: 8284199.0000\n",
      "Epoch 1125/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8168675.5000 - val_loss: 8283597.0000\n",
      "Epoch 1126/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8168074.5000 - val_loss: 8282958.5000\n",
      "Epoch 1127/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8167486.0000 - val_loss: 8282326.5000\n",
      "Epoch 1128/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8166884.0000 - val_loss: 8281694.5000\n",
      "Epoch 1129/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8166290.5000 - val_loss: 8281065.0000\n",
      "Epoch 1130/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8165696.0000 - val_loss: 8280453.0000\n",
      "Epoch 1131/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8165102.0000 - val_loss: 8279814.0000\n",
      "Epoch 1132/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8164513.0000 - val_loss: 8279197.0000\n",
      "Epoch 1133/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8163916.5000 - val_loss: 8278570.0000\n",
      "Epoch 1134/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8163330.0000 - val_loss: 8277945.0000\n",
      "Epoch 1135/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8162745.0000 - val_loss: 8277337.0000\n",
      "Epoch 1136/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8162147.0000 - val_loss: 8276697.0000\n",
      "Epoch 1137/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8161555.0000 - val_loss: 8276098.0000\n",
      "Epoch 1138/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8160966.5000 - val_loss: 8275485.5000\n",
      "Epoch 1139/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8160374.0000 - val_loss: 8274899.5000\n",
      "Epoch 1140/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8159773.0000 - val_loss: 8274239.5000\n",
      "Epoch 1141/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8159185.5000 - val_loss: 8273608.5000\n",
      "Epoch 1142/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8158593.5000 - val_loss: 8272995.0000\n",
      "Epoch 1143/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8157997.5000 - val_loss: 8272387.5000\n",
      "Epoch 1144/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8157408.0000 - val_loss: 8271759.0000\n",
      "Epoch 1145/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8156813.5000 - val_loss: 8271141.5000\n",
      "Epoch 1146/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8156220.0000 - val_loss: 8270516.5000\n",
      "Epoch 1147/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8155632.5000 - val_loss: 8269908.5000\n",
      "Epoch 1148/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8155039.5000 - val_loss: 8269285.5000\n",
      "Epoch 1149/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8154451.5000 - val_loss: 8268685.5000\n",
      "Epoch 1150/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8153863.0000 - val_loss: 8268076.5000\n",
      "Epoch 1151/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8153273.0000 - val_loss: 8267457.0000\n",
      "Epoch 1152/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8152684.0000 - val_loss: 8266841.5000\n",
      "Epoch 1153/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8152090.5000 - val_loss: 8266205.0000\n",
      "Epoch 1154/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8151501.5000 - val_loss: 8265586.0000\n",
      "Epoch 1155/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8150911.0000 - val_loss: 8264993.5000\n",
      "Epoch 1156/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8150328.0000 - val_loss: 8264376.0000\n",
      "Epoch 1157/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8149733.5000 - val_loss: 8263743.0000\n",
      "Epoch 1158/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8149148.5000 - val_loss: 8263140.0000\n",
      "Epoch 1159/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8148559.5000 - val_loss: 8262511.5000\n",
      "Epoch 1160/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8147977.5000 - val_loss: 8261910.0000\n",
      "Epoch 1161/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8147383.5000 - val_loss: 8261289.5000\n",
      "Epoch 1162/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8146806.0000 - val_loss: 8260697.5000\n",
      "Epoch 1163/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8146206.5000 - val_loss: 8260050.0000\n",
      "Epoch 1164/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8145621.5000 - val_loss: 8259456.5000\n",
      "Epoch 1165/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8145033.0000 - val_loss: 8258838.0000\n",
      "Epoch 1166/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8144447.0000 - val_loss: 8258233.5000\n",
      "Epoch 1167/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8143850.5000 - val_loss: 8257617.5000\n",
      "Epoch 1168/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8143265.0000 - val_loss: 8256998.0000\n",
      "Epoch 1169/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8142680.5000 - val_loss: 8256382.5000\n",
      "Epoch 1170/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8142081.0000 - val_loss: 8255754.5000\n",
      "Epoch 1171/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8141492.0000 - val_loss: 8255137.5000\n",
      "Epoch 1172/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8140906.0000 - val_loss: 8254535.0000\n",
      "Epoch 1173/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8140321.5000 - val_loss: 8253915.0000\n",
      "Epoch 1174/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8139731.0000 - val_loss: 8253284.5000\n",
      "Epoch 1175/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8139144.5000 - val_loss: 8252675.0000\n",
      "Epoch 1176/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8138554.0000 - val_loss: 8252082.5000\n",
      "Epoch 1177/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8137975.5000 - val_loss: 8251468.0000\n",
      "Epoch 1178/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8137387.0000 - val_loss: 8250859.5000\n",
      "Epoch 1179/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8136793.5000 - val_loss: 8250223.0000\n",
      "Epoch 1180/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8136211.5000 - val_loss: 8249620.5000\n",
      "Epoch 1181/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8135633.5000 - val_loss: 8249001.5000\n",
      "Epoch 1182/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8135050.0000 - val_loss: 8248396.0000\n",
      "Epoch 1183/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8134461.0000 - val_loss: 8247789.0000\n",
      "Epoch 1184/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8133884.5000 - val_loss: 8247200.5000\n",
      "Epoch 1185/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8133305.0000 - val_loss: 8246595.5000\n",
      "Epoch 1186/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8132724.5000 - val_loss: 8245947.0000\n",
      "Epoch 1187/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8132137.5000 - val_loss: 8245378.0000\n",
      "Epoch 1188/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8131550.0000 - val_loss: 8244772.5000\n",
      "Epoch 1189/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8130960.0000 - val_loss: 8244168.0000\n",
      "Epoch 1190/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8130372.5000 - val_loss: 8243546.5000\n",
      "Epoch 1191/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8129791.5000 - val_loss: 8242941.0000\n",
      "Epoch 1192/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8129207.0000 - val_loss: 8242348.5000\n",
      "Epoch 1193/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8128630.5000 - val_loss: 8241738.0000\n",
      "Epoch 1194/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8128043.0000 - val_loss: 8241145.5000\n",
      "Epoch 1195/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8127466.5000 - val_loss: 8240552.5000\n",
      "Epoch 1196/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8126882.5000 - val_loss: 8239931.0000\n",
      "Epoch 1197/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8126304.0000 - val_loss: 8239305.0000\n",
      "Epoch 1198/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8125718.0000 - val_loss: 8238709.0000\n",
      "Epoch 1199/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8125130.5000 - val_loss: 8238098.5000\n",
      "Epoch 1200/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8124547.0000 - val_loss: 8237487.5000\n",
      "Epoch 1201/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8123965.5000 - val_loss: 8236883.0000\n",
      "Epoch 1202/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8123386.0000 - val_loss: 8236262.0000\n",
      "Epoch 1203/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8122802.0000 - val_loss: 8235651.5000\n",
      "Epoch 1204/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8122216.0000 - val_loss: 8235032.5000\n",
      "Epoch 1205/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8121636.5000 - val_loss: 8234414.5000\n",
      "Epoch 1206/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8121054.5000 - val_loss: 8233806.5000\n",
      "Epoch 1207/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8120463.5000 - val_loss: 8233214.5000\n",
      "Epoch 1208/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8119894.5000 - val_loss: 8232604.0000\n",
      "Epoch 1209/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8119307.0000 - val_loss: 8231988.5000\n",
      "Epoch 1210/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8118732.0000 - val_loss: 8231390.5000\n",
      "Epoch 1211/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8118138.5000 - val_loss: 8230789.0000\n",
      "Epoch 1212/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8117561.5000 - val_loss: 8230187.0000\n",
      "Epoch 1213/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8116974.5000 - val_loss: 8229587.0000\n",
      "Epoch 1214/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8116386.5000 - val_loss: 8228973.5000\n",
      "Epoch 1215/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8115810.5000 - val_loss: 8228361.0000\n",
      "Epoch 1216/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8115229.0000 - val_loss: 8227759.5000\n",
      "Epoch 1217/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8114646.5000 - val_loss: 8227164.5000\n",
      "Epoch 1218/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8114068.5000 - val_loss: 8226570.5000\n",
      "Epoch 1219/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8113496.5000 - val_loss: 8225946.0000\n",
      "Epoch 1220/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8112909.0000 - val_loss: 8225383.0000\n",
      "Epoch 1221/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8112332.5000 - val_loss: 8224760.0000\n",
      "Epoch 1222/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8111757.5000 - val_loss: 8224143.5000\n",
      "Epoch 1223/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8111173.5000 - val_loss: 8223570.0000\n",
      "Epoch 1224/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8110592.5000 - val_loss: 8222968.0000\n",
      "Epoch 1225/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8110018.0000 - val_loss: 8222372.5000\n",
      "Epoch 1226/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8109435.5000 - val_loss: 8221780.5000\n",
      "Epoch 1227/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8108865.0000 - val_loss: 8221156.5000\n",
      "Epoch 1228/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8108282.5000 - val_loss: 8220537.5000\n",
      "Epoch 1229/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8107702.5000 - val_loss: 8219957.5000\n",
      "Epoch 1230/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8107123.5000 - val_loss: 8219353.5000\n",
      "Epoch 1231/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8106550.0000 - val_loss: 8218769.0000\n",
      "Epoch 1232/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8105970.0000 - val_loss: 8218192.5000\n",
      "Epoch 1233/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8105398.5000 - val_loss: 8217604.5000\n",
      "Epoch 1234/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8104817.5000 - val_loss: 8216995.5000\n",
      "Epoch 1235/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8104240.0000 - val_loss: 8216381.5000\n",
      "Epoch 1236/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8103665.0000 - val_loss: 8215770.5000\n",
      "Epoch 1237/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8103080.0000 - val_loss: 8215170.0000\n",
      "Epoch 1238/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8102507.5000 - val_loss: 8214580.5000\n",
      "Epoch 1239/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8101934.5000 - val_loss: 8213952.5000\n",
      "Epoch 1240/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8101360.5000 - val_loss: 8213357.5000\n",
      "Epoch 1241/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8100779.5000 - val_loss: 8212742.0000\n",
      "Epoch 1242/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8100198.5000 - val_loss: 8212178.0000\n",
      "Epoch 1243/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8099625.0000 - val_loss: 8211576.0000\n",
      "Epoch 1244/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8099049.5000 - val_loss: 8210959.0000\n",
      "Epoch 1245/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8098473.5000 - val_loss: 8210382.5000\n",
      "Epoch 1246/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8097897.0000 - val_loss: 8209804.5000\n",
      "Epoch 1247/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8097316.5000 - val_loss: 8209174.0000\n",
      "Epoch 1248/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8096737.0000 - val_loss: 8208565.5000\n",
      "Epoch 1249/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8096161.0000 - val_loss: 8207938.0000\n",
      "Epoch 1250/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8095579.0000 - val_loss: 8207372.0000\n",
      "Epoch 1251/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8095003.0000 - val_loss: 8206746.0000\n",
      "Epoch 1252/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8094421.5000 - val_loss: 8206134.0000\n",
      "Epoch 1253/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8093845.5000 - val_loss: 8205563.0000\n",
      "Epoch 1254/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8093265.5000 - val_loss: 8204949.5000\n",
      "Epoch 1255/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8092701.5000 - val_loss: 8204341.5000\n",
      "Epoch 1256/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8092126.5000 - val_loss: 8203757.5000\n",
      "Epoch 1257/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8091554.0000 - val_loss: 8203185.5000\n",
      "Epoch 1258/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8090990.0000 - val_loss: 8202589.0000\n",
      "Epoch 1259/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8090405.5000 - val_loss: 8201997.5000\n",
      "Epoch 1260/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8089834.0000 - val_loss: 8201399.5000\n",
      "Epoch 1261/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8089262.0000 - val_loss: 8200810.0000\n",
      "Epoch 1262/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8088685.0000 - val_loss: 8200216.5000\n",
      "Epoch 1263/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8088113.5000 - val_loss: 8199612.0000\n",
      "Epoch 1264/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8087541.5000 - val_loss: 8199043.0000\n",
      "Epoch 1265/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8086976.5000 - val_loss: 8198442.0000\n",
      "Epoch 1266/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8086397.0000 - val_loss: 8197861.5000\n",
      "Epoch 1267/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8085824.0000 - val_loss: 8197264.5000\n",
      "Epoch 1268/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8085248.5000 - val_loss: 8196654.0000\n",
      "Epoch 1269/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8084675.0000 - val_loss: 8196022.0000\n",
      "Epoch 1270/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8084100.0000 - val_loss: 8195447.0000\n",
      "Epoch 1271/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8083522.0000 - val_loss: 8194848.0000\n",
      "Epoch 1272/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8082953.0000 - val_loss: 8194268.5000\n",
      "Epoch 1273/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8082381.0000 - val_loss: 8193658.0000\n",
      "Epoch 1274/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8081808.0000 - val_loss: 8193064.0000\n",
      "Epoch 1275/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8081237.5000 - val_loss: 8192479.5000\n",
      "Epoch 1276/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8080671.5000 - val_loss: 8191895.0000\n",
      "Epoch 1277/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8080093.5000 - val_loss: 8191296.5000\n",
      "Epoch 1278/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8079519.5000 - val_loss: 8190689.5000\n",
      "Epoch 1279/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8078942.0000 - val_loss: 8190110.5000\n",
      "Epoch 1280/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8078372.5000 - val_loss: 8189518.5000\n",
      "Epoch 1281/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8077796.5000 - val_loss: 8188914.0000\n",
      "Epoch 1282/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8077225.5000 - val_loss: 8188323.0000\n",
      "Epoch 1283/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8076649.5000 - val_loss: 8187726.5000\n",
      "Epoch 1284/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8076077.5000 - val_loss: 8187141.0000\n",
      "Epoch 1285/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8075502.0000 - val_loss: 8186551.0000\n",
      "Epoch 1286/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8074933.0000 - val_loss: 8185947.0000\n",
      "Epoch 1287/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8074356.5000 - val_loss: 8185365.5000\n",
      "Epoch 1288/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8073791.0000 - val_loss: 8184759.5000\n",
      "Epoch 1289/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8073225.0000 - val_loss: 8184184.5000\n",
      "Epoch 1290/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8072652.0000 - val_loss: 8183632.0000\n",
      "Epoch 1291/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8072079.5000 - val_loss: 8183020.0000\n",
      "Epoch 1292/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8071513.5000 - val_loss: 8182444.5000\n",
      "Epoch 1293/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8070933.0000 - val_loss: 8181826.5000\n",
      "Epoch 1294/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8070369.5000 - val_loss: 8181261.5000\n",
      "Epoch 1295/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8069801.0000 - val_loss: 8180655.5000\n",
      "Epoch 1296/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8069232.0000 - val_loss: 8180102.0000\n",
      "Epoch 1297/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8068666.0000 - val_loss: 8179503.5000\n",
      "Epoch 1298/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8068099.5000 - val_loss: 8178885.0000\n",
      "Epoch 1299/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8067522.5000 - val_loss: 8178337.5000\n",
      "Epoch 1300/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8066949.0000 - val_loss: 8177754.5000\n",
      "Epoch 1301/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8066388.0000 - val_loss: 8177170.0000\n",
      "Epoch 1302/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8065824.0000 - val_loss: 8176596.5000\n",
      "Epoch 1303/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8065253.0000 - val_loss: 8175984.5000\n",
      "Epoch 1304/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8064687.5000 - val_loss: 8175391.0000\n",
      "Epoch 1305/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8064109.5000 - val_loss: 8174831.0000\n",
      "Epoch 1306/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8063547.5000 - val_loss: 8174257.0000\n",
      "Epoch 1307/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8062979.0000 - val_loss: 8173674.5000\n",
      "Epoch 1308/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8062413.5000 - val_loss: 8173074.5000\n",
      "Epoch 1309/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8061844.0000 - val_loss: 8172499.0000\n",
      "Epoch 1310/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8061276.0000 - val_loss: 8171876.5000\n",
      "Epoch 1311/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8060701.5000 - val_loss: 8171310.5000\n",
      "Epoch 1312/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8060145.0000 - val_loss: 8170748.5000\n",
      "Epoch 1313/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8059573.0000 - val_loss: 8170156.5000\n",
      "Epoch 1314/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8059006.5000 - val_loss: 8169575.5000\n",
      "Epoch 1315/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8058438.5000 - val_loss: 8168979.0000\n",
      "Epoch 1316/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8057868.0000 - val_loss: 8168395.5000\n",
      "Epoch 1317/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8057304.5000 - val_loss: 8167817.0000\n",
      "Epoch 1318/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8056731.0000 - val_loss: 8167241.0000\n",
      "Epoch 1319/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8056167.5000 - val_loss: 8166656.0000\n",
      "Epoch 1320/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8055597.5000 - val_loss: 8166060.5000\n",
      "Epoch 1321/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8055035.0000 - val_loss: 8165475.0000\n",
      "Epoch 1322/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8054463.0000 - val_loss: 8164874.5000\n",
      "Epoch 1323/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8053893.5000 - val_loss: 8164303.0000\n",
      "Epoch 1324/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8053328.0000 - val_loss: 8163715.0000\n",
      "Epoch 1325/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8052776.0000 - val_loss: 8163105.5000\n",
      "Epoch 1326/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8052193.0000 - val_loss: 8162543.5000\n",
      "Epoch 1327/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8051632.0000 - val_loss: 8161954.0000\n",
      "Epoch 1328/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8051060.5000 - val_loss: 8161366.5000\n",
      "Epoch 1329/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8050497.5000 - val_loss: 8160790.0000\n",
      "Epoch 1330/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8049928.5000 - val_loss: 8160202.0000\n",
      "Epoch 1331/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8049363.0000 - val_loss: 8159632.5000\n",
      "Epoch 1332/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8048792.5000 - val_loss: 8159034.5000\n",
      "Epoch 1333/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8048234.0000 - val_loss: 8158456.0000\n",
      "Epoch 1334/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8047661.0000 - val_loss: 8157861.5000\n",
      "Epoch 1335/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8047100.5000 - val_loss: 8157274.5000\n",
      "Epoch 1336/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8046530.5000 - val_loss: 8156705.5000\n",
      "Epoch 1337/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8045965.0000 - val_loss: 8156115.5000\n",
      "Epoch 1338/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8045400.5000 - val_loss: 8155528.0000\n",
      "Epoch 1339/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8044841.0000 - val_loss: 8154973.0000\n",
      "Epoch 1340/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8044269.0000 - val_loss: 8154378.5000\n",
      "Epoch 1341/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8043712.0000 - val_loss: 8153799.0000\n",
      "Epoch 1342/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8043143.5000 - val_loss: 8153205.5000\n",
      "Epoch 1343/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8042581.0000 - val_loss: 8152645.0000\n",
      "Epoch 1344/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8042017.5000 - val_loss: 8152073.0000\n",
      "Epoch 1345/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8041458.0000 - val_loss: 8151482.5000\n",
      "Epoch 1346/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8040889.5000 - val_loss: 8150902.5000\n",
      "Epoch 1347/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8040331.5000 - val_loss: 8150315.0000\n",
      "Epoch 1348/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8039767.0000 - val_loss: 8149732.5000\n",
      "Epoch 1349/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8039200.0000 - val_loss: 8149172.5000\n",
      "Epoch 1350/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8038644.0000 - val_loss: 8148589.0000\n",
      "Epoch 1351/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8038080.0000 - val_loss: 8148005.0000\n",
      "Epoch 1352/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8037511.0000 - val_loss: 8147473.0000\n",
      "Epoch 1353/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8036951.5000 - val_loss: 8146871.5000\n",
      "Epoch 1354/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8036390.0000 - val_loss: 8146303.5000\n",
      "Epoch 1355/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8035826.0000 - val_loss: 8145709.0000\n",
      "Epoch 1356/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8035263.5000 - val_loss: 8145133.5000\n",
      "Epoch 1357/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8034704.0000 - val_loss: 8144567.0000\n",
      "Epoch 1358/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8034141.5000 - val_loss: 8143975.0000\n",
      "Epoch 1359/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8033585.5000 - val_loss: 8143407.5000\n",
      "Epoch 1360/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8033022.0000 - val_loss: 8142877.0000\n",
      "Epoch 1361/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8032459.0000 - val_loss: 8142276.0000\n",
      "Epoch 1362/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8031891.5000 - val_loss: 8141704.0000\n",
      "Epoch 1363/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8031341.0000 - val_loss: 8141149.0000\n",
      "Epoch 1364/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8030775.0000 - val_loss: 8140550.5000\n",
      "Epoch 1365/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8030213.0000 - val_loss: 8140001.0000\n",
      "Epoch 1366/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8029659.5000 - val_loss: 8139432.0000\n",
      "Epoch 1367/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8029093.5000 - val_loss: 8138821.0000\n",
      "Epoch 1368/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8028532.0000 - val_loss: 8138240.0000\n",
      "Epoch 1369/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8027966.5000 - val_loss: 8137694.0000\n",
      "Epoch 1370/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8027406.5000 - val_loss: 8137121.5000\n",
      "Epoch 1371/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8026842.5000 - val_loss: 8136525.0000\n",
      "Epoch 1372/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8026279.5000 - val_loss: 8135960.5000\n",
      "Epoch 1373/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8025718.5000 - val_loss: 8135363.5000\n",
      "Epoch 1374/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8025156.0000 - val_loss: 8134785.5000\n",
      "Epoch 1375/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8024596.0000 - val_loss: 8134208.5000\n",
      "Epoch 1376/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8024037.5000 - val_loss: 8133650.0000\n",
      "Epoch 1377/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8023467.5000 - val_loss: 8133078.5000\n",
      "Epoch 1378/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8022910.5000 - val_loss: 8132485.0000\n",
      "Epoch 1379/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8022343.0000 - val_loss: 8131921.5000\n",
      "Epoch 1380/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8021788.5000 - val_loss: 8131352.5000\n",
      "Epoch 1381/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8021228.5000 - val_loss: 8130760.5000\n",
      "Epoch 1382/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8020666.0000 - val_loss: 8130213.0000\n",
      "Epoch 1383/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8020109.0000 - val_loss: 8129627.0000\n",
      "Epoch 1384/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8019548.5000 - val_loss: 8129075.0000\n",
      "Epoch 1385/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8018988.5000 - val_loss: 8128487.0000\n",
      "Epoch 1386/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8018430.0000 - val_loss: 8127931.0000\n",
      "Epoch 1387/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8017871.0000 - val_loss: 8127364.5000\n",
      "Epoch 1388/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8017313.0000 - val_loss: 8126789.0000\n",
      "Epoch 1389/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8016752.5000 - val_loss: 8126229.5000\n",
      "Epoch 1390/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8016199.0000 - val_loss: 8125657.5000\n",
      "Epoch 1391/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8015641.0000 - val_loss: 8125096.5000\n",
      "Epoch 1392/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8015085.0000 - val_loss: 8124529.0000\n",
      "Epoch 1393/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8014528.5000 - val_loss: 8123967.0000\n",
      "Epoch 1394/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8013970.5000 - val_loss: 8123395.0000\n",
      "Epoch 1395/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8013407.0000 - val_loss: 8122801.5000\n",
      "Epoch 1396/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8012849.0000 - val_loss: 8122238.5000\n",
      "Epoch 1397/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8012294.5000 - val_loss: 8121689.5000\n",
      "Epoch 1398/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8011735.0000 - val_loss: 8121120.0000\n",
      "Epoch 1399/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8011181.0000 - val_loss: 8120533.0000\n",
      "Epoch 1400/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8010626.0000 - val_loss: 8119979.5000\n",
      "Epoch 1401/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8010066.0000 - val_loss: 8119383.5000\n",
      "Epoch 1402/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8009511.5000 - val_loss: 8118846.0000\n",
      "Epoch 1403/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8008951.5000 - val_loss: 8118247.0000\n",
      "Epoch 1404/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8008394.5000 - val_loss: 8117687.0000\n",
      "Epoch 1405/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8007844.5000 - val_loss: 8117120.0000\n",
      "Epoch 1406/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8007287.5000 - val_loss: 8116563.5000\n",
      "Epoch 1407/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8006723.5000 - val_loss: 8115990.0000\n",
      "Epoch 1408/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8006169.0000 - val_loss: 8115405.5000\n",
      "Epoch 1409/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8005615.5000 - val_loss: 8114853.0000\n",
      "Epoch 1410/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8005056.5000 - val_loss: 8114290.0000\n",
      "Epoch 1411/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8004503.0000 - val_loss: 8113723.0000\n",
      "Epoch 1412/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8003946.5000 - val_loss: 8113156.5000\n",
      "Epoch 1413/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8003389.0000 - val_loss: 8112585.0000\n",
      "Epoch 1414/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8002832.0000 - val_loss: 8112026.0000\n",
      "Epoch 1415/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8002272.5000 - val_loss: 8111426.0000\n",
      "Epoch 1416/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8001716.0000 - val_loss: 8110856.0000\n",
      "Epoch 1417/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8001159.5000 - val_loss: 8110277.0000\n",
      "Epoch 1418/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8000601.0000 - val_loss: 8109725.5000\n",
      "Epoch 1419/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8000049.0000 - val_loss: 8109145.0000\n",
      "Epoch 1420/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7999480.5000 - val_loss: 8108576.0000\n",
      "Epoch 1421/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7998926.5000 - val_loss: 8108017.0000\n",
      "Epoch 1422/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7998370.5000 - val_loss: 8107412.5000\n",
      "Epoch 1423/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7997812.0000 - val_loss: 8106861.5000\n",
      "Epoch 1424/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7997253.5000 - val_loss: 8106288.0000\n",
      "Epoch 1425/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7996702.0000 - val_loss: 8105711.0000\n",
      "Epoch 1426/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7996146.5000 - val_loss: 8105144.0000\n",
      "Epoch 1427/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7995593.0000 - val_loss: 8104569.5000\n",
      "Epoch 1428/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7995035.0000 - val_loss: 8104019.5000\n",
      "Epoch 1429/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7994483.5000 - val_loss: 8103449.0000\n",
      "Epoch 1430/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7993928.0000 - val_loss: 8102895.0000\n",
      "Epoch 1431/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7993379.5000 - val_loss: 8102320.0000\n",
      "Epoch 1432/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7992824.0000 - val_loss: 8101763.0000\n",
      "Epoch 1433/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7992275.5000 - val_loss: 8101231.5000\n",
      "Epoch 1434/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7991717.0000 - val_loss: 8100666.5000\n",
      "Epoch 1435/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7991162.5000 - val_loss: 8100069.5000\n",
      "Epoch 1436/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7990614.5000 - val_loss: 8099531.5000\n",
      "Epoch 1437/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7990058.5000 - val_loss: 8098958.0000\n",
      "Epoch 1438/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7989508.0000 - val_loss: 8098410.5000\n",
      "Epoch 1439/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7988956.0000 - val_loss: 8097829.5000\n",
      "Epoch 1440/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7988405.0000 - val_loss: 8097254.0000\n",
      "Epoch 1441/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7987848.5000 - val_loss: 8096717.0000\n",
      "Epoch 1442/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7987291.0000 - val_loss: 8096135.5000\n",
      "Epoch 1443/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7986740.0000 - val_loss: 8095564.0000\n",
      "Epoch 1444/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7986188.5000 - val_loss: 8095019.0000\n",
      "Epoch 1445/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7985633.0000 - val_loss: 8094424.0000\n",
      "Epoch 1446/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7985080.0000 - val_loss: 8093893.5000\n",
      "Epoch 1447/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7984525.0000 - val_loss: 8093327.5000\n",
      "Epoch 1448/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7983974.0000 - val_loss: 8092750.5000\n",
      "Epoch 1449/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7983420.5000 - val_loss: 8092198.5000\n",
      "Epoch 1450/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7982860.0000 - val_loss: 8091652.5000\n",
      "Epoch 1451/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7982306.5000 - val_loss: 8091054.5000\n",
      "Epoch 1452/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7981752.5000 - val_loss: 8090489.5000\n",
      "Epoch 1453/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7981202.0000 - val_loss: 8089942.5000\n",
      "Epoch 1454/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7980650.0000 - val_loss: 8089393.5000\n",
      "Epoch 1455/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7980099.5000 - val_loss: 8088826.0000\n",
      "Epoch 1456/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7979549.0000 - val_loss: 8088284.5000\n",
      "Epoch 1457/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7979000.0000 - val_loss: 8087725.0000\n",
      "Epoch 1458/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7978439.0000 - val_loss: 8087138.5000\n",
      "Epoch 1459/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7977896.0000 - val_loss: 8086597.0000\n",
      "Epoch 1460/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7977349.0000 - val_loss: 8086051.0000\n",
      "Epoch 1461/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7976790.5000 - val_loss: 8085492.0000\n",
      "Epoch 1462/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7976242.0000 - val_loss: 8084912.0000\n",
      "Epoch 1463/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7975690.5000 - val_loss: 8084366.0000\n",
      "Epoch 1464/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7975139.5000 - val_loss: 8083808.0000\n",
      "Epoch 1465/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7974584.0000 - val_loss: 8083224.5000\n",
      "Epoch 1466/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7974031.5000 - val_loss: 8082671.5000\n",
      "Epoch 1467/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7973485.5000 - val_loss: 8082103.5000\n",
      "Epoch 1468/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7972925.5000 - val_loss: 8081539.0000\n",
      "Epoch 1469/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7972377.0000 - val_loss: 8080999.5000\n",
      "Epoch 1470/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7971832.0000 - val_loss: 8080420.5000\n",
      "Epoch 1471/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7971271.0000 - val_loss: 8079881.5000\n",
      "Epoch 1472/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7970729.5000 - val_loss: 8079313.5000\n",
      "Epoch 1473/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7970172.0000 - val_loss: 8078743.0000\n",
      "Epoch 1474/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7969628.0000 - val_loss: 8078208.5000\n",
      "Epoch 1475/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7969072.0000 - val_loss: 8077627.0000\n",
      "Epoch 1476/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7968521.5000 - val_loss: 8077076.5000\n",
      "Epoch 1477/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7967981.0000 - val_loss: 8076516.0000\n",
      "Epoch 1478/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7967419.5000 - val_loss: 8075941.5000\n",
      "Epoch 1479/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7966870.5000 - val_loss: 8075370.0000\n",
      "Epoch 1480/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7966323.5000 - val_loss: 8074818.5000\n",
      "Epoch 1481/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7965772.5000 - val_loss: 8074278.5000\n",
      "Epoch 1482/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7965220.5000 - val_loss: 8073707.5000\n",
      "Epoch 1483/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7964672.5000 - val_loss: 8073127.0000\n",
      "Epoch 1484/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7964117.0000 - val_loss: 8072596.5000\n",
      "Epoch 1485/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7963568.5000 - val_loss: 8072041.0000\n",
      "Epoch 1486/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7963019.5000 - val_loss: 8071472.0000\n",
      "Epoch 1487/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7962470.0000 - val_loss: 8070929.0000\n",
      "Epoch 1488/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7961915.5000 - val_loss: 8070373.5000\n",
      "Epoch 1489/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7961372.0000 - val_loss: 8069816.0000\n",
      "Epoch 1490/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7960823.5000 - val_loss: 8069239.0000\n",
      "Epoch 1491/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 7960276.0000 - val_loss: 8068685.5000\n",
      "Epoch 1492/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7959725.5000 - val_loss: 8068124.0000\n",
      "Epoch 1493/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7959175.5000 - val_loss: 8067590.0000\n",
      "Epoch 1494/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7958625.0000 - val_loss: 8067024.5000\n",
      "Epoch 1495/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7958083.5000 - val_loss: 8066452.0000\n",
      "Epoch 1496/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7957533.0000 - val_loss: 8065917.0000\n",
      "Epoch 1497/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7956982.5000 - val_loss: 8065351.0000\n",
      "Epoch 1498/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7956435.5000 - val_loss: 8064784.5000\n",
      "Epoch 1499/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7955888.5000 - val_loss: 8064222.0000\n",
      "Epoch 1500/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7955342.5000 - val_loss: 8063680.5000\n",
      "Epoch 1501/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7954791.5000 - val_loss: 8063124.5000\n",
      "Epoch 1502/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7954253.5000 - val_loss: 8062553.0000\n",
      "Epoch 1503/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7953697.0000 - val_loss: 8062015.0000\n",
      "Epoch 1504/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7953152.5000 - val_loss: 8061454.0000\n",
      "Epoch 1505/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7952606.5000 - val_loss: 8060910.0000\n",
      "Epoch 1506/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7952056.5000 - val_loss: 8060340.0000\n",
      "Epoch 1507/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7951508.0000 - val_loss: 8059779.0000\n",
      "Epoch 1508/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7950955.5000 - val_loss: 8059245.0000\n",
      "Epoch 1509/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7950420.5000 - val_loss: 8058678.0000\n",
      "Epoch 1510/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7949873.5000 - val_loss: 8058111.5000\n",
      "Epoch 1511/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7949326.0000 - val_loss: 8057581.0000\n",
      "Epoch 1512/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7948778.0000 - val_loss: 8057026.5000\n",
      "Epoch 1513/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7948231.5000 - val_loss: 8056483.5000\n",
      "Epoch 1514/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7947685.5000 - val_loss: 8055945.5000\n",
      "Epoch 1515/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7947141.5000 - val_loss: 8055364.0000\n",
      "Epoch 1516/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7946593.5000 - val_loss: 8054819.5000\n",
      "Epoch 1517/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7946054.0000 - val_loss: 8054277.0000\n",
      "Epoch 1518/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7945501.5000 - val_loss: 8053723.5000\n",
      "Epoch 1519/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7944957.5000 - val_loss: 8053165.0000\n",
      "Epoch 1520/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7944410.0000 - val_loss: 8052598.5000\n",
      "Epoch 1521/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7943861.5000 - val_loss: 8052048.5000\n",
      "Epoch 1522/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7943318.5000 - val_loss: 8051502.5000\n",
      "Epoch 1523/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7942768.5000 - val_loss: 8050927.5000\n",
      "Epoch 1524/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7942225.0000 - val_loss: 8050371.5000\n",
      "Epoch 1525/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7941679.5000 - val_loss: 8049844.0000\n",
      "Epoch 1526/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7941136.5000 - val_loss: 8049279.5000\n",
      "Epoch 1527/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7940590.0000 - val_loss: 8048734.5000\n",
      "Epoch 1528/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7940045.0000 - val_loss: 8048202.5000\n",
      "Epoch 1529/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7939507.5000 - val_loss: 8047670.0000\n",
      "Epoch 1530/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7938958.0000 - val_loss: 8047091.5000\n",
      "Epoch 1531/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7938411.0000 - val_loss: 8046544.0000\n",
      "Epoch 1532/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7937863.0000 - val_loss: 8045985.5000\n",
      "Epoch 1533/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7937321.0000 - val_loss: 8045434.0000\n",
      "Epoch 1534/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7936776.0000 - val_loss: 8044869.5000\n",
      "Epoch 1535/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7936232.5000 - val_loss: 8044347.0000\n",
      "Epoch 1536/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7935692.5000 - val_loss: 8043813.5000\n",
      "Epoch 1537/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7935144.0000 - val_loss: 8043237.5000\n",
      "Epoch 1538/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7934601.0000 - val_loss: 8042686.0000\n",
      "Epoch 1539/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7934057.0000 - val_loss: 8042145.5000\n",
      "Epoch 1540/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7933509.0000 - val_loss: 8041586.0000\n",
      "Epoch 1541/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7932971.0000 - val_loss: 8041035.5000\n",
      "Epoch 1542/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7932421.0000 - val_loss: 8040477.0000\n",
      "Epoch 1543/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7931875.0000 - val_loss: 8039927.0000\n",
      "Epoch 1544/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7931324.0000 - val_loss: 8039365.5000\n",
      "Epoch 1545/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7930780.5000 - val_loss: 8038799.5000\n",
      "Epoch 1546/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7930236.0000 - val_loss: 8038244.5000\n",
      "Epoch 1547/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7929693.0000 - val_loss: 8037708.0000\n",
      "Epoch 1548/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7929147.5000 - val_loss: 8037169.0000\n",
      "Epoch 1549/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7928609.0000 - val_loss: 8036623.5000\n",
      "Epoch 1550/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7928060.0000 - val_loss: 8036057.5000\n",
      "Epoch 1551/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 7927518.5000 - val_loss: 8035533.5000\n",
      "Epoch 1552/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7926976.0000 - val_loss: 8034965.5000\n",
      "Epoch 1553/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7926427.0000 - val_loss: 8034410.0000\n",
      "Epoch 1554/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7925882.5000 - val_loss: 8033870.5000\n",
      "Epoch 1555/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7925340.5000 - val_loss: 8033315.0000\n",
      "Epoch 1556/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7924795.5000 - val_loss: 8032766.0000\n",
      "Epoch 1557/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7924252.0000 - val_loss: 8032218.5000\n",
      "Epoch 1558/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7923721.0000 - val_loss: 8031679.5000\n",
      "Epoch 1559/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7923166.0000 - val_loss: 8031104.0000\n",
      "Epoch 1560/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7922622.0000 - val_loss: 8030565.5000\n",
      "Epoch 1561/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7922079.0000 - val_loss: 8030004.0000\n",
      "Epoch 1562/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7921541.5000 - val_loss: 8029470.5000\n",
      "Epoch 1563/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7920998.0000 - val_loss: 8028906.5000\n",
      "Epoch 1564/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7920453.5000 - val_loss: 8028367.0000\n",
      "Epoch 1565/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7919913.0000 - val_loss: 8027845.0000\n",
      "Epoch 1566/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7919373.5000 - val_loss: 8027270.5000\n",
      "Epoch 1567/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7918827.0000 - val_loss: 8026735.0000\n",
      "Epoch 1568/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7918281.5000 - val_loss: 8026187.5000\n",
      "Epoch 1569/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7917744.5000 - val_loss: 8025656.0000\n",
      "Epoch 1570/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7917205.5000 - val_loss: 8025095.5000\n",
      "Epoch 1571/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7916652.0000 - val_loss: 8024559.5000\n",
      "Epoch 1572/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7916113.5000 - val_loss: 8024010.0000\n",
      "Epoch 1573/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7915578.5000 - val_loss: 8023464.0000\n",
      "Epoch 1574/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7915031.5000 - val_loss: 8022924.0000\n",
      "Epoch 1575/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7914488.5000 - val_loss: 8022374.0000\n",
      "Epoch 1576/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7913953.5000 - val_loss: 8021808.0000\n",
      "Epoch 1577/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7913411.0000 - val_loss: 8021273.0000\n",
      "Epoch 1578/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7912871.0000 - val_loss: 8020744.0000\n",
      "Epoch 1579/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7912331.0000 - val_loss: 8020186.5000\n",
      "Epoch 1580/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7911791.0000 - val_loss: 8019631.5000\n",
      "Epoch 1581/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7911247.5000 - val_loss: 8019081.0000\n",
      "Epoch 1582/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7910704.5000 - val_loss: 8018521.5000\n",
      "Epoch 1583/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7910165.0000 - val_loss: 8017992.5000\n",
      "Epoch 1584/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7909633.0000 - val_loss: 8017445.0000\n",
      "Epoch 1585/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7909100.5000 - val_loss: 8016925.5000\n",
      "Epoch 1586/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7908548.5000 - val_loss: 8016386.0000\n",
      "Epoch 1587/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7908007.5000 - val_loss: 8015811.5000\n",
      "Epoch 1588/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7907469.5000 - val_loss: 8015268.5000\n",
      "Epoch 1589/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7906928.5000 - val_loss: 8014731.0000\n",
      "Epoch 1590/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7906390.0000 - val_loss: 8014186.5000\n",
      "Epoch 1591/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7905846.0000 - val_loss: 8013657.0000\n",
      "Epoch 1592/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7905306.5000 - val_loss: 8013108.5000\n",
      "Epoch 1593/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7904769.5000 - val_loss: 8012562.5000\n",
      "Epoch 1594/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7904230.0000 - val_loss: 8012017.0000\n",
      "Epoch 1595/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 7903693.5000 - val_loss: 8011506.0000\n",
      "Epoch 1596/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7903152.5000 - val_loss: 8010939.0000\n",
      "Epoch 1597/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7902608.0000 - val_loss: 8010392.5000\n",
      "Epoch 1598/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7902070.0000 - val_loss: 8009849.5000\n",
      "Epoch 1599/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7901529.5000 - val_loss: 8009327.0000\n",
      "Epoch 1600/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7900994.5000 - val_loss: 8008776.5000\n",
      "Epoch 1601/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7900454.0000 - val_loss: 8008208.5000\n",
      "Epoch 1602/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7899915.5000 - val_loss: 8007689.0000\n",
      "Epoch 1603/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7899377.0000 - val_loss: 8007144.5000\n",
      "Epoch 1604/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7898831.5000 - val_loss: 8006590.0000\n",
      "Epoch 1605/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7898290.0000 - val_loss: 8006051.5000\n",
      "Epoch 1606/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7897751.0000 - val_loss: 8005530.5000\n",
      "Epoch 1607/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7897220.0000 - val_loss: 8004947.5000\n",
      "Epoch 1608/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7896677.5000 - val_loss: 8004418.5000\n",
      "Epoch 1609/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7896147.5000 - val_loss: 8003913.0000\n",
      "Epoch 1610/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7895601.5000 - val_loss: 8003368.5000\n",
      "Epoch 1611/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7895066.5000 - val_loss: 8002821.0000\n",
      "Epoch 1612/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7894532.5000 - val_loss: 8002290.0000\n",
      "Epoch 1613/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7893998.0000 - val_loss: 8001746.0000\n",
      "Epoch 1614/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7893452.0000 - val_loss: 8001204.0000\n",
      "Epoch 1615/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7892920.0000 - val_loss: 8000652.5000\n",
      "Epoch 1616/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7892382.0000 - val_loss: 8000118.5000\n",
      "Epoch 1617/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7891845.5000 - val_loss: 7999574.5000\n",
      "Epoch 1618/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7891312.5000 - val_loss: 7999050.5000\n",
      "Epoch 1619/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7890773.0000 - val_loss: 7998496.0000\n",
      "Epoch 1620/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7890229.0000 - val_loss: 7997959.5000\n",
      "Epoch 1621/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7889692.0000 - val_loss: 7997406.0000\n",
      "Epoch 1622/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7889142.5000 - val_loss: 7996860.0000\n",
      "Epoch 1623/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7888610.0000 - val_loss: 7996309.5000\n",
      "Epoch 1624/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7888076.0000 - val_loss: 7995778.0000\n",
      "Epoch 1625/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7887538.5000 - val_loss: 7995250.0000\n",
      "Epoch 1626/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 7887000.0000 - val_loss: 7994706.0000\n",
      "Epoch 1627/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7886459.0000 - val_loss: 7994147.0000\n",
      "Epoch 1628/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7885922.0000 - val_loss: 7993621.5000\n",
      "Epoch 1629/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7885390.5000 - val_loss: 7993075.5000\n",
      "Epoch 1630/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7884846.5000 - val_loss: 7992536.0000\n",
      "Epoch 1631/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7884313.0000 - val_loss: 7991999.0000\n",
      "Epoch 1632/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7883771.0000 - val_loss: 7991451.5000\n",
      "Epoch 1633/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7883231.5000 - val_loss: 7990901.0000\n",
      "Epoch 1634/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7882694.0000 - val_loss: 7990352.0000\n",
      "Epoch 1635/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7882156.5000 - val_loss: 7989810.5000\n",
      "Epoch 1636/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7881620.5000 - val_loss: 7989256.0000\n",
      "Epoch 1637/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7881093.5000 - val_loss: 7988756.0000\n",
      "Epoch 1638/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7880548.5000 - val_loss: 7988215.0000\n",
      "Epoch 1639/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7880018.0000 - val_loss: 7987683.0000\n",
      "Epoch 1640/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7879478.5000 - val_loss: 7987152.0000\n",
      "Epoch 1641/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7878945.5000 - val_loss: 7986618.5000\n",
      "Epoch 1642/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7878416.5000 - val_loss: 7986063.0000\n",
      "Epoch 1643/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7877881.5000 - val_loss: 7985563.5000\n",
      "Epoch 1644/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7877344.5000 - val_loss: 7985008.5000\n",
      "Epoch 1645/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7876809.5000 - val_loss: 7984500.0000\n",
      "Epoch 1646/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7876282.0000 - val_loss: 7983946.5000\n",
      "Epoch 1647/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7875744.0000 - val_loss: 7983437.0000\n",
      "Epoch 1648/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7875207.5000 - val_loss: 7982892.5000\n",
      "Epoch 1649/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7874680.0000 - val_loss: 7982356.5000\n",
      "Epoch 1650/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7874139.0000 - val_loss: 7981822.0000\n",
      "Epoch 1651/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7873604.0000 - val_loss: 7981275.5000\n",
      "Epoch 1652/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7873074.5000 - val_loss: 7980749.0000\n",
      "Epoch 1653/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7872532.0000 - val_loss: 7980222.0000\n",
      "Epoch 1654/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7872000.0000 - val_loss: 7979694.5000\n",
      "Epoch 1655/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7871466.5000 - val_loss: 7979159.0000\n",
      "Epoch 1656/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7870930.0000 - val_loss: 7978612.0000\n",
      "Epoch 1657/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7870402.5000 - val_loss: 7978064.5000\n",
      "Epoch 1658/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7869858.0000 - val_loss: 7977541.5000\n",
      "Epoch 1659/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7869324.5000 - val_loss: 7976997.5000\n",
      "Epoch 1660/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7868790.0000 - val_loss: 7976468.0000\n",
      "Epoch 1661/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7868262.5000 - val_loss: 7975933.0000\n",
      "Epoch 1662/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7867731.5000 - val_loss: 7975373.0000\n",
      "Epoch 1663/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7867187.0000 - val_loss: 7974863.0000\n",
      "Epoch 1664/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7866658.5000 - val_loss: 7974304.5000\n",
      "Epoch 1665/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7866125.5000 - val_loss: 7973769.5000\n",
      "Epoch 1666/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7865594.5000 - val_loss: 7973258.5000\n",
      "Epoch 1667/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7865054.5000 - val_loss: 7972742.5000\n",
      "Epoch 1668/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7864525.0000 - val_loss: 7972185.0000\n",
      "Epoch 1669/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7863995.5000 - val_loss: 7971661.0000\n",
      "Epoch 1670/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7863465.0000 - val_loss: 7971149.0000\n",
      "Epoch 1671/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 7862925.0000 - val_loss: 7970619.0000\n",
      "Epoch 1672/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7862398.5000 - val_loss: 7970071.5000\n",
      "Epoch 1673/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7861869.0000 - val_loss: 7969548.5000\n",
      "Epoch 1674/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7861335.5000 - val_loss: 7969005.5000\n",
      "Epoch 1675/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7860804.0000 - val_loss: 7968490.0000\n",
      "Epoch 1676/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7860265.5000 - val_loss: 7967954.0000\n",
      "Epoch 1677/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7859730.0000 - val_loss: 7967410.5000\n",
      "Epoch 1678/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7859195.0000 - val_loss: 7966871.5000\n",
      "Epoch 1679/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7858664.5000 - val_loss: 7966342.0000\n",
      "Epoch 1680/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7858125.0000 - val_loss: 7965796.0000\n",
      "Epoch 1681/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7857596.5000 - val_loss: 7965269.0000\n",
      "Epoch 1682/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7857059.5000 - val_loss: 7964724.0000\n",
      "Epoch 1683/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7856527.5000 - val_loss: 7964206.0000\n",
      "Epoch 1684/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7856001.5000 - val_loss: 7963672.5000\n",
      "Epoch 1685/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 7855468.5000 - val_loss: 7963134.5000\n",
      "Epoch 1686/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 7854933.0000 - val_loss: 7962602.5000\n",
      "Epoch 1687/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7854399.5000 - val_loss: 7962058.5000\n",
      "Epoch 1688/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7853866.5000 - val_loss: 7961529.5000\n",
      "Epoch 1689/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7853342.0000 - val_loss: 7961018.5000\n",
      "Epoch 1690/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7852805.5000 - val_loss: 7960474.0000\n",
      "Epoch 1691/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7852278.0000 - val_loss: 7959947.0000\n",
      "Epoch 1692/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7851746.0000 - val_loss: 7959419.5000\n",
      "Epoch 1693/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7851210.5000 - val_loss: 7958890.5000\n",
      "Epoch 1694/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7850677.5000 - val_loss: 7958352.5000\n",
      "Epoch 1695/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7850145.5000 - val_loss: 7957821.5000\n",
      "Epoch 1696/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7849621.0000 - val_loss: 7957285.0000\n",
      "Epoch 1697/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7849081.0000 - val_loss: 7956749.5000\n",
      "Epoch 1698/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7848545.0000 - val_loss: 7956224.0000\n",
      "Epoch 1699/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7848014.5000 - val_loss: 7955690.5000\n",
      "Epoch 1700/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7847482.5000 - val_loss: 7955155.5000\n",
      "Epoch 1701/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7846952.0000 - val_loss: 7954637.0000\n",
      "Epoch 1702/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7846418.5000 - val_loss: 7954104.0000\n",
      "Epoch 1703/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7845890.0000 - val_loss: 7953569.5000\n",
      "Epoch 1704/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7845361.0000 - val_loss: 7953024.5000\n",
      "Epoch 1705/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7844827.5000 - val_loss: 7952495.5000\n",
      "Epoch 1706/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7844295.5000 - val_loss: 7951973.5000\n",
      "Epoch 1707/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7843768.0000 - val_loss: 7951426.5000\n",
      "Epoch 1708/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7843232.5000 - val_loss: 7950912.5000\n",
      "Epoch 1709/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7842699.0000 - val_loss: 7950371.0000\n",
      "Epoch 1710/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7842168.5000 - val_loss: 7949854.5000\n",
      "Epoch 1711/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7841639.5000 - val_loss: 7949298.5000\n",
      "Epoch 1712/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7841109.5000 - val_loss: 7948784.5000\n",
      "Epoch 1713/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7840580.0000 - val_loss: 7948276.0000\n",
      "Epoch 1714/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7840050.0000 - val_loss: 7947741.0000\n",
      "Epoch 1715/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7839521.0000 - val_loss: 7947208.0000\n",
      "Epoch 1716/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7838997.0000 - val_loss: 7946673.5000\n",
      "Epoch 1717/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7838462.0000 - val_loss: 7946149.5000\n",
      "Epoch 1718/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7837935.5000 - val_loss: 7945613.5000\n",
      "Epoch 1719/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7837410.5000 - val_loss: 7945079.0000\n",
      "Epoch 1720/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7836874.5000 - val_loss: 7944568.5000\n",
      "Epoch 1721/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7836352.5000 - val_loss: 7944036.5000\n",
      "Epoch 1722/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7835820.0000 - val_loss: 7943498.5000\n",
      "Epoch 1723/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7835288.0000 - val_loss: 7942961.0000\n",
      "Epoch 1724/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7834765.5000 - val_loss: 7942453.5000\n",
      "Epoch 1725/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7834232.0000 - val_loss: 7941928.5000\n",
      "Epoch 1726/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7833700.0000 - val_loss: 7941400.5000\n",
      "Epoch 1727/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7833176.0000 - val_loss: 7940871.5000\n",
      "Epoch 1728/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7832643.5000 - val_loss: 7940341.5000\n",
      "Epoch 1729/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7832116.5000 - val_loss: 7939829.0000\n",
      "Epoch 1730/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7831587.5000 - val_loss: 7939280.5000\n",
      "Epoch 1731/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7831054.0000 - val_loss: 7938760.5000\n",
      "Epoch 1732/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7830525.0000 - val_loss: 7938243.5000\n",
      "Epoch 1733/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7830002.5000 - val_loss: 7937744.0000\n",
      "Epoch 1734/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7829463.0000 - val_loss: 7937204.5000\n",
      "Epoch 1735/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7828938.5000 - val_loss: 7936667.5000\n",
      "Epoch 1736/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7828412.5000 - val_loss: 7936151.0000\n",
      "Epoch 1737/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7827882.0000 - val_loss: 7935614.0000\n",
      "Epoch 1738/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7827353.0000 - val_loss: 7935104.0000\n",
      "Epoch 1739/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7826828.5000 - val_loss: 7934551.5000\n",
      "Epoch 1740/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7826296.5000 - val_loss: 7934031.0000\n",
      "Epoch 1741/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7825769.5000 - val_loss: 7933525.0000\n",
      "Epoch 1742/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7825245.0000 - val_loss: 7932994.0000\n",
      "Epoch 1743/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7824714.5000 - val_loss: 7932458.0000\n",
      "Epoch 1744/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7824191.5000 - val_loss: 7931946.0000\n",
      "Epoch 1745/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7823661.5000 - val_loss: 7931426.0000\n",
      "Epoch 1746/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7823127.5000 - val_loss: 7930895.0000\n",
      "Epoch 1747/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7822597.0000 - val_loss: 7930360.5000\n",
      "Epoch 1748/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7822079.0000 - val_loss: 7929823.5000\n",
      "Epoch 1749/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7821542.5000 - val_loss: 7929302.0000\n",
      "Epoch 1750/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7821009.5000 - val_loss: 7928788.5000\n",
      "Epoch 1751/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7820479.0000 - val_loss: 7928257.0000\n",
      "Epoch 1752/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7819951.5000 - val_loss: 7927733.5000\n",
      "Epoch 1753/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7819424.0000 - val_loss: 7927198.5000\n",
      "Epoch 1754/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7818901.0000 - val_loss: 7926679.5000\n",
      "Epoch 1755/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7818372.5000 - val_loss: 7926161.0000\n",
      "Epoch 1756/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7817845.0000 - val_loss: 7925649.0000\n",
      "Epoch 1757/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7817319.5000 - val_loss: 7925126.5000\n",
      "Epoch 1758/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7816787.0000 - val_loss: 7924594.5000\n",
      "Epoch 1759/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7816264.0000 - val_loss: 7924061.0000\n",
      "Epoch 1760/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7815735.0000 - val_loss: 7923542.5000\n",
      "Epoch 1761/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7815215.5000 - val_loss: 7923032.0000\n",
      "Epoch 1762/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7814688.0000 - val_loss: 7922523.5000\n",
      "Epoch 1763/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7814163.5000 - val_loss: 7921980.0000\n",
      "Epoch 1764/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7813633.5000 - val_loss: 7921459.0000\n",
      "Epoch 1765/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7813109.5000 - val_loss: 7920948.5000\n",
      "Epoch 1766/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7812591.0000 - val_loss: 7920450.0000\n",
      "Epoch 1767/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7812062.0000 - val_loss: 7919903.0000\n",
      "Epoch 1768/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7811535.0000 - val_loss: 7919392.0000\n",
      "Epoch 1769/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7811015.5000 - val_loss: 7918900.5000\n",
      "Epoch 1770/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7810484.5000 - val_loss: 7918341.0000\n",
      "Epoch 1771/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7809960.0000 - val_loss: 7917827.0000\n",
      "Epoch 1772/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7809436.5000 - val_loss: 7917301.5000\n",
      "Epoch 1773/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7808904.5000 - val_loss: 7916766.5000\n",
      "Epoch 1774/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7808384.0000 - val_loss: 7916256.0000\n",
      "Epoch 1775/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7807847.5000 - val_loss: 7915720.5000\n",
      "Epoch 1776/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7807331.0000 - val_loss: 7915198.0000\n",
      "Epoch 1777/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7806805.0000 - val_loss: 7914659.0000\n",
      "Epoch 1778/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7806278.0000 - val_loss: 7914142.5000\n",
      "Epoch 1779/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7805752.0000 - val_loss: 7913610.5000\n",
      "Epoch 1780/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7805228.0000 - val_loss: 7913087.5000\n",
      "Epoch 1781/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7804699.0000 - val_loss: 7912566.5000\n",
      "Epoch 1782/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7804183.5000 - val_loss: 7912051.5000\n",
      "Epoch 1783/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7803651.5000 - val_loss: 7911524.5000\n",
      "Epoch 1784/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7803128.0000 - val_loss: 7911001.5000\n",
      "Epoch 1785/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7802606.0000 - val_loss: 7910477.5000\n",
      "Epoch 1786/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7802078.5000 - val_loss: 7909972.5000\n",
      "Epoch 1787/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7801548.5000 - val_loss: 7909448.5000\n",
      "Epoch 1788/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7801024.5000 - val_loss: 7908936.0000\n",
      "Epoch 1789/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7800505.0000 - val_loss: 7908398.0000\n",
      "Epoch 1790/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7799974.0000 - val_loss: 7907884.5000\n",
      "Epoch 1791/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7799453.0000 - val_loss: 7907380.5000\n",
      "Epoch 1792/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7798928.5000 - val_loss: 7906866.5000\n",
      "Epoch 1793/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7798409.0000 - val_loss: 7906356.5000\n",
      "Epoch 1794/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7797875.5000 - val_loss: 7905803.0000\n",
      "Epoch 1795/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7797354.0000 - val_loss: 7905277.0000\n",
      "Epoch 1796/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7796827.0000 - val_loss: 7904782.0000\n",
      "Epoch 1797/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7796307.0000 - val_loss: 7904263.5000\n",
      "Epoch 1798/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7795783.0000 - val_loss: 7903735.0000\n",
      "Epoch 1799/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7795254.0000 - val_loss: 7903221.0000\n",
      "Epoch 1800/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7794730.0000 - val_loss: 7902681.5000\n",
      "Epoch 1801/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7794208.5000 - val_loss: 7902186.5000\n",
      "Epoch 1802/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7793685.5000 - val_loss: 7901651.0000\n",
      "Epoch 1803/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7793161.5000 - val_loss: 7901128.0000\n",
      "Epoch 1804/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7792635.0000 - val_loss: 7900600.0000\n",
      "Epoch 1805/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7792112.5000 - val_loss: 7900078.0000\n",
      "Epoch 1806/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7791584.0000 - val_loss: 7899553.5000\n",
      "Epoch 1807/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7791064.0000 - val_loss: 7899039.0000\n",
      "Epoch 1808/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7790542.5000 - val_loss: 7898522.0000\n",
      "Epoch 1809/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7790013.5000 - val_loss: 7897987.5000\n",
      "Epoch 1810/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 7789486.0000 - val_loss: 7897457.0000\n",
      "Epoch 1811/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7788966.5000 - val_loss: 7896943.0000\n",
      "Epoch 1812/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7788447.0000 - val_loss: 7896421.5000\n",
      "Epoch 1813/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7787924.0000 - val_loss: 7895913.0000\n",
      "Epoch 1814/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7787393.5000 - val_loss: 7895388.5000\n",
      "Epoch 1815/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7786874.0000 - val_loss: 7894853.0000\n",
      "Epoch 1816/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7786345.5000 - val_loss: 7894338.0000\n",
      "Epoch 1817/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7785821.5000 - val_loss: 7893828.0000\n",
      "Epoch 1818/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7785299.5000 - val_loss: 7893309.5000\n",
      "Epoch 1819/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7784785.0000 - val_loss: 7892809.0000\n",
      "Epoch 1820/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7784265.0000 - val_loss: 7892243.0000\n",
      "Epoch 1821/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7783735.0000 - val_loss: 7891764.0000\n",
      "Epoch 1822/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7783205.5000 - val_loss: 7891239.0000\n",
      "Epoch 1823/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7782686.0000 - val_loss: 7890677.0000\n",
      "Epoch 1824/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7782162.0000 - val_loss: 7890178.0000\n",
      "Epoch 1825/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7781636.0000 - val_loss: 7889669.0000\n",
      "Epoch 1826/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7781119.0000 - val_loss: 7889147.5000\n",
      "Epoch 1827/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7780596.5000 - val_loss: 7888602.5000\n",
      "Epoch 1828/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7780068.0000 - val_loss: 7888092.5000\n",
      "Epoch 1829/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7779543.0000 - val_loss: 7887585.0000\n",
      "Epoch 1830/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7779020.0000 - val_loss: 7887065.0000\n",
      "Epoch 1831/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7778495.0000 - val_loss: 7886544.0000\n",
      "Epoch 1832/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7777971.5000 - val_loss: 7886007.0000\n",
      "Epoch 1833/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7777442.5000 - val_loss: 7885503.0000\n",
      "Epoch 1834/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7776926.0000 - val_loss: 7884983.5000\n",
      "Epoch 1835/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7776406.5000 - val_loss: 7884472.0000\n",
      "Epoch 1836/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7775884.0000 - val_loss: 7883950.5000\n",
      "Epoch 1837/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7775360.0000 - val_loss: 7883425.5000\n",
      "Epoch 1838/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7774840.0000 - val_loss: 7882936.0000\n",
      "Epoch 1839/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7774319.0000 - val_loss: 7882391.5000\n",
      "Epoch 1840/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7773794.5000 - val_loss: 7881883.5000\n",
      "Epoch 1841/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7773270.0000 - val_loss: 7881370.5000\n",
      "Epoch 1842/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7772758.5000 - val_loss: 7880840.0000\n",
      "Epoch 1843/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7772235.5000 - val_loss: 7880326.5000\n",
      "Epoch 1844/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7771718.5000 - val_loss: 7879817.5000\n",
      "Epoch 1845/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7771194.5000 - val_loss: 7879321.0000\n",
      "Epoch 1846/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7770673.5000 - val_loss: 7878782.5000\n",
      "Epoch 1847/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7770150.5000 - val_loss: 7878270.5000\n",
      "Epoch 1848/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7769635.0000 - val_loss: 7877755.5000\n",
      "Epoch 1849/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7769110.0000 - val_loss: 7877237.0000\n",
      "Epoch 1850/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7768595.5000 - val_loss: 7876726.5000\n",
      "Epoch 1851/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7768073.0000 - val_loss: 7876238.0000\n",
      "Epoch 1852/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7767547.0000 - val_loss: 7875707.0000\n",
      "Epoch 1853/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7767027.5000 - val_loss: 7875187.5000\n",
      "Epoch 1854/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7766505.0000 - val_loss: 7874657.5000\n",
      "Epoch 1855/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7765990.0000 - val_loss: 7874142.0000\n",
      "Epoch 1856/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7765467.0000 - val_loss: 7873645.0000\n",
      "Epoch 1857/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7764947.0000 - val_loss: 7873122.5000\n",
      "Epoch 1858/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7764430.5000 - val_loss: 7872592.5000\n",
      "Epoch 1859/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7763903.5000 - val_loss: 7872103.0000\n",
      "Epoch 1860/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7763381.0000 - val_loss: 7871597.5000\n",
      "Epoch 1861/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7762870.0000 - val_loss: 7871045.5000\n",
      "Epoch 1862/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7762345.5000 - val_loss: 7870523.0000\n",
      "Epoch 1863/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7761819.0000 - val_loss: 7870019.5000\n",
      "Epoch 1864/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7761303.0000 - val_loss: 7869504.5000\n",
      "Epoch 1865/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7760782.0000 - val_loss: 7868996.0000\n",
      "Epoch 1866/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7760262.5000 - val_loss: 7868485.5000\n",
      "Epoch 1867/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7759744.5000 - val_loss: 7867946.0000\n",
      "Epoch 1868/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7759231.0000 - val_loss: 7867455.5000\n",
      "Epoch 1869/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7758703.0000 - val_loss: 7866944.5000\n",
      "Epoch 1870/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7758190.0000 - val_loss: 7866459.5000\n",
      "Epoch 1871/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7757668.5000 - val_loss: 7865929.0000\n",
      "Epoch 1872/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 7757147.0000 - val_loss: 7865416.0000\n",
      "Epoch 1873/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7756632.5000 - val_loss: 7864884.0000\n",
      "Epoch 1874/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7756103.5000 - val_loss: 7864386.0000\n",
      "Epoch 1875/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7755588.5000 - val_loss: 7863864.0000\n",
      "Epoch 1876/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7755067.5000 - val_loss: 7863348.0000\n",
      "Epoch 1877/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7754549.0000 - val_loss: 7862824.0000\n",
      "Epoch 1878/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7754035.0000 - val_loss: 7862329.5000\n",
      "Epoch 1879/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7753512.5000 - val_loss: 7861795.0000\n",
      "Epoch 1880/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7752992.0000 - val_loss: 7861292.5000\n",
      "Epoch 1881/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7752471.5000 - val_loss: 7860776.5000\n",
      "Epoch 1882/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 7751957.0000 - val_loss: 7860266.0000\n",
      "Epoch 1883/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7751434.5000 - val_loss: 7859735.0000\n",
      "Epoch 1884/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7750919.0000 - val_loss: 7859227.5000\n",
      "Epoch 1885/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7750400.5000 - val_loss: 7858730.0000\n",
      "Epoch 1886/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7749881.0000 - val_loss: 7858213.0000\n",
      "Epoch 1887/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7749363.0000 - val_loss: 7857697.5000\n",
      "Epoch 1888/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7748844.5000 - val_loss: 7857194.0000\n",
      "Epoch 1889/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7748326.5000 - val_loss: 7856686.0000\n",
      "Epoch 1890/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7747807.0000 - val_loss: 7856194.5000\n",
      "Epoch 1891/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7747287.5000 - val_loss: 7855673.5000\n",
      "Epoch 1892/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7746772.0000 - val_loss: 7855165.5000\n",
      "Epoch 1893/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7746249.5000 - val_loss: 7854647.0000\n",
      "Epoch 1894/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7745733.0000 - val_loss: 7854129.5000\n",
      "Epoch 1895/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7745222.5000 - val_loss: 7853625.5000\n",
      "Epoch 1896/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7744701.5000 - val_loss: 7853107.0000\n",
      "Epoch 1897/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7744184.5000 - val_loss: 7852608.5000\n",
      "Epoch 1898/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7743657.5000 - val_loss: 7852092.5000\n",
      "Epoch 1899/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7743142.0000 - val_loss: 7851587.5000\n",
      "Epoch 1900/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7742630.5000 - val_loss: 7851071.5000\n",
      "Epoch 1901/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7742104.0000 - val_loss: 7850549.5000\n",
      "Epoch 1902/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7741595.5000 - val_loss: 7850033.0000\n",
      "Epoch 1903/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7741073.0000 - val_loss: 7849529.0000\n",
      "Epoch 1904/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7740557.0000 - val_loss: 7849013.5000\n",
      "Epoch 1905/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7740037.5000 - val_loss: 7848480.0000\n",
      "Epoch 1906/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7739517.0000 - val_loss: 7847987.0000\n",
      "Epoch 1907/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7739006.0000 - val_loss: 7847460.5000\n",
      "Epoch 1908/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7738480.0000 - val_loss: 7846949.5000\n",
      "Epoch 1909/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7737962.0000 - val_loss: 7846455.0000\n",
      "Epoch 1910/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7737447.5000 - val_loss: 7845927.0000\n",
      "Epoch 1911/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7736933.5000 - val_loss: 7845450.0000\n",
      "Epoch 1912/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7736413.5000 - val_loss: 7844930.5000\n",
      "Epoch 1913/2000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 7735898.5000 - val_loss: 7844413.5000\n",
      "Epoch 1914/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7735382.0000 - val_loss: 7843882.0000\n",
      "Epoch 1915/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7734865.0000 - val_loss: 7843386.5000\n",
      "Epoch 1916/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7734347.0000 - val_loss: 7842843.5000\n",
      "Epoch 1917/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7733822.0000 - val_loss: 7842344.5000\n",
      "Epoch 1918/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7733303.5000 - val_loss: 7841855.0000\n",
      "Epoch 1919/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7732797.5000 - val_loss: 7841326.5000\n",
      "Epoch 1920/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7732275.0000 - val_loss: 7840815.5000\n",
      "Epoch 1921/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7731750.5000 - val_loss: 7840294.5000\n",
      "Epoch 1922/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7731240.0000 - val_loss: 7839779.0000\n",
      "Epoch 1923/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7730717.5000 - val_loss: 7839292.0000\n",
      "Epoch 1924/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7730202.5000 - val_loss: 7838770.5000\n",
      "Epoch 1925/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7729682.5000 - val_loss: 7838270.0000\n",
      "Epoch 1926/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7729173.5000 - val_loss: 7837755.0000\n",
      "Epoch 1927/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7728650.5000 - val_loss: 7837247.0000\n",
      "Epoch 1928/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7728137.0000 - val_loss: 7836735.0000\n",
      "Epoch 1929/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7727622.0000 - val_loss: 7836248.0000\n",
      "Epoch 1930/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7727105.5000 - val_loss: 7835723.5000\n",
      "Epoch 1931/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7726588.5000 - val_loss: 7835213.5000\n",
      "Epoch 1932/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7726076.5000 - val_loss: 7834697.0000\n",
      "Epoch 1933/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7725566.5000 - val_loss: 7834167.0000\n",
      "Epoch 1934/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7725047.0000 - val_loss: 7833672.0000\n",
      "Epoch 1935/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7724527.0000 - val_loss: 7833179.0000\n",
      "Epoch 1936/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7724018.0000 - val_loss: 7832664.0000\n",
      "Epoch 1937/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7723495.0000 - val_loss: 7832153.5000\n",
      "Epoch 1938/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7722983.0000 - val_loss: 7831637.0000\n",
      "Epoch 1939/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7722465.0000 - val_loss: 7831137.5000\n",
      "Epoch 1940/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7721949.0000 - val_loss: 7830625.0000\n",
      "Epoch 1941/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7721435.5000 - val_loss: 7830136.0000\n",
      "Epoch 1942/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7720922.0000 - val_loss: 7829606.0000\n",
      "Epoch 1943/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7720394.5000 - val_loss: 7829089.0000\n",
      "Epoch 1944/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7719882.0000 - val_loss: 7828573.0000\n",
      "Epoch 1945/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7719363.0000 - val_loss: 7828051.5000\n",
      "Epoch 1946/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7718845.5000 - val_loss: 7827552.0000\n",
      "Epoch 1947/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7718336.5000 - val_loss: 7827044.5000\n",
      "Epoch 1948/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7717815.5000 - val_loss: 7826540.0000\n",
      "Epoch 1949/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7717299.0000 - val_loss: 7826041.5000\n",
      "Epoch 1950/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7716787.0000 - val_loss: 7825522.5000\n",
      "Epoch 1951/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7716272.5000 - val_loss: 7825031.5000\n",
      "Epoch 1952/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7715751.0000 - val_loss: 7824527.0000\n",
      "Epoch 1953/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7715237.5000 - val_loss: 7824023.0000\n",
      "Epoch 1954/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7714721.0000 - val_loss: 7823505.0000\n",
      "Epoch 1955/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7714207.5000 - val_loss: 7823006.5000\n",
      "Epoch 1956/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7713697.0000 - val_loss: 7822490.5000\n",
      "Epoch 1957/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7713177.0000 - val_loss: 7821984.5000\n",
      "Epoch 1958/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7712661.5000 - val_loss: 7821463.0000\n",
      "Epoch 1959/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7712143.5000 - val_loss: 7820956.0000\n",
      "Epoch 1960/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7711628.5000 - val_loss: 7820451.5000\n",
      "Epoch 1961/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7711115.5000 - val_loss: 7819944.5000\n",
      "Epoch 1962/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7710601.5000 - val_loss: 7819432.5000\n",
      "Epoch 1963/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7710096.0000 - val_loss: 7818898.5000\n",
      "Epoch 1964/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7709574.5000 - val_loss: 7818414.5000\n",
      "Epoch 1965/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7709059.0000 - val_loss: 7817888.0000\n",
      "Epoch 1966/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7708547.0000 - val_loss: 7817386.0000\n",
      "Epoch 1967/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7708034.0000 - val_loss: 7816914.0000\n",
      "Epoch 1968/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7707521.5000 - val_loss: 7816397.0000\n",
      "Epoch 1969/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7707008.5000 - val_loss: 7815877.5000\n",
      "Epoch 1970/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7706493.0000 - val_loss: 7815373.5000\n",
      "Epoch 1971/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7705979.5000 - val_loss: 7814872.0000\n",
      "Epoch 1972/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7705466.0000 - val_loss: 7814369.0000\n",
      "Epoch 1973/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7704952.5000 - val_loss: 7813832.5000\n",
      "Epoch 1974/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7704443.5000 - val_loss: 7813345.5000\n",
      "Epoch 1975/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7703930.5000 - val_loss: 7812852.0000\n",
      "Epoch 1976/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7703415.0000 - val_loss: 7812340.0000\n",
      "Epoch 1977/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7702905.0000 - val_loss: 7811839.5000\n",
      "Epoch 1978/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7702394.0000 - val_loss: 7811331.5000\n",
      "Epoch 1979/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7701873.0000 - val_loss: 7810845.0000\n",
      "Epoch 1980/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7701369.0000 - val_loss: 7810341.5000\n",
      "Epoch 1981/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7700855.0000 - val_loss: 7809850.5000\n",
      "Epoch 1982/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7700339.0000 - val_loss: 7809356.0000\n",
      "Epoch 1983/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7699831.5000 - val_loss: 7808841.0000\n",
      "Epoch 1984/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7699317.5000 - val_loss: 7808328.5000\n",
      "Epoch 1985/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7698806.0000 - val_loss: 7807841.0000\n",
      "Epoch 1986/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7698292.5000 - val_loss: 7807341.5000\n",
      "Epoch 1987/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7697778.5000 - val_loss: 7806844.5000\n",
      "Epoch 1988/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7697265.0000 - val_loss: 7806325.0000\n",
      "Epoch 1989/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7696751.0000 - val_loss: 7805818.0000\n",
      "Epoch 1990/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7696240.5000 - val_loss: 7805312.5000\n",
      "Epoch 1991/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7695726.0000 - val_loss: 7804815.5000\n",
      "Epoch 1992/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7695215.5000 - val_loss: 7804320.5000\n",
      "Epoch 1993/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7694701.5000 - val_loss: 7803795.0000\n",
      "Epoch 1994/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7694192.5000 - val_loss: 7803292.0000\n",
      "Epoch 1995/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7693681.5000 - val_loss: 7802794.0000\n",
      "Epoch 1996/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7693166.0000 - val_loss: 7802297.5000\n",
      "Epoch 1997/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7692652.5000 - val_loss: 7801797.0000\n",
      "Epoch 1998/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7692145.5000 - val_loss: 7801267.0000\n",
      "Epoch 1999/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7691629.5000 - val_loss: 7800789.0000\n",
      "Epoch 2000/2000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7691127.0000 - val_loss: 7800269.0000\n",
      "Wall time: 11min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\", patience=4, mode=\"min\"\n",
    "    )\n",
    "history = linear_model.fit(\n",
    "    train_features,\n",
    "    train_label,\n",
    "    epochs=2000,\n",
    "    validation_split=.2,\n",
    "    callbacks=[early_stopping],\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>7693166.0</td>\n",
       "      <td>7802297.5</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>7692652.5</td>\n",
       "      <td>7801797.0</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>7692145.5</td>\n",
       "      <td>7801267.0</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>7691629.5</td>\n",
       "      <td>7800789.0</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>7691127.0</td>\n",
       "      <td>7800269.0</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           loss   val_loss  epoch\n",
       "1995  7693166.0  7802297.5   1995\n",
       "1996  7692652.5  7801797.0   1996\n",
       "1997  7692145.5  7801267.0   1997\n",
       "1998  7691629.5  7800789.0   1998\n",
       "1999  7691127.0  7800269.0   1999"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist[\"epoch\"] = history.epoch\n",
    "hist.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = {}\n",
    "\n",
    "test_results[\"linear_baseline\"] = linear_model.evaluate(\n",
    "    test_features, test_label, verbose=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_compile_model(norm):\n",
    "    model = tf.keras.models.Sequential(\n",
    "        [\n",
    "            norm,\n",
    "            tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(1),\n",
    "        ]\n",
    "    )\n",
    "    model.compile(\n",
    "        loss=\"mse\", optimizer=\"adam\", metrics=[tf.metrics.MeanAbsoluteError()]\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "normalization (Normalization (None, 58)                117       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                3776      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 8,118\n",
      "Trainable params: 8,001\n",
      "Non-trainable params: 117\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dnn_model = build_and_compile_model(normalizer)\n",
    "\n",
    "dnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 8981285.0000 - mean_absolute_error: 2923.2644 - val_loss: 9008968.0000 - val_mean_absolute_error: 2929.6611\n",
      "Epoch 2/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8000555.0000 - mean_absolute_error: 2751.4326 - val_loss: 6967678.0000 - val_mean_absolute_error: 2559.5283\n",
      "Epoch 3/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 4977300.0000 - mean_absolute_error: 2091.3530 - val_loss: 3419422.7500 - val_mean_absolute_error: 1678.6096\n",
      "Epoch 4/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 2409067.2500 - mean_absolute_error: 1356.7600 - val_loss: 1885042.1250 - val_mean_absolute_error: 1196.6982\n",
      "Epoch 5/2000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 1561783.0000 - mean_absolute_error: 1061.2186 - val_loss: 1375477.8750 - val_mean_absolute_error: 997.4456\n",
      "Epoch 6/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 1195078.1250 - mean_absolute_error: 906.8055 - val_loss: 1102518.2500 - val_mean_absolute_error: 881.2978\n",
      "Epoch 7/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 971358.9375 - mean_absolute_error: 811.2698 - val_loss: 906217.4375 - val_mean_absolute_error: 795.0089\n",
      "Epoch 8/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 793269.3750 - mean_absolute_error: 730.3031 - val_loss: 739572.5000 - val_mean_absolute_error: 714.8806\n",
      "Epoch 9/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 647467.0000 - mean_absolute_error: 652.7527 - val_loss: 606514.9375 - val_mean_absolute_error: 643.0864\n",
      "Epoch 10/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 532656.4375 - mean_absolute_error: 587.7890 - val_loss: 503268.9062 - val_mean_absolute_error: 580.4235\n",
      "Epoch 11/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 448745.5938 - mean_absolute_error: 533.6190 - val_loss: 429326.2812 - val_mean_absolute_error: 532.7331\n",
      "Epoch 12/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 387662.0938 - mean_absolute_error: 490.7310 - val_loss: 377226.0625 - val_mean_absolute_error: 498.3225\n",
      "Epoch 13/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 341878.0312 - mean_absolute_error: 458.2061 - val_loss: 336529.7500 - val_mean_absolute_error: 469.0763\n",
      "Epoch 14/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 305440.2500 - mean_absolute_error: 429.8079 - val_loss: 301425.0938 - val_mean_absolute_error: 442.4955\n",
      "Epoch 15/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 275194.5000 - mean_absolute_error: 405.1203 - val_loss: 276082.6562 - val_mean_absolute_error: 422.4898\n",
      "Epoch 16/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 248703.5312 - mean_absolute_error: 384.2734 - val_loss: 252910.7969 - val_mean_absolute_error: 402.3611\n",
      "Epoch 17/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 226176.4688 - mean_absolute_error: 365.0432 - val_loss: 232391.2656 - val_mean_absolute_error: 384.7337\n",
      "Epoch 18/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 206310.9531 - mean_absolute_error: 347.5475 - val_loss: 216450.0312 - val_mean_absolute_error: 370.3411\n",
      "Epoch 19/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 188395.7188 - mean_absolute_error: 330.9888 - val_loss: 202039.5625 - val_mean_absolute_error: 357.0813\n",
      "Epoch 20/2000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 173193.9375 - mean_absolute_error: 316.9274 - val_loss: 187723.1406 - val_mean_absolute_error: 343.2311\n",
      "Epoch 21/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 158791.3906 - mean_absolute_error: 303.3808 - val_loss: 174039.4062 - val_mean_absolute_error: 328.6461\n",
      "Epoch 22/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 146522.5625 - mean_absolute_error: 289.9797 - val_loss: 163273.0469 - val_mean_absolute_error: 317.5986\n",
      "Epoch 23/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 134961.1875 - mean_absolute_error: 278.5802 - val_loss: 153383.3594 - val_mean_absolute_error: 307.3745\n",
      "Epoch 24/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 125037.9531 - mean_absolute_error: 267.4622 - val_loss: 144125.0469 - val_mean_absolute_error: 297.0915\n",
      "Epoch 25/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 115764.3750 - mean_absolute_error: 257.5719 - val_loss: 134977.7344 - val_mean_absolute_error: 286.3426\n",
      "Epoch 26/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 107169.3516 - mean_absolute_error: 247.9281 - val_loss: 127466.9922 - val_mean_absolute_error: 276.8842\n",
      "Epoch 27/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 99860.1016 - mean_absolute_error: 239.6927 - val_loss: 120439.8516 - val_mean_absolute_error: 268.3676\n",
      "Epoch 28/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 93139.3984 - mean_absolute_error: 230.7629 - val_loss: 113509.7891 - val_mean_absolute_error: 259.4731\n",
      "Epoch 29/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 86637.0469 - mean_absolute_error: 223.2697 - val_loss: 107962.6016 - val_mean_absolute_error: 252.8021\n",
      "Epoch 30/2000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 81132.2578 - mean_absolute_error: 216.4455 - val_loss: 101773.0547 - val_mean_absolute_error: 244.5777\n",
      "Epoch 31/2000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 75709.4766 - mean_absolute_error: 209.7778 - val_loss: 96781.3047 - val_mean_absolute_error: 237.5150\n",
      "Epoch 32/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 71316.9844 - mean_absolute_error: 203.6961 - val_loss: 91629.5000 - val_mean_absolute_error: 230.7469\n",
      "Epoch 33/2000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 66898.8281 - mean_absolute_error: 197.7112 - val_loss: 87065.1016 - val_mean_absolute_error: 224.5673\n",
      "Epoch 34/2000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 62604.9570 - mean_absolute_error: 191.2763 - val_loss: 83721.8594 - val_mean_absolute_error: 220.2760\n",
      "Epoch 35/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 58932.7305 - mean_absolute_error: 186.1873 - val_loss: 79119.7656 - val_mean_absolute_error: 212.0605\n",
      "Epoch 36/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 55606.3867 - mean_absolute_error: 180.5548 - val_loss: 75330.5234 - val_mean_absolute_error: 207.3326\n",
      "Epoch 37/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 52337.0000 - mean_absolute_error: 175.2717 - val_loss: 71796.4688 - val_mean_absolute_error: 202.0320\n",
      "Epoch 38/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 49237.7930 - mean_absolute_error: 170.4894 - val_loss: 68459.5312 - val_mean_absolute_error: 195.8200\n",
      "Epoch 39/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 46408.7422 - mean_absolute_error: 165.5745 - val_loss: 65570.2969 - val_mean_absolute_error: 190.8227\n",
      "Epoch 40/2000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 43634.5664 - mean_absolute_error: 160.5594 - val_loss: 62245.3750 - val_mean_absolute_error: 185.6966\n",
      "Epoch 41/2000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 41049.8867 - mean_absolute_error: 155.9393 - val_loss: 59357.8047 - val_mean_absolute_error: 180.8221\n",
      "Epoch 42/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 38934.7734 - mean_absolute_error: 151.7352 - val_loss: 56909.1055 - val_mean_absolute_error: 176.2302\n",
      "Epoch 43/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 36543.6719 - mean_absolute_error: 147.0268 - val_loss: 54473.7734 - val_mean_absolute_error: 171.4714\n",
      "Epoch 44/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 34560.8008 - mean_absolute_error: 143.2699 - val_loss: 51902.9023 - val_mean_absolute_error: 167.4572\n",
      "Epoch 45/2000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 32684.3496 - mean_absolute_error: 139.5478 - val_loss: 49088.8594 - val_mean_absolute_error: 163.2983\n",
      "Epoch 46/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 30813.1543 - mean_absolute_error: 135.4162 - val_loss: 47466.6484 - val_mean_absolute_error: 159.7118\n",
      "Epoch 47/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 29043.2070 - mean_absolute_error: 131.4653 - val_loss: 45107.7266 - val_mean_absolute_error: 155.1023\n",
      "Epoch 48/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 27502.0352 - mean_absolute_error: 128.1257 - val_loss: 42863.1602 - val_mean_absolute_error: 150.7916\n",
      "Epoch 49/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 25940.3672 - mean_absolute_error: 124.2713 - val_loss: 40816.3398 - val_mean_absolute_error: 146.7426\n",
      "Epoch 50/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 24622.1504 - mean_absolute_error: 120.7718 - val_loss: 38736.9609 - val_mean_absolute_error: 142.7675\n",
      "Epoch 51/2000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 23180.0059 - mean_absolute_error: 117.6577 - val_loss: 37609.5859 - val_mean_absolute_error: 139.5706\n",
      "Epoch 52/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 21927.7070 - mean_absolute_error: 114.2826 - val_loss: 35849.0039 - val_mean_absolute_error: 136.1541\n",
      "Epoch 53/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 20828.2910 - mean_absolute_error: 111.4526 - val_loss: 34140.6016 - val_mean_absolute_error: 133.5746\n",
      "Epoch 54/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 19687.1211 - mean_absolute_error: 108.2775 - val_loss: 32422.2812 - val_mean_absolute_error: 128.4596\n",
      "Epoch 55/2000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 18669.3926 - mean_absolute_error: 105.2421 - val_loss: 31112.3379 - val_mean_absolute_error: 125.0530\n",
      "Epoch 56/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 17409.0039 - mean_absolute_error: 102.4161 - val_loss: 30569.2578 - val_mean_absolute_error: 123.1641\n",
      "Epoch 57/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 16632.1035 - mean_absolute_error: 99.7209 - val_loss: 28664.0957 - val_mean_absolute_error: 119.5862\n",
      "Epoch 58/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 15642.2852 - mean_absolute_error: 96.4550 - val_loss: 27187.9043 - val_mean_absolute_error: 115.9112\n",
      "Epoch 59/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 14746.5674 - mean_absolute_error: 93.9299 - val_loss: 26171.8867 - val_mean_absolute_error: 113.7114\n",
      "Epoch 60/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 13917.6758 - mean_absolute_error: 90.9596 - val_loss: 24380.8672 - val_mean_absolute_error: 110.3814\n",
      "Epoch 61/2000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 13240.5312 - mean_absolute_error: 89.3385 - val_loss: 23233.3203 - val_mean_absolute_error: 107.3144\n",
      "Epoch 62/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 12481.9092 - mean_absolute_error: 86.0323 - val_loss: 22498.9297 - val_mean_absolute_error: 105.3759\n",
      "Epoch 63/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 11891.6846 - mean_absolute_error: 84.2780 - val_loss: 21686.4121 - val_mean_absolute_error: 102.1921\n",
      "Epoch 64/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 11158.7090 - mean_absolute_error: 81.3140 - val_loss: 20528.0352 - val_mean_absolute_error: 101.0410\n",
      "Epoch 65/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 10615.5928 - mean_absolute_error: 79.5195 - val_loss: 19586.4453 - val_mean_absolute_error: 97.7117\n",
      "Epoch 66/2000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 9992.7461 - mean_absolute_error: 77.3265 - val_loss: 18949.3750 - val_mean_absolute_error: 95.7571\n",
      "Epoch 67/2000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 9588.2930 - mean_absolute_error: 75.9481 - val_loss: 18263.2344 - val_mean_absolute_error: 94.6424\n",
      "Epoch 68/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 9038.8701 - mean_absolute_error: 73.1222 - val_loss: 17560.2812 - val_mean_absolute_error: 91.5517\n",
      "Epoch 69/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8585.5996 - mean_absolute_error: 71.4341 - val_loss: 16383.6592 - val_mean_absolute_error: 90.2568\n",
      "Epoch 70/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 8150.6846 - mean_absolute_error: 69.5279 - val_loss: 16372.6768 - val_mean_absolute_error: 87.3531\n",
      "Epoch 71/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 7635.2144 - mean_absolute_error: 67.4696 - val_loss: 15286.5840 - val_mean_absolute_error: 85.5186\n",
      "Epoch 72/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 7324.2822 - mean_absolute_error: 66.0181 - val_loss: 14887.5713 - val_mean_absolute_error: 83.6573\n",
      "Epoch 73/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6917.0146 - mean_absolute_error: 64.3508 - val_loss: 14268.3701 - val_mean_absolute_error: 81.2133\n",
      "Epoch 74/2000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 6573.6040 - mean_absolute_error: 62.4979 - val_loss: 13696.4395 - val_mean_absolute_error: 80.8308\n",
      "Epoch 75/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6256.6782 - mean_absolute_error: 61.2339 - val_loss: 13763.9648 - val_mean_absolute_error: 79.4480\n",
      "Epoch 76/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6049.2505 - mean_absolute_error: 60.4196 - val_loss: 12992.8320 - val_mean_absolute_error: 77.1720\n",
      "Epoch 77/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5645.0859 - mean_absolute_error: 58.1873 - val_loss: 12868.0273 - val_mean_absolute_error: 76.1871\n",
      "Epoch 78/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 5376.2466 - mean_absolute_error: 56.7862 - val_loss: 11798.9238 - val_mean_absolute_error: 73.5434\n",
      "Epoch 79/2000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5148.8574 - mean_absolute_error: 55.4821 - val_loss: 12063.4521 - val_mean_absolute_error: 73.6899\n",
      "Epoch 80/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 4892.0991 - mean_absolute_error: 53.7541 - val_loss: 10872.9766 - val_mean_absolute_error: 71.1445\n",
      "Epoch 81/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 4737.8784 - mean_absolute_error: 53.2173 - val_loss: 10678.3057 - val_mean_absolute_error: 70.0850\n",
      "Epoch 82/2000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 4480.6157 - mean_absolute_error: 51.6399 - val_loss: 10479.9023 - val_mean_absolute_error: 69.0812\n",
      "Epoch 83/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 4270.0635 - mean_absolute_error: 50.7699 - val_loss: 10050.8330 - val_mean_absolute_error: 67.2563\n",
      "Epoch 84/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 4046.7544 - mean_absolute_error: 49.2801 - val_loss: 9327.8799 - val_mean_absolute_error: 65.3666\n",
      "Epoch 85/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 3972.6719 - mean_absolute_error: 49.0388 - val_loss: 9620.2207 - val_mean_absolute_error: 64.8888\n",
      "Epoch 86/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 3711.2866 - mean_absolute_error: 47.3487 - val_loss: 9289.1836 - val_mean_absolute_error: 64.2881\n",
      "Epoch 87/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 3590.8845 - mean_absolute_error: 46.4248 - val_loss: 8291.7207 - val_mean_absolute_error: 62.2255\n",
      "Epoch 88/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 3361.0513 - mean_absolute_error: 44.8142 - val_loss: 8597.4346 - val_mean_absolute_error: 61.2677\n",
      "Epoch 89/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 3246.6523 - mean_absolute_error: 44.2281 - val_loss: 8374.9570 - val_mean_absolute_error: 60.3504\n",
      "Epoch 90/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 3081.9102 - mean_absolute_error: 43.2026 - val_loss: 8212.9307 - val_mean_absolute_error: 59.6320\n",
      "Epoch 91/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 2929.7922 - mean_absolute_error: 42.1017 - val_loss: 7645.5786 - val_mean_absolute_error: 57.7300\n",
      "Epoch 92/2000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 2807.0891 - mean_absolute_error: 41.1719 - val_loss: 7612.0181 - val_mean_absolute_error: 57.0490\n",
      "Epoch 93/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 2724.2559 - mean_absolute_error: 40.6788 - val_loss: 7262.0688 - val_mean_absolute_error: 55.2774\n",
      "Epoch 94/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 2560.7358 - mean_absolute_error: 39.3405 - val_loss: 7217.6523 - val_mean_absolute_error: 55.3974\n",
      "Epoch 95/2000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 2485.9465 - mean_absolute_error: 38.8111 - val_loss: 7277.4033 - val_mean_absolute_error: 55.1062\n",
      "Epoch 96/2000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 2419.9580 - mean_absolute_error: 38.2198 - val_loss: 6494.9243 - val_mean_absolute_error: 53.4232\n",
      "Epoch 97/2000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 2241.6973 - mean_absolute_error: 36.8432 - val_loss: 6287.2095 - val_mean_absolute_error: 52.2785\n",
      "Epoch 98/2000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 2187.3159 - mean_absolute_error: 36.3490 - val_loss: 6652.5767 - val_mean_absolute_error: 51.9525\n",
      "Epoch 99/2000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 2100.4529 - mean_absolute_error: 35.9607 - val_loss: 6056.0576 - val_mean_absolute_error: 51.2316\n",
      "Epoch 100/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 2056.7537 - mean_absolute_error: 35.3376 - val_loss: 5881.1162 - val_mean_absolute_error: 50.1363\n",
      "Epoch 101/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 1922.9143 - mean_absolute_error: 34.1871 - val_loss: 5813.3066 - val_mean_absolute_error: 48.7942\n",
      "Epoch 102/2000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 1844.2777 - mean_absolute_error: 33.6053 - val_loss: 5345.1079 - val_mean_absolute_error: 47.9277\n",
      "Epoch 103/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 1759.1840 - mean_absolute_error: 32.9683 - val_loss: 5553.8149 - val_mean_absolute_error: 47.6842\n",
      "Epoch 104/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 1718.5795 - mean_absolute_error: 32.4201 - val_loss: 5333.5566 - val_mean_absolute_error: 46.8783\n",
      "Epoch 105/2000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 1638.5181 - mean_absolute_error: 31.7685 - val_loss: 5135.5371 - val_mean_absolute_error: 45.3382\n",
      "Epoch 106/2000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 1571.8053 - mean_absolute_error: 31.1131 - val_loss: 4897.8882 - val_mean_absolute_error: 45.7862\n",
      "Epoch 107/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 1525.8599 - mean_absolute_error: 30.6706 - val_loss: 4961.7568 - val_mean_absolute_error: 44.9443\n",
      "Epoch 108/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 1477.0081 - mean_absolute_error: 30.0169 - val_loss: 4732.7061 - val_mean_absolute_error: 43.5909\n",
      "Epoch 109/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 1402.9752 - mean_absolute_error: 29.2799 - val_loss: 4688.2041 - val_mean_absolute_error: 42.4468\n",
      "Epoch 110/2000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 1352.4613 - mean_absolute_error: 28.8587 - val_loss: 4689.7324 - val_mean_absolute_error: 42.3529\n",
      "Epoch 111/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 1317.5106 - mean_absolute_error: 28.4569 - val_loss: 4586.8887 - val_mean_absolute_error: 41.9471\n",
      "Epoch 112/2000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 1278.8921 - mean_absolute_error: 27.9915 - val_loss: 3977.6091 - val_mean_absolute_error: 41.2590\n",
      "Epoch 113/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 1194.6803 - mean_absolute_error: 26.9892 - val_loss: 4408.4619 - val_mean_absolute_error: 41.0740\n",
      "Epoch 114/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 1187.3179 - mean_absolute_error: 26.9557 - val_loss: 3956.0164 - val_mean_absolute_error: 40.1950\n",
      "Epoch 115/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 1145.8751 - mean_absolute_error: 26.4485 - val_loss: 4193.2300 - val_mean_absolute_error: 40.5889\n",
      "Epoch 116/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 1072.7305 - mean_absolute_error: 25.7137 - val_loss: 3791.8303 - val_mean_absolute_error: 39.0774\n",
      "Epoch 117/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 1055.0693 - mean_absolute_error: 25.4603 - val_loss: 4053.7290 - val_mean_absolute_error: 39.0058\n",
      "Epoch 118/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 1032.9519 - mean_absolute_error: 25.2035 - val_loss: 3723.5608 - val_mean_absolute_error: 38.1240\n",
      "Epoch 119/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 1010.4555 - mean_absolute_error: 24.9486 - val_loss: 3872.9216 - val_mean_absolute_error: 37.5943\n",
      "Epoch 120/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 971.2536 - mean_absolute_error: 24.4495 - val_loss: 3404.9407 - val_mean_absolute_error: 36.0737\n",
      "Epoch 121/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 911.2896 - mean_absolute_error: 23.6735 - val_loss: 3497.7290 - val_mean_absolute_error: 35.4368\n",
      "Epoch 122/2000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 925.6012 - mean_absolute_error: 23.9250 - val_loss: 3690.4150 - val_mean_absolute_error: 36.9069\n",
      "Epoch 123/2000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 916.8496 - mean_absolute_error: 23.6533 - val_loss: 3591.1658 - val_mean_absolute_error: 35.8901\n",
      "Epoch 124/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 829.9673 - mean_absolute_error: 22.6346 - val_loss: 3119.8296 - val_mean_absolute_error: 34.0700\n",
      "Epoch 125/2000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 837.1852 - mean_absolute_error: 22.6534 - val_loss: 3208.1094 - val_mean_absolute_error: 34.2967\n",
      "Epoch 126/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 812.4957 - mean_absolute_error: 22.2712 - val_loss: 2987.4512 - val_mean_absolute_error: 33.8832\n",
      "Epoch 127/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 774.0381 - mean_absolute_error: 21.8678 - val_loss: 2862.7334 - val_mean_absolute_error: 32.9526\n",
      "Epoch 128/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 736.0322 - mean_absolute_error: 21.0539 - val_loss: 2944.8447 - val_mean_absolute_error: 32.5348\n",
      "Epoch 129/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 708.5743 - mean_absolute_error: 20.7506 - val_loss: 2866.4104 - val_mean_absolute_error: 32.3906\n",
      "Epoch 130/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 710.0104 - mean_absolute_error: 20.8261 - val_loss: 2508.7100 - val_mean_absolute_error: 30.8804\n",
      "Epoch 131/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 688.6698 - mean_absolute_error: 20.4676 - val_loss: 2523.4170 - val_mean_absolute_error: 31.5454\n",
      "Epoch 132/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 656.6375 - mean_absolute_error: 20.0764 - val_loss: 2402.9785 - val_mean_absolute_error: 30.6955\n",
      "Epoch 133/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 684.4772 - mean_absolute_error: 20.4299 - val_loss: 2485.1672 - val_mean_absolute_error: 30.7208\n",
      "Epoch 134/2000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 737.0735 - mean_absolute_error: 20.8856 - val_loss: 2365.4023 - val_mean_absolute_error: 30.5559\n",
      "Epoch 135/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 793.1915 - mean_absolute_error: 21.0595 - val_loss: 2293.0422 - val_mean_absolute_error: 29.0714\n",
      "Epoch 136/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 671.4999 - mean_absolute_error: 19.6424 - val_loss: 2319.1892 - val_mean_absolute_error: 30.7164\n",
      "Epoch 137/2000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 666.3107 - mean_absolute_error: 19.9526 - val_loss: 2206.2205 - val_mean_absolute_error: 28.5176\n",
      "Epoch 138/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 623.2295 - mean_absolute_error: 19.3152 - val_loss: 2323.7949 - val_mean_absolute_error: 28.6385\n",
      "Epoch 139/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 616.6252 - mean_absolute_error: 19.1632 - val_loss: 2306.0281 - val_mean_absolute_error: 28.3383\n",
      "Epoch 140/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 550.9163 - mean_absolute_error: 18.1382 - val_loss: 2206.2649 - val_mean_absolute_error: 28.0221\n",
      "Epoch 141/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 521.2559 - mean_absolute_error: 17.8490 - val_loss: 2083.2517 - val_mean_absolute_error: 28.0281\n",
      "Epoch 142/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 495.7616 - mean_absolute_error: 17.5252 - val_loss: 2261.5503 - val_mean_absolute_error: 29.1888\n",
      "Epoch 143/2000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 495.5211 - mean_absolute_error: 17.6058 - val_loss: 2038.0981 - val_mean_absolute_error: 27.3606\n",
      "Epoch 144/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 501.7185 - mean_absolute_error: 17.6669 - val_loss: 2086.5759 - val_mean_absolute_error: 27.4970\n",
      "Epoch 145/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 457.9545 - mean_absolute_error: 16.8030 - val_loss: 2015.8004 - val_mean_absolute_error: 27.1398\n",
      "Epoch 146/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 478.4525 - mean_absolute_error: 17.3053 - val_loss: 1926.7316 - val_mean_absolute_error: 26.6396\n",
      "Epoch 147/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 466.0086 - mean_absolute_error: 16.9777 - val_loss: 2095.6272 - val_mean_absolute_error: 27.2422\n",
      "Epoch 148/2000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 451.9532 - mean_absolute_error: 16.6998 - val_loss: 1957.0444 - val_mean_absolute_error: 27.1341\n",
      "Epoch 149/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 449.2155 - mean_absolute_error: 16.6011 - val_loss: 2047.6089 - val_mean_absolute_error: 27.8391\n",
      "Epoch 150/2000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 446.7823 - mean_absolute_error: 16.5579 - val_loss: 1885.3282 - val_mean_absolute_error: 25.3740\n",
      "Epoch 151/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 398.9879 - mean_absolute_error: 15.9080 - val_loss: 1812.8363 - val_mean_absolute_error: 25.3197\n",
      "Epoch 152/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 405.8394 - mean_absolute_error: 15.7779 - val_loss: 1901.9803 - val_mean_absolute_error: 25.7718\n",
      "Epoch 153/2000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 394.9618 - mean_absolute_error: 15.5706 - val_loss: 1975.4352 - val_mean_absolute_error: 25.7035\n",
      "Epoch 154/2000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 387.8687 - mean_absolute_error: 15.4273 - val_loss: 1874.3616 - val_mean_absolute_error: 25.3921\n",
      "Epoch 155/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 382.9022 - mean_absolute_error: 15.2338 - val_loss: 1697.7277 - val_mean_absolute_error: 25.6091\n",
      "Epoch 156/2000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 367.9588 - mean_absolute_error: 14.9314 - val_loss: 1690.7363 - val_mean_absolute_error: 24.5383\n",
      "Epoch 157/2000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 397.7717 - mean_absolute_error: 15.4457 - val_loss: 1564.7594 - val_mean_absolute_error: 23.9830\n",
      "Epoch 158/2000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 374.8384 - mean_absolute_error: 15.1971 - val_loss: 1729.8425 - val_mean_absolute_error: 24.8662\n",
      "Epoch 159/2000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 378.4447 - mean_absolute_error: 15.1943 - val_loss: 1737.3038 - val_mean_absolute_error: 23.5139\n",
      "Epoch 160/2000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 372.9144 - mean_absolute_error: 14.7691 - val_loss: 1727.9596 - val_mean_absolute_error: 24.5872\n",
      "Epoch 161/2000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 320.9619 - mean_absolute_error: 14.1080 - val_loss: 1705.1016 - val_mean_absolute_error: 24.8189\n",
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = dnn_model.fit(\n",
    "    train_features,\n",
    "    train_label,\n",
    "    validation_split=0.2,\n",
    "    epochs=2000, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='epoch'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 279,
       "width": 365
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist[\"epoch\"] = history.epoch\n",
    "hist.plot(x=\"epoch\", y=\"loss\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 3ms/step - loss: 2581.0327 - mean_absolute_error: 27.6908\n",
      "{'linear_baseline': 7722508.5, 'dnn_model': [2581.03271484375, 27.690780639648438]}\n"
     ]
    }
   ],
   "source": [
    "test_results[\"dnn_model\"] = dnn_model.evaluate(test_features, test_label)\n",
    "\n",
    "print(test_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = {}\n",
    "test_predictions[\"dnn_model\"] = dnn_model.predict(test_features).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:08:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/objective/regression_obj.cu:188: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\teval-rmse:97.33028\ttrain-rmse:94.79799\n",
      "[1]\teval-rmse:21.15627\ttrain-rmse:13.05729\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(train_features, label=train_label)\n",
    "dtest = xgb.DMatrix(test_features, label=test_label)\n",
    "\n",
    "param = {\"max_depth\": 50, \"eta\": 1, \"objective\": \"reg:squarederror\", \"booster\": \"gbtree\"}\n",
    "evallist = [(dtest, \"eval\"), (dtrain, \"train\")]\n",
    "\n",
    "num_round = 2\n",
    "xg = xgb.train(param, dtrain, num_round, evallist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Booster' object has no attribute 'evaluate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13164/1675904388.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"xgb\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_results\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Booster' object has no attribute 'evaluate'"
     ]
    }
   ],
   "source": [
    "test_results[\"xgb\"] = xg.evaluate(test_features, test_label)\n",
    "\n",
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions[\"xgb\"] = xg.predict(test_features).flatten()\n",
    "\n",
    "print(test_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def conv_model(normalizer):\n",
    "#     CONV_WIDTH = 3\n",
    "\n",
    "#     model = tf.keras.models.Sequential(\n",
    "#         [\n",
    "#             normalizer,\n",
    "#             # tf.keras.layers.Lambda(lambda x: x[:, -CONV_WIDTH:, :]),\n",
    "#             # tf.keras.layers.Conv1D(\n",
    "#             #     filters=64,\n",
    "#             #     kernel_size=(CONV_WIDTH),\n",
    "#             #     strides=1,\n",
    "#             #     padding=\"causal\",\n",
    "#             #     # activation=\"relu\",\n",
    "#             # ),\n",
    "#             tf.keras.layers.Bidirectional(\n",
    "#                 tf.keras.layers.LSTM(128, return_sequences=False)\n",
    "#             ),\n",
    "#             # tf.keras.layers.Bidirectional(\n",
    "#             #     tf.keras.layers.LSTM(64, return_sequences=True)),\n",
    "#             tf.keras.layers.Dense(128),\n",
    "#             tf.keras.layers.Dropout(0.2),\n",
    "#             tf.keras.layers.Dense(1),\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "#     model.compile(\n",
    "#         loss=\"mse\", optimizer=\"adam\", metrics=[tf.metrics.MeanAbsoluteError()]\n",
    "#     )\n",
    "\n",
    "#     return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_model = conv_model(normalizer)\n",
    "\n",
    "# conv_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# history = conv_model.fit(\n",
    "#     train_features,\n",
    "#     train_label,\n",
    "#     validation_split=0.2,\n",
    "#     epochs=2000, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_results[\"conv_model\"] = dnn_model.evaluate(test_features, test_label)\n",
    "\n",
    "# print(test_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_predictions[\"conv_model\"] = dnn_model.predict(test_features).flatten()\n",
    "\n",
    "# print(test_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(labels, preds):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.scatter(x=labels.index, y=labels, color=\"r\", marker=\".\", label=\"real data\")\n",
    "    plt.scatter(x=labels.index, y=preds, color=\"b\", marker=\"X\", label=\"predictions\")\n",
    "    plt.xlabel(\"time\")\n",
    "    plt.ylabel(\"price\")\n",
    "    plt.title(\"Red is predictions, Blue is real data\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result(test_label, test_predictions[\"dnn_model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result(test_label, test_predictions[\"xgb\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5b28a564d154730cebcf0a77751c471b8962279a1a72eb3cf8cb939e9c4c97bb"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('env': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
