{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.distribute.one_device_strategy.OneDeviceStrategy at 0x257b2b12978>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "%matplotlib inline\n",
    "%config IPCompleter.greedy = True\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(\n",
    "    font=\"Franklin Gothic Book\",\n",
    "    rc={\n",
    "        \"axes.axisbelow\": False,\n",
    "        \"axes.edgecolor\": \"lightgrey\",\n",
    "        \"axes.facecolor\": \"None\",\n",
    "        \"axes.grid\": False,\n",
    "        \"axes.labelcolor\": \"dimgrey\",\n",
    "        \"axes.spines.right\": False,\n",
    "        \"axes.spines.top\": False,\n",
    "        \"figure.facecolor\": \"white\",\n",
    "        \"lines.solid_capstyle\": \"round\",\n",
    "        \"patch.edgecolor\": \"w\",\n",
    "        \"patch.force_edgecolor\": True,\n",
    "        \"text.color\": \"dimgrey\",\n",
    "        \"xtick.bottom\": False,\n",
    "        \"xtick.color\": \"dimgrey\",\n",
    "        \"xtick.direction\": \"out\",\n",
    "        \"xtick.top\": False,\n",
    "        \"ytick.color\": \"dimgrey\",\n",
    "        \"ytick.direction\": \"out\",\n",
    "        \"ytick.left\": False,\n",
    "        \"ytick.right\": False,\n",
    "    },\n",
    ")\n",
    "\n",
    "sns.set_context(\n",
    "    \"notebook\", rc={\"font.size\": 16, \"axes.titlesize\": 20, \"axes.labelsize\": 18}\n",
    ")\n",
    "import requests\n",
    "from creds import api_key\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from pandasgui import show\n",
    "\n",
    "tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.lunarcrush.com/v2?data=assets&key=ru1zaf0ssaa29394mb4ahp&symbol=ETH&change=1d&change=1w&change=1m&change=3m&change=6m&change=1y&change=2y&data_points=720&start=1626586954.295639\n",
      "0\n",
      "2021-08-17 05:00:00\n",
      "2021-07-18 06:00:00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>volume</th>\n",
       "      <th>market_cap</th>\n",
       "      <th>url_shares</th>\n",
       "      <th>unique_url_shares</th>\n",
       "      <th>reddit_posts</th>\n",
       "      <th>reddit_posts_score</th>\n",
       "      <th>...</th>\n",
       "      <th>social_volume</th>\n",
       "      <th>price_btc</th>\n",
       "      <th>social_volume_global</th>\n",
       "      <th>social_dominance</th>\n",
       "      <th>market_cap_global</th>\n",
       "      <th>market_dominance</th>\n",
       "      <th>percent_change_24h</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-08-17 01:00:00</th>\n",
       "      <td>3139.761912</td>\n",
       "      <td>3179.462301</td>\n",
       "      <td>3182.182764</td>\n",
       "      <td>3138.543819</td>\n",
       "      <td>1.572350e+09</td>\n",
       "      <td>372060486171</td>\n",
       "      <td>529</td>\n",
       "      <td>272</td>\n",
       "      <td>37.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2878</td>\n",
       "      <td>0.068600</td>\n",
       "      <td>56348</td>\n",
       "      <td>5.107546</td>\n",
       "      <td>2142161972560</td>\n",
       "      <td>17.368457</td>\n",
       "      <td>-4.018101</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-17 02:00:00</th>\n",
       "      <td>3180.878295</td>\n",
       "      <td>3198.536384</td>\n",
       "      <td>3199.727077</td>\n",
       "      <td>3174.424613</td>\n",
       "      <td>1.152643e+09</td>\n",
       "      <td>374535654856</td>\n",
       "      <td>654</td>\n",
       "      <td>319</td>\n",
       "      <td>40.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3315</td>\n",
       "      <td>0.068757</td>\n",
       "      <td>56203</td>\n",
       "      <td>5.898262</td>\n",
       "      <td>2151961698547</td>\n",
       "      <td>17.404383</td>\n",
       "      <td>-3.662531</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-17 03:00:00</th>\n",
       "      <td>3197.676353</td>\n",
       "      <td>3198.998794</td>\n",
       "      <td>3212.707827</td>\n",
       "      <td>3184.497353</td>\n",
       "      <td>1.324026e+09</td>\n",
       "      <td>374690922728</td>\n",
       "      <td>639</td>\n",
       "      <td>310</td>\n",
       "      <td>20.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3087</td>\n",
       "      <td>0.068809</td>\n",
       "      <td>60209</td>\n",
       "      <td>5.127140</td>\n",
       "      <td>2159923806715</td>\n",
       "      <td>17.347414</td>\n",
       "      <td>-2.013159</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-17 04:00:00</th>\n",
       "      <td>3199.206427</td>\n",
       "      <td>3196.827627</td>\n",
       "      <td>3218.532602</td>\n",
       "      <td>3190.825275</td>\n",
       "      <td>1.248667e+09</td>\n",
       "      <td>374770431412</td>\n",
       "      <td>574</td>\n",
       "      <td>306</td>\n",
       "      <td>28.0</td>\n",
       "      <td>726.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2658</td>\n",
       "      <td>0.068833</td>\n",
       "      <td>56070</td>\n",
       "      <td>4.740503</td>\n",
       "      <td>2157259098075</td>\n",
       "      <td>17.372528</td>\n",
       "      <td>-2.557348</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-17 05:00:00</th>\n",
       "      <td>3197.956905</td>\n",
       "      <td>3179.306522</td>\n",
       "      <td>3203.446906</td>\n",
       "      <td>3175.862523</td>\n",
       "      <td>1.622100e+09</td>\n",
       "      <td>373082033586</td>\n",
       "      <td>753</td>\n",
       "      <td>461</td>\n",
       "      <td>39.0</td>\n",
       "      <td>467.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2969</td>\n",
       "      <td>0.068927</td>\n",
       "      <td>54441</td>\n",
       "      <td>5.453610</td>\n",
       "      <td>2137909490256</td>\n",
       "      <td>17.450787</td>\n",
       "      <td>-3.718966</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            open        close         high          low  \\\n",
       "time                                                                      \n",
       "2021-08-17 01:00:00  3139.761912  3179.462301  3182.182764  3138.543819   \n",
       "2021-08-17 02:00:00  3180.878295  3198.536384  3199.727077  3174.424613   \n",
       "2021-08-17 03:00:00  3197.676353  3198.998794  3212.707827  3184.497353   \n",
       "2021-08-17 04:00:00  3199.206427  3196.827627  3218.532602  3190.825275   \n",
       "2021-08-17 05:00:00  3197.956905  3179.306522  3203.446906  3175.862523   \n",
       "\n",
       "                           volume    market_cap  url_shares  \\\n",
       "time                                                          \n",
       "2021-08-17 01:00:00  1.572350e+09  372060486171         529   \n",
       "2021-08-17 02:00:00  1.152643e+09  374535654856         654   \n",
       "2021-08-17 03:00:00  1.324026e+09  374690922728         639   \n",
       "2021-08-17 04:00:00  1.248667e+09  374770431412         574   \n",
       "2021-08-17 05:00:00  1.622100e+09  373082033586         753   \n",
       "\n",
       "                     unique_url_shares  reddit_posts  reddit_posts_score  ...  \\\n",
       "time                                                                      ...   \n",
       "2021-08-17 01:00:00                272          37.0               440.0  ...   \n",
       "2021-08-17 02:00:00                319          40.0               157.0  ...   \n",
       "2021-08-17 03:00:00                310          20.0               170.0  ...   \n",
       "2021-08-17 04:00:00                306          28.0               726.0  ...   \n",
       "2021-08-17 05:00:00                461          39.0               467.0  ...   \n",
       "\n",
       "                     social_volume  price_btc  social_volume_global  \\\n",
       "time                                                                  \n",
       "2021-08-17 01:00:00           2878   0.068600                 56348   \n",
       "2021-08-17 02:00:00           3315   0.068757                 56203   \n",
       "2021-08-17 03:00:00           3087   0.068809                 60209   \n",
       "2021-08-17 04:00:00           2658   0.068833                 56070   \n",
       "2021-08-17 05:00:00           2969   0.068927                 54441   \n",
       "\n",
       "                     social_dominance  market_cap_global  market_dominance  \\\n",
       "time                                                                         \n",
       "2021-08-17 01:00:00          5.107546      2142161972560         17.368457   \n",
       "2021-08-17 02:00:00          5.898262      2151961698547         17.404383   \n",
       "2021-08-17 03:00:00          5.127140      2159923806715         17.347414   \n",
       "2021-08-17 04:00:00          4.740503      2157259098075         17.372528   \n",
       "2021-08-17 05:00:00          5.453610      2137909490256         17.450787   \n",
       "\n",
       "                     percent_change_24h  month  day  hour  \n",
       "time                                                       \n",
       "2021-08-17 01:00:00           -4.018101      8   17     1  \n",
       "2021-08-17 02:00:00           -3.662531      8   17     2  \n",
       "2021-08-17 03:00:00           -2.013159      8   17     3  \n",
       "2021-08-17 04:00:00           -2.557348      8   17     4  \n",
       "2021-08-17 05:00:00           -3.718966      8   17     5  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compile_lc_data(num_days=100, coins=\"ETH\"):\n",
    "    intervals = [\"1d\", \"1w\", \"1m\", \"3m\", \"6m\", \"1y\", \"2y\"]\n",
    "    now = datetime.now()\n",
    "    delta = timedelta(num_days)\n",
    "    ut = datetime.timestamp((now - delta))\n",
    "\n",
    "    payload = {\n",
    "        \"key\": api_key,\n",
    "        \"symbol\": coins,\n",
    "        \"change\": intervals,\n",
    "        \"data_points\": \"720\",\n",
    "        \"start\": ut,\n",
    "        \n",
    "        # \"end\": datetime.timestamp(now),\n",
    "    }\n",
    "\n",
    "    r = requests.get(\"https://api.lunarcrush.com/v2?data=assets\", params=payload)\n",
    "    print(r.url)\n",
    "    # print(r.json())\n",
    "    data = pd.DataFrame.from_dict(r.json()[\"data\"][0])\n",
    "    ts = data.timeSeries.to_dict()\n",
    "    new = pd.DataFrame.from_dict(ts, orient=\"index\")\n",
    "    new.pop(\"asset_id\")\n",
    "    new.pop(\"search_average\")\n",
    "    new[\"time\"] = pd.to_datetime(new[\"time\"], unit=\"s\")\n",
    "    new.set_index(\"time\", inplace=True)\n",
    "    new.sort_index(ascending=True, inplace=True)\n",
    "    new[\"month\"] = [new.index[i].month for i in range(len(new))]\n",
    "    new[\"day\"] = [new.index[i].day for i in range(len(new))]\n",
    "    new[\"hour\"] = [new.index[i].hour for i in range(len(new))]\n",
    "    new.fillna(new.mean(), inplace=True)\n",
    "\n",
    "    return new\n",
    "\n",
    "\n",
    "df = compile_lc_data()\n",
    "print(df.isna().sum().sum())\n",
    "print(df.index.max())\n",
    "print(df.index.min())\n",
    "df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = df.sample(frac=0.8, random_state=0)\n",
    "test_ds = df.drop(train_ds.index)\n",
    "\n",
    "train_features = train_ds.copy()\n",
    "test_features = test_ds.copy()\n",
    "\n",
    "train_label = train_features.pop(\"close\")\n",
    "test_labels = test_features.pop(\"close\")\n",
    "\n",
    "\n",
    "# ds = tf.data.Dataset.from_tensor_slices((features, label)).batch(32)\n",
    "\n",
    "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "normalizer.adapt(np.array(train_features).astype(\"float32\"))\n",
    "\n",
    "linear_model = tf.keras.models.Sequential([normalizer, tf.keras.layers.Dense(1)])\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "linear_model.compile(optimizer=optimizer, loss=\"mse\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'dense/kernel:0' shape=(58, 1) dtype=float32, numpy=\n",
       "array([[-0.3004485 ],\n",
       "       [-0.26289377],\n",
       "       [-0.00128037],\n",
       "       [ 0.24445736],\n",
       "       [ 0.27752304],\n",
       "       [-0.2999052 ],\n",
       "       [-0.165909  ],\n",
       "       [ 0.17040107],\n",
       "       [-0.05109468],\n",
       "       [-0.06189838],\n",
       "       [ 0.03506061],\n",
       "       [-0.13656278],\n",
       "       [-0.02032813],\n",
       "       [ 0.2562182 ],\n",
       "       [-0.26320922],\n",
       "       [ 0.07644382],\n",
       "       [-0.16917817],\n",
       "       [-0.17606756],\n",
       "       [-0.3119776 ],\n",
       "       [-0.0379571 ],\n",
       "       [ 0.27487564],\n",
       "       [-0.16923405],\n",
       "       [-0.06943926],\n",
       "       [-0.03104264],\n",
       "       [ 0.05635193],\n",
       "       [ 0.16255239],\n",
       "       [-0.04242444],\n",
       "       [ 0.0940147 ],\n",
       "       [ 0.04281959],\n",
       "       [ 0.15197036],\n",
       "       [ 0.13552085],\n",
       "       [ 0.06689322],\n",
       "       [ 0.16213483],\n",
       "       [ 0.12362188],\n",
       "       [ 0.26082253],\n",
       "       [-0.03940722],\n",
       "       [ 0.19352949],\n",
       "       [ 0.04616386],\n",
       "       [ 0.04315075],\n",
       "       [ 0.27530718],\n",
       "       [-0.18275136],\n",
       "       [ 0.11564615],\n",
       "       [-0.24021325],\n",
       "       [-0.25607944],\n",
       "       [ 0.20565617],\n",
       "       [-0.00242919],\n",
       "       [-0.3082522 ],\n",
       "       [-0.00233081],\n",
       "       [ 0.13307768],\n",
       "       [ 0.30383247],\n",
       "       [ 0.30238622],\n",
       "       [ 0.24957335],\n",
       "       [ 0.23967618],\n",
       "       [-0.2647905 ],\n",
       "       [-0.23234718],\n",
       "       [-0.13089262],\n",
       "       [-0.19121814],\n",
       "       [-0.06942657]], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.layers[1].kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "15/15 [==============================] - 1s 11ms/step - loss: 12863310.0000 - val_loss: 13087858.0000\n",
      "Epoch 2/20\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 12862960.0000 - val_loss: 13087573.0000\n",
      "Epoch 3/20\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 12862639.0000 - val_loss: 13087283.0000\n",
      "Epoch 4/20\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 12862319.0000 - val_loss: 13087002.0000\n",
      "Epoch 5/20\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 12861994.0000 - val_loss: 13086702.0000\n",
      "Epoch 6/20\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 12861672.0000 - val_loss: 13086417.0000\n",
      "Epoch 7/20\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 12861347.0000 - val_loss: 13086146.0000\n",
      "Epoch 8/20\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 12861021.0000 - val_loss: 13085868.0000\n",
      "Epoch 9/20\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 12860704.0000 - val_loss: 13085570.0000\n",
      "Epoch 10/20\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 12860390.0000 - val_loss: 13085308.0000\n",
      "Epoch 11/20\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 12860058.0000 - val_loss: 13085022.0000\n",
      "Epoch 12/20\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 12859736.0000 - val_loss: 13084740.0000\n",
      "Epoch 13/20\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 12859416.0000 - val_loss: 13084460.0000\n",
      "Epoch 14/20\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 12859082.0000 - val_loss: 13084175.0000\n",
      "Epoch 15/20\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 12858772.0000 - val_loss: 13083917.0000\n",
      "Epoch 16/20\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 12858450.0000 - val_loss: 13083599.0000\n",
      "Epoch 17/20\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 12858120.0000 - val_loss: 13083329.0000\n",
      "Epoch 18/20\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 12857793.0000 - val_loss: 13083021.0000\n",
      "Epoch 19/20\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 12857471.0000 - val_loss: 13082729.0000\n",
      "Epoch 20/20\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 12857143.0000 - val_loss: 13082439.0000\n",
      "Wall time: 2.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\", patience=4, mode=\"min\"\n",
    "    )\n",
    "history = linear_model.fit(\n",
    "    train_features,\n",
    "    train_label,\n",
    "    epochs=2000,\n",
    "    validation_split=.2,\n",
    "    callbacks=[early_stopping],\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12858450.0</td>\n",
       "      <td>13083599.0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>12858120.0</td>\n",
       "      <td>13083329.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>12857793.0</td>\n",
       "      <td>13083021.0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>12857471.0</td>\n",
       "      <td>13082729.0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>12857143.0</td>\n",
       "      <td>13082439.0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          loss    val_loss  epoch\n",
       "15  12858450.0  13083599.0     15\n",
       "16  12858120.0  13083329.0     16\n",
       "17  12857793.0  13083021.0     17\n",
       "18  12857471.0  13082729.0     18\n",
       "19  12857143.0  13082439.0     19"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist[\"epoch\"] = history.epoch\n",
    "hist.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = {}\n",
    "\n",
    "test_results[\"linear_baseline\"] = linear_model.evaluate(\n",
    "    test_features, test_labels, verbose=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_compile_model(norm):\n",
    "    model = tf.keras.models.Sequential(\n",
    "        [\n",
    "            norm,\n",
    "            tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(1),\n",
    "        ]\n",
    "    )\n",
    "    model.compile(\n",
    "        loss=\"mse\", optimizer=\"adam\", metrics=[tf.metrics.MeanAbsoluteError()]\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "normalization (Normalization (None, 58)                117       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                3776      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 8,118\n",
      "Trainable params: 8,001\n",
      "Non-trainable params: 117\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dnn_model = build_and_compile_model(normalizer)\n",
    "\n",
    "dnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 12858347.0000 - mean_absolute_error: 3567.2588 - val_loss: 13074611.0000 - val_mean_absolute_error: 3594.1011\n",
      "Epoch 2/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 12838979.0000 - mean_absolute_error: 3564.5413 - val_loss: 13052147.0000 - val_mean_absolute_error: 3590.9646\n",
      "Epoch 3/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 12810039.0000 - mean_absolute_error: 3560.4766 - val_loss: 13014353.0000 - val_mean_absolute_error: 3585.6929\n",
      "Epoch 4/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 12760512.0000 - mean_absolute_error: 3553.5181 - val_loss: 12949472.0000 - val_mean_absolute_error: 3576.6426\n",
      "Epoch 5/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 12676611.0000 - mean_absolute_error: 3541.7441 - val_loss: 12843124.0000 - val_mean_absolute_error: 3561.7798\n",
      "Epoch 6/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 12543178.0000 - mean_absolute_error: 3522.9001 - val_loss: 12676610.0000 - val_mean_absolute_error: 3538.4666\n",
      "Epoch 7/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 12340815.0000 - mean_absolute_error: 3494.2310 - val_loss: 12434230.0000 - val_mean_absolute_error: 3504.2258\n",
      "Epoch 8/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 12051528.0000 - mean_absolute_error: 3452.8613 - val_loss: 12097315.0000 - val_mean_absolute_error: 3456.0410\n",
      "Epoch 9/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 11661680.0000 - mean_absolute_error: 3396.1931 - val_loss: 11647550.0000 - val_mean_absolute_error: 3390.7537\n",
      "Epoch 10/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 11152664.0000 - mean_absolute_error: 3320.5774 - val_loss: 11077731.0000 - val_mean_absolute_error: 3305.7822\n",
      "Epoch 11/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10522232.0000 - mean_absolute_error: 3223.8911 - val_loss: 10382574.0000 - val_mean_absolute_error: 3198.5806\n",
      "Epoch 12/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9773394.0000 - mean_absolute_error: 3104.1021 - val_loss: 9571495.0000 - val_mean_absolute_error: 3067.7351\n",
      "Epoch 13/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 8918469.0000 - mean_absolute_error: 2960.7073 - val_loss: 8660160.0000 - val_mean_absolute_error: 2912.2629\n",
      "Epoch 14/2000\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 7976045.0000 - mean_absolute_error: 2791.1511 - val_loss: 7675468.0000 - val_mean_absolute_error: 2732.0024\n",
      "Epoch 15/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 6973837.5000 - mean_absolute_error: 2596.1013 - val_loss: 6662627.5000 - val_mean_absolute_error: 2528.6926\n",
      "Epoch 16/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 5980531.5000 - mean_absolute_error: 2386.6702 - val_loss: 5657191.5000 - val_mean_absolute_error: 2304.3350\n",
      "Epoch 17/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 5021192.0000 - mean_absolute_error: 2154.3552 - val_loss: 4719106.0000 - val_mean_absolute_error: 2066.3484\n",
      "Epoch 18/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 4166233.5000 - mean_absolute_error: 1924.2522 - val_loss: 3899040.5000 - val_mean_absolute_error: 1823.3940\n",
      "Epoch 19/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 3434885.7500 - mean_absolute_error: 1712.7855 - val_loss: 3241251.5000 - val_mean_absolute_error: 1619.7748\n",
      "Epoch 20/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 2879387.5000 - mean_absolute_error: 1535.2002 - val_loss: 2708598.2500 - val_mean_absolute_error: 1452.1851\n",
      "Epoch 21/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 2440989.5000 - mean_absolute_error: 1392.2074 - val_loss: 2332648.2500 - val_mean_absolute_error: 1342.2244\n",
      "Epoch 22/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2138466.7500 - mean_absolute_error: 1276.9680 - val_loss: 2059129.7500 - val_mean_absolute_error: 1265.3586\n",
      "Epoch 23/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1917521.5000 - mean_absolute_error: 1191.4260 - val_loss: 1864440.5000 - val_mean_absolute_error: 1204.3516\n",
      "Epoch 24/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1750000.1250 - mean_absolute_error: 1125.5333 - val_loss: 1725618.7500 - val_mean_absolute_error: 1154.3773\n",
      "Epoch 25/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1625907.5000 - mean_absolute_error: 1072.1962 - val_loss: 1611835.8750 - val_mean_absolute_error: 1107.6903\n",
      "Epoch 26/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1511626.5000 - mean_absolute_error: 1026.6661 - val_loss: 1515803.7500 - val_mean_absolute_error: 1071.1428\n",
      "Epoch 27/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1412497.8750 - mean_absolute_error: 986.5250 - val_loss: 1428936.2500 - val_mean_absolute_error: 1034.4810\n",
      "Epoch 28/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1316018.2500 - mean_absolute_error: 946.4559 - val_loss: 1349469.8750 - val_mean_absolute_error: 1001.2726\n",
      "Epoch 29/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1225444.3750 - mean_absolute_error: 909.8117 - val_loss: 1279299.2500 - val_mean_absolute_error: 970.9621\n",
      "Epoch 30/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1146204.1250 - mean_absolute_error: 876.4828 - val_loss: 1210028.3750 - val_mean_absolute_error: 941.2046\n",
      "Epoch 31/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1065937.5000 - mean_absolute_error: 841.1000 - val_loss: 1147707.6250 - val_mean_absolute_error: 909.2157\n",
      "Epoch 32/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 994407.0000 - mean_absolute_error: 808.7123 - val_loss: 1087997.6250 - val_mean_absolute_error: 878.8510\n",
      "Epoch 33/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 926739.9375 - mean_absolute_error: 776.2023 - val_loss: 1031337.2500 - val_mean_absolute_error: 848.8587\n",
      "Epoch 34/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 862785.0625 - mean_absolute_error: 746.8242 - val_loss: 979124.1250 - val_mean_absolute_error: 821.6117\n",
      "Epoch 35/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 806091.3125 - mean_absolute_error: 718.5468 - val_loss: 930064.5625 - val_mean_absolute_error: 793.5862\n",
      "Epoch 36/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 749162.8750 - mean_absolute_error: 689.1141 - val_loss: 883683.0625 - val_mean_absolute_error: 769.1542\n",
      "Epoch 37/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 703481.7500 - mean_absolute_error: 664.5666 - val_loss: 837409.2500 - val_mean_absolute_error: 745.1227\n",
      "Epoch 38/2000\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 652210.6250 - mean_absolute_error: 638.0021 - val_loss: 800963.3125 - val_mean_absolute_error: 723.3021\n",
      "Epoch 39/2000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 608493.6250 - mean_absolute_error: 613.7726 - val_loss: 761255.5625 - val_mean_absolute_error: 704.4134\n",
      "Epoch 40/2000\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 568765.6250 - mean_absolute_error: 590.9983 - val_loss: 726153.6250 - val_mean_absolute_error: 685.5318\n",
      "Epoch 41/2000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 532687.4375 - mean_absolute_error: 569.1078 - val_loss: 695788.1250 - val_mean_absolute_error: 668.2921\n",
      "Epoch 42/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 496922.0312 - mean_absolute_error: 548.1283 - val_loss: 669369.2500 - val_mean_absolute_error: 651.6412\n",
      "Epoch 43/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 467118.9375 - mean_absolute_error: 528.7147 - val_loss: 642730.8125 - val_mean_absolute_error: 635.1720\n",
      "Epoch 44/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 436958.5312 - mean_absolute_error: 510.0330 - val_loss: 617690.3750 - val_mean_absolute_error: 620.1824\n",
      "Epoch 45/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 410721.4375 - mean_absolute_error: 494.1740 - val_loss: 592491.1250 - val_mean_absolute_error: 605.4122\n",
      "Epoch 46/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 385089.9062 - mean_absolute_error: 479.6139 - val_loss: 573005.8125 - val_mean_absolute_error: 593.7391\n",
      "Epoch 47/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 363534.1250 - mean_absolute_error: 465.4926 - val_loss: 551730.3750 - val_mean_absolute_error: 582.4107\n",
      "Epoch 48/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 343881.5000 - mean_absolute_error: 452.2353 - val_loss: 534743.4375 - val_mean_absolute_error: 571.9282\n",
      "Epoch 49/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 325479.1250 - mean_absolute_error: 439.0054 - val_loss: 514521.5312 - val_mean_absolute_error: 561.2657\n",
      "Epoch 50/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 308435.1562 - mean_absolute_error: 427.4590 - val_loss: 498056.9062 - val_mean_absolute_error: 551.4012\n",
      "Epoch 51/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 293217.2500 - mean_absolute_error: 417.2617 - val_loss: 482257.9688 - val_mean_absolute_error: 543.4523\n",
      "Epoch 52/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 279143.4375 - mean_absolute_error: 407.0788 - val_loss: 467745.3125 - val_mean_absolute_error: 534.9098\n",
      "Epoch 53/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 266415.3750 - mean_absolute_error: 396.8894 - val_loss: 456806.8750 - val_mean_absolute_error: 526.9901\n",
      "Epoch 54/2000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 253782.4375 - mean_absolute_error: 388.3638 - val_loss: 441196.3750 - val_mean_absolute_error: 519.5319\n",
      "Epoch 55/2000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 242460.3438 - mean_absolute_error: 380.4486 - val_loss: 428730.0312 - val_mean_absolute_error: 512.1181\n",
      "Epoch 56/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 232441.2500 - mean_absolute_error: 373.0693 - val_loss: 414248.1875 - val_mean_absolute_error: 503.7400\n",
      "Epoch 57/2000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 222176.7812 - mean_absolute_error: 365.8039 - val_loss: 403141.7188 - val_mean_absolute_error: 495.6653\n",
      "Epoch 58/2000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 213457.0312 - mean_absolute_error: 358.3598 - val_loss: 392215.5625 - val_mean_absolute_error: 487.9047\n",
      "Epoch 59/2000\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 204827.7812 - mean_absolute_error: 351.5200 - val_loss: 382373.2500 - val_mean_absolute_error: 481.0328\n",
      "Epoch 60/2000\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 196891.4219 - mean_absolute_error: 344.8508 - val_loss: 373110.5938 - val_mean_absolute_error: 474.3244\n",
      "Epoch 61/2000\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 189540.6094 - mean_absolute_error: 338.8806 - val_loss: 361845.9062 - val_mean_absolute_error: 467.6843\n",
      "Epoch 62/2000\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 182844.2656 - mean_absolute_error: 333.9887 - val_loss: 351914.9062 - val_mean_absolute_error: 461.5594\n",
      "Epoch 63/2000\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 176040.2188 - mean_absolute_error: 328.0387 - val_loss: 343478.6875 - val_mean_absolute_error: 455.4319\n",
      "Epoch 64/2000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 170113.7500 - mean_absolute_error: 322.6816 - val_loss: 334745.4375 - val_mean_absolute_error: 449.5515\n",
      "Epoch 65/2000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 164453.2031 - mean_absolute_error: 317.4308 - val_loss: 326403.7500 - val_mean_absolute_error: 442.9115\n",
      "Epoch 66/2000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 158912.4531 - mean_absolute_error: 312.0786 - val_loss: 318079.3438 - val_mean_absolute_error: 436.0715\n",
      "Epoch 67/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 153754.5781 - mean_absolute_error: 307.3527 - val_loss: 309922.4062 - val_mean_absolute_error: 430.4725\n",
      "Epoch 68/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 148928.9219 - mean_absolute_error: 302.9813 - val_loss: 302833.0625 - val_mean_absolute_error: 425.5040\n",
      "Epoch 69/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 144191.0312 - mean_absolute_error: 298.2919 - val_loss: 296209.2812 - val_mean_absolute_error: 419.8108\n",
      "Epoch 70/2000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 139768.1719 - mean_absolute_error: 293.6506 - val_loss: 288967.6562 - val_mean_absolute_error: 414.4379\n",
      "Epoch 71/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 135741.0625 - mean_absolute_error: 288.8939 - val_loss: 283268.7812 - val_mean_absolute_error: 409.5197\n",
      "Epoch 72/2000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 131708.5000 - mean_absolute_error: 284.2347 - val_loss: 276454.3438 - val_mean_absolute_error: 404.4117\n",
      "Epoch 73/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 127799.9062 - mean_absolute_error: 280.3962 - val_loss: 269132.6875 - val_mean_absolute_error: 399.3386\n",
      "Epoch 74/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 124202.3750 - mean_absolute_error: 276.7381 - val_loss: 262135.5625 - val_mean_absolute_error: 394.1746\n",
      "Epoch 75/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 120615.7734 - mean_absolute_error: 272.9765 - val_loss: 255479.4688 - val_mean_absolute_error: 388.9477\n",
      "Epoch 76/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 116932.4141 - mean_absolute_error: 268.9167 - val_loss: 248727.1406 - val_mean_absolute_error: 384.2267\n",
      "Epoch 77/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 113803.0000 - mean_absolute_error: 265.4265 - val_loss: 242642.7969 - val_mean_absolute_error: 379.8797\n",
      "Epoch 78/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 110805.2109 - mean_absolute_error: 262.1585 - val_loss: 236829.1875 - val_mean_absolute_error: 375.4350\n",
      "Epoch 79/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 107357.2266 - mean_absolute_error: 258.0347 - val_loss: 231653.4062 - val_mean_absolute_error: 370.6139\n",
      "Epoch 80/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 104712.3203 - mean_absolute_error: 254.9171 - val_loss: 226486.7031 - val_mean_absolute_error: 366.1429\n",
      "Epoch 81/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 101693.7266 - mean_absolute_error: 251.2601 - val_loss: 221104.0000 - val_mean_absolute_error: 361.8575\n",
      "Epoch 82/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 98920.5391 - mean_absolute_error: 247.8925 - val_loss: 216379.5312 - val_mean_absolute_error: 357.7585\n",
      "Epoch 83/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 96345.5703 - mean_absolute_error: 244.8468 - val_loss: 211100.4531 - val_mean_absolute_error: 353.1188\n",
      "Epoch 84/2000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 93615.6797 - mean_absolute_error: 241.7400 - val_loss: 204454.7656 - val_mean_absolute_error: 348.7315\n",
      "Epoch 85/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 91057.0312 - mean_absolute_error: 238.9548 - val_loss: 200226.6875 - val_mean_absolute_error: 344.2558\n",
      "Epoch 86/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 88667.6406 - mean_absolute_error: 235.8607 - val_loss: 196142.7812 - val_mean_absolute_error: 340.4137\n",
      "Epoch 87/2000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 86448.6094 - mean_absolute_error: 232.8414 - val_loss: 191120.9844 - val_mean_absolute_error: 335.4756\n",
      "Epoch 88/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 84374.9844 - mean_absolute_error: 230.1010 - val_loss: 186580.0938 - val_mean_absolute_error: 331.5125\n",
      "Epoch 89/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 81944.2031 - mean_absolute_error: 227.0457 - val_loss: 181498.8594 - val_mean_absolute_error: 326.9875\n",
      "Epoch 90/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 79989.4141 - mean_absolute_error: 224.3015 - val_loss: 177727.6875 - val_mean_absolute_error: 323.1771\n",
      "Epoch 91/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 78026.3281 - mean_absolute_error: 221.7319 - val_loss: 173531.5469 - val_mean_absolute_error: 318.9216\n",
      "Epoch 92/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 76125.8047 - mean_absolute_error: 219.4933 - val_loss: 168140.2031 - val_mean_absolute_error: 315.3178\n",
      "Epoch 93/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 74092.6328 - mean_absolute_error: 216.6934 - val_loss: 164763.7656 - val_mean_absolute_error: 311.2999\n",
      "Epoch 94/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 72446.8359 - mean_absolute_error: 214.5188 - val_loss: 161028.8906 - val_mean_absolute_error: 307.2304\n",
      "Epoch 95/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 70566.0547 - mean_absolute_error: 211.7996 - val_loss: 157120.7969 - val_mean_absolute_error: 303.7192\n",
      "Epoch 96/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 69111.8750 - mean_absolute_error: 209.6865 - val_loss: 152997.4688 - val_mean_absolute_error: 300.2341\n",
      "Epoch 97/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 67499.3984 - mean_absolute_error: 207.4390 - val_loss: 149699.9062 - val_mean_absolute_error: 295.9320\n",
      "Epoch 98/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 65931.5703 - mean_absolute_error: 204.8690 - val_loss: 146748.5000 - val_mean_absolute_error: 291.7430\n",
      "Epoch 99/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 64320.8359 - mean_absolute_error: 202.4736 - val_loss: 142782.4219 - val_mean_absolute_error: 287.9274\n",
      "Epoch 100/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 62841.6406 - mean_absolute_error: 200.4313 - val_loss: 139419.6875 - val_mean_absolute_error: 286.1989\n",
      "Epoch 101/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 61462.7383 - mean_absolute_error: 198.5994 - val_loss: 136346.2656 - val_mean_absolute_error: 283.1068\n",
      "Epoch 102/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 60055.9297 - mean_absolute_error: 196.4831 - val_loss: 133080.1875 - val_mean_absolute_error: 279.1250\n",
      "Epoch 103/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 58614.6055 - mean_absolute_error: 194.0269 - val_loss: 130298.4922 - val_mean_absolute_error: 275.5235\n",
      "Epoch 104/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 57211.0703 - mean_absolute_error: 191.6975 - val_loss: 127810.3906 - val_mean_absolute_error: 272.4228\n",
      "Epoch 105/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 55976.5156 - mean_absolute_error: 189.7817 - val_loss: 124727.0703 - val_mean_absolute_error: 269.2578\n",
      "Epoch 106/2000\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 54720.0039 - mean_absolute_error: 187.6618 - val_loss: 122157.5547 - val_mean_absolute_error: 266.0518\n",
      "Epoch 107/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 53508.1211 - mean_absolute_error: 185.7343 - val_loss: 119291.4062 - val_mean_absolute_error: 263.4575\n",
      "Epoch 108/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 52405.4570 - mean_absolute_error: 183.9383 - val_loss: 117141.6094 - val_mean_absolute_error: 260.4859\n",
      "Epoch 109/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 51262.0742 - mean_absolute_error: 181.7345 - val_loss: 114801.3984 - val_mean_absolute_error: 256.9021\n",
      "Epoch 110/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 50194.3398 - mean_absolute_error: 179.5882 - val_loss: 112769.1016 - val_mean_absolute_error: 254.1606\n",
      "Epoch 111/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 49166.0000 - mean_absolute_error: 177.7897 - val_loss: 110512.6328 - val_mean_absolute_error: 251.6251\n",
      "Epoch 112/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 48110.8086 - mean_absolute_error: 175.9258 - val_loss: 108634.1094 - val_mean_absolute_error: 249.4449\n",
      "Epoch 113/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 47207.2109 - mean_absolute_error: 174.2916 - val_loss: 105558.2031 - val_mean_absolute_error: 246.6275\n",
      "Epoch 114/2000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 46253.1211 - mean_absolute_error: 172.6223 - val_loss: 103801.3438 - val_mean_absolute_error: 244.0934\n",
      "Epoch 115/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 45278.7891 - mean_absolute_error: 170.6698 - val_loss: 102145.2578 - val_mean_absolute_error: 241.7040\n",
      "Epoch 116/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 44467.4102 - mean_absolute_error: 168.8214 - val_loss: 100022.5938 - val_mean_absolute_error: 239.4562\n",
      "Epoch 117/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 43474.5781 - mean_absolute_error: 167.1086 - val_loss: 97426.6797 - val_mean_absolute_error: 236.6820\n",
      "Epoch 118/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 42642.7500 - mean_absolute_error: 165.5881 - val_loss: 96149.4219 - val_mean_absolute_error: 234.3921\n",
      "Epoch 119/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 41866.7383 - mean_absolute_error: 163.8772 - val_loss: 94455.2422 - val_mean_absolute_error: 231.4350\n",
      "Epoch 120/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 41049.1328 - mean_absolute_error: 162.2177 - val_loss: 92591.0312 - val_mean_absolute_error: 229.5560\n",
      "Epoch 121/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 40358.0352 - mean_absolute_error: 160.8076 - val_loss: 90646.9766 - val_mean_absolute_error: 227.1655\n",
      "Epoch 122/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 39555.3477 - mean_absolute_error: 159.1071 - val_loss: 89094.2734 - val_mean_absolute_error: 225.4105\n",
      "Epoch 123/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 38889.9609 - mean_absolute_error: 157.5428 - val_loss: 87784.7578 - val_mean_absolute_error: 223.8478\n",
      "Epoch 124/2000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 38266.1602 - mean_absolute_error: 156.2308 - val_loss: 86436.2344 - val_mean_absolute_error: 220.8109\n",
      "Epoch 125/2000\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 37423.3672 - mean_absolute_error: 154.2575 - val_loss: 84780.4844 - val_mean_absolute_error: 219.3485\n",
      "Epoch 126/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 36793.0234 - mean_absolute_error: 153.0780 - val_loss: 83413.7578 - val_mean_absolute_error: 217.6698\n",
      "Epoch 127/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 36182.1406 - mean_absolute_error: 151.6338 - val_loss: 82279.9531 - val_mean_absolute_error: 216.0511\n",
      "Epoch 128/2000\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 35619.0078 - mean_absolute_error: 150.3198 - val_loss: 80821.2031 - val_mean_absolute_error: 214.2660\n",
      "Epoch 129/2000\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 34991.2109 - mean_absolute_error: 149.1206 - val_loss: 78992.0078 - val_mean_absolute_error: 211.8337\n",
      "Epoch 130/2000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 34412.4570 - mean_absolute_error: 147.9424 - val_loss: 77751.2422 - val_mean_absolute_error: 210.1199\n",
      "Epoch 131/2000\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 33832.8828 - mean_absolute_error: 146.6075 - val_loss: 76936.7969 - val_mean_absolute_error: 208.8267\n",
      "Epoch 132/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 33389.6406 - mean_absolute_error: 145.3870 - val_loss: 75939.7500 - val_mean_absolute_error: 207.6339\n",
      "Epoch 133/2000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 32706.6855 - mean_absolute_error: 143.7189 - val_loss: 74987.5234 - val_mean_absolute_error: 206.1443\n",
      "Epoch 134/2000\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 32233.0332 - mean_absolute_error: 142.6722 - val_loss: 73799.4141 - val_mean_absolute_error: 204.6090\n",
      "Epoch 135/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 31687.6016 - mean_absolute_error: 141.3382 - val_loss: 72954.7422 - val_mean_absolute_error: 203.5586\n",
      "Epoch 136/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 31187.0977 - mean_absolute_error: 140.1507 - val_loss: 71638.9609 - val_mean_absolute_error: 201.6861\n",
      "Epoch 137/2000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 30680.9336 - mean_absolute_error: 138.8947 - val_loss: 70280.8359 - val_mean_absolute_error: 199.8540\n",
      "Epoch 138/2000\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 30208.9883 - mean_absolute_error: 137.8451 - val_loss: 69947.0859 - val_mean_absolute_error: 199.8658\n",
      "Epoch 139/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 29843.7773 - mean_absolute_error: 137.1002 - val_loss: 68978.5547 - val_mean_absolute_error: 198.0488\n",
      "Epoch 140/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 29486.3301 - mean_absolute_error: 136.2073 - val_loss: 68463.1953 - val_mean_absolute_error: 198.2504\n",
      "Epoch 141/2000\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 28943.9102 - mean_absolute_error: 134.8666 - val_loss: 66634.2109 - val_mean_absolute_error: 195.1630\n",
      "Epoch 142/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 28531.2910 - mean_absolute_error: 133.9520 - val_loss: 65530.9414 - val_mean_absolute_error: 193.8078\n",
      "Epoch 143/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 28146.2148 - mean_absolute_error: 133.0903 - val_loss: 64628.4492 - val_mean_absolute_error: 193.3605\n",
      "Epoch 144/2000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 27809.4434 - mean_absolute_error: 132.1671 - val_loss: 64827.7656 - val_mean_absolute_error: 193.0515\n",
      "Epoch 145/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 27320.3125 - mean_absolute_error: 130.7995 - val_loss: 63369.5547 - val_mean_absolute_error: 191.1173\n",
      "Epoch 146/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 26991.4375 - mean_absolute_error: 130.1981 - val_loss: 63677.9570 - val_mean_absolute_error: 191.5236\n",
      "Epoch 147/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 26530.7910 - mean_absolute_error: 129.2079 - val_loss: 62154.9648 - val_mean_absolute_error: 188.9817\n",
      "Epoch 148/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 26316.2285 - mean_absolute_error: 128.4490 - val_loss: 60777.6328 - val_mean_absolute_error: 187.4741\n",
      "Epoch 149/2000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 25848.6523 - mean_absolute_error: 127.1559 - val_loss: 61077.0859 - val_mean_absolute_error: 188.2782\n",
      "Epoch 150/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 25497.1836 - mean_absolute_error: 126.1947 - val_loss: 60512.3672 - val_mean_absolute_error: 187.5932\n",
      "Epoch 151/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 25125.5566 - mean_absolute_error: 125.2654 - val_loss: 59419.9180 - val_mean_absolute_error: 185.8367\n",
      "Epoch 152/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 24774.5488 - mean_absolute_error: 124.3059 - val_loss: 58350.9062 - val_mean_absolute_error: 184.7447\n",
      "Epoch 153/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 24444.9863 - mean_absolute_error: 123.5715 - val_loss: 57910.0703 - val_mean_absolute_error: 184.1074\n",
      "Epoch 154/2000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 24127.6914 - mean_absolute_error: 122.6436 - val_loss: 56846.7227 - val_mean_absolute_error: 182.2285\n",
      "Epoch 155/2000\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 23854.0020 - mean_absolute_error: 121.7410 - val_loss: 56303.5508 - val_mean_absolute_error: 181.5637\n",
      "Epoch 156/2000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 23493.7383 - mean_absolute_error: 120.7038 - val_loss: 55739.4219 - val_mean_absolute_error: 180.7505\n",
      "Epoch 157/2000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 23225.6738 - mean_absolute_error: 120.2449 - val_loss: 54939.9258 - val_mean_absolute_error: 179.6882\n",
      "Epoch 158/2000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 22979.9336 - mean_absolute_error: 119.4060 - val_loss: 54599.7422 - val_mean_absolute_error: 178.7546\n",
      "Epoch 159/2000\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 22570.7539 - mean_absolute_error: 118.3492 - val_loss: 54085.3164 - val_mean_absolute_error: 178.4291\n",
      "Epoch 160/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 22336.1523 - mean_absolute_error: 117.5308 - val_loss: 53382.5078 - val_mean_absolute_error: 177.3263\n",
      "Epoch 161/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 22155.7324 - mean_absolute_error: 116.9317 - val_loss: 53470.4141 - val_mean_absolute_error: 177.7408\n",
      "Epoch 162/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 21844.3086 - mean_absolute_error: 115.9890 - val_loss: 51896.8867 - val_mean_absolute_error: 174.8442\n",
      "Epoch 163/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 21574.9004 - mean_absolute_error: 115.3184 - val_loss: 51586.1016 - val_mean_absolute_error: 174.0815\n",
      "Epoch 164/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 21270.5078 - mean_absolute_error: 114.3945 - val_loss: 51568.2891 - val_mean_absolute_error: 174.4368\n",
      "Epoch 165/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 21025.4902 - mean_absolute_error: 113.5369 - val_loss: 51168.8359 - val_mean_absolute_error: 173.7563\n",
      "Epoch 166/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 20755.7793 - mean_absolute_error: 112.8344 - val_loss: 51074.3750 - val_mean_absolute_error: 173.9262\n",
      "Epoch 167/2000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 20542.6191 - mean_absolute_error: 112.3223 - val_loss: 50618.9961 - val_mean_absolute_error: 172.8766\n",
      "Epoch 168/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 20317.5879 - mean_absolute_error: 111.6629 - val_loss: 49263.9531 - val_mean_absolute_error: 171.0590\n",
      "Epoch 169/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 20082.6328 - mean_absolute_error: 110.9055 - val_loss: 49190.6328 - val_mean_absolute_error: 170.8369\n",
      "Epoch 170/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19810.9980 - mean_absolute_error: 110.2178 - val_loss: 48777.1211 - val_mean_absolute_error: 170.1122\n",
      "Epoch 171/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19639.6035 - mean_absolute_error: 109.6759 - val_loss: 48623.7344 - val_mean_absolute_error: 170.0234\n",
      "Epoch 172/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19434.6699 - mean_absolute_error: 108.7245 - val_loss: 47229.4219 - val_mean_absolute_error: 167.6216\n",
      "Epoch 173/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19189.5332 - mean_absolute_error: 108.2423 - val_loss: 47369.8203 - val_mean_absolute_error: 168.0299\n",
      "Epoch 174/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 18983.7246 - mean_absolute_error: 107.9955 - val_loss: 47223.2383 - val_mean_absolute_error: 167.6075\n",
      "Epoch 175/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 18754.9766 - mean_absolute_error: 107.1928 - val_loss: 46825.3672 - val_mean_absolute_error: 167.0280\n",
      "Epoch 176/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 18529.1777 - mean_absolute_error: 106.3061 - val_loss: 46213.0000 - val_mean_absolute_error: 166.1616\n",
      "Epoch 177/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 18327.5879 - mean_absolute_error: 105.6512 - val_loss: 45844.0508 - val_mean_absolute_error: 165.5851\n",
      "Epoch 178/2000\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 18107.7168 - mean_absolute_error: 104.9786 - val_loss: 45570.4531 - val_mean_absolute_error: 165.2148\n",
      "Epoch 179/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 17919.5703 - mean_absolute_error: 104.5864 - val_loss: 44769.4180 - val_mean_absolute_error: 163.7108\n",
      "Epoch 180/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 17760.4375 - mean_absolute_error: 103.9549 - val_loss: 43973.6094 - val_mean_absolute_error: 162.4925\n",
      "Epoch 181/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 17561.4375 - mean_absolute_error: 103.6531 - val_loss: 43853.3281 - val_mean_absolute_error: 162.5231\n",
      "Epoch 182/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 17308.2070 - mean_absolute_error: 102.7071 - val_loss: 43515.6289 - val_mean_absolute_error: 161.5304\n",
      "Epoch 183/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 17173.1348 - mean_absolute_error: 102.5957 - val_loss: 44510.1328 - val_mean_absolute_error: 162.9658\n",
      "Epoch 184/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 16973.3340 - mean_absolute_error: 101.8754 - val_loss: 43925.5273 - val_mean_absolute_error: 161.9713\n",
      "Epoch 185/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 16777.0547 - mean_absolute_error: 101.2558 - val_loss: 43099.6367 - val_mean_absolute_error: 160.4140\n",
      "Epoch 186/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 16581.0410 - mean_absolute_error: 100.7057 - val_loss: 42340.9570 - val_mean_absolute_error: 159.2396\n",
      "Epoch 187/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 16472.3809 - mean_absolute_error: 99.9611 - val_loss: 41740.2852 - val_mean_absolute_error: 158.0337\n",
      "Epoch 188/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 16292.8789 - mean_absolute_error: 99.7336 - val_loss: 41893.0703 - val_mean_absolute_error: 158.7009\n",
      "Epoch 189/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 16174.4502 - mean_absolute_error: 99.2422 - val_loss: 42322.4844 - val_mean_absolute_error: 159.8830\n",
      "Epoch 190/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 16004.2764 - mean_absolute_error: 98.2365 - val_loss: 40878.7617 - val_mean_absolute_error: 156.4890\n",
      "Epoch 191/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 15844.6416 - mean_absolute_error: 98.2585 - val_loss: 41729.8320 - val_mean_absolute_error: 158.5912\n",
      "Epoch 192/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 15590.5107 - mean_absolute_error: 97.4830 - val_loss: 40956.3398 - val_mean_absolute_error: 156.4463\n",
      "Epoch 193/2000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 15411.6533 - mean_absolute_error: 96.9508 - val_loss: 40506.9336 - val_mean_absolute_error: 155.6184\n",
      "Epoch 194/2000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 15308.8867 - mean_absolute_error: 96.0894 - val_loss: 39968.7461 - val_mean_absolute_error: 155.2295\n",
      "Epoch 195/2000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 15089.5684 - mean_absolute_error: 95.6441 - val_loss: 40059.2969 - val_mean_absolute_error: 155.3594\n",
      "Epoch 196/2000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 14961.9707 - mean_absolute_error: 95.2575 - val_loss: 39461.1094 - val_mean_absolute_error: 154.0653\n",
      "Epoch 197/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 14789.5381 - mean_absolute_error: 94.5648 - val_loss: 39439.1484 - val_mean_absolute_error: 154.0402\n",
      "Epoch 198/2000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 14717.0908 - mean_absolute_error: 94.6043 - val_loss: 40607.4180 - val_mean_absolute_error: 156.0519\n",
      "Epoch 199/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 14517.8594 - mean_absolute_error: 93.8703 - val_loss: 38817.0391 - val_mean_absolute_error: 152.3198\n",
      "Epoch 200/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 14361.5586 - mean_absolute_error: 93.3249 - val_loss: 39157.6367 - val_mean_absolute_error: 152.6986\n",
      "Epoch 201/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 14214.5488 - mean_absolute_error: 92.5444 - val_loss: 38482.6562 - val_mean_absolute_error: 151.8566\n",
      "Epoch 202/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 14054.7090 - mean_absolute_error: 92.2251 - val_loss: 38494.8359 - val_mean_absolute_error: 152.1583\n",
      "Epoch 203/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 14041.2637 - mean_absolute_error: 92.2469 - val_loss: 37525.5703 - val_mean_absolute_error: 149.9222\n",
      "Epoch 204/2000\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 13784.5225 - mean_absolute_error: 91.2617 - val_loss: 37789.5859 - val_mean_absolute_error: 150.9749\n",
      "Epoch 205/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 13611.5713 - mean_absolute_error: 90.7913 - val_loss: 37345.9727 - val_mean_absolute_error: 149.5593\n",
      "Epoch 206/2000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 13503.9004 - mean_absolute_error: 90.3473 - val_loss: 37388.8984 - val_mean_absolute_error: 149.8639\n",
      "Epoch 207/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 13426.0771 - mean_absolute_error: 90.2882 - val_loss: 36501.4688 - val_mean_absolute_error: 148.2020\n",
      "Epoch 208/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 13195.6387 - mean_absolute_error: 89.2904 - val_loss: 37053.9922 - val_mean_absolute_error: 149.3772\n",
      "Epoch 209/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 13181.2422 - mean_absolute_error: 89.3706 - val_loss: 36366.7266 - val_mean_absolute_error: 147.9034\n",
      "Epoch 210/2000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 12916.4824 - mean_absolute_error: 88.1188 - val_loss: 35905.7266 - val_mean_absolute_error: 146.7590\n",
      "Epoch 211/2000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 12837.8721 - mean_absolute_error: 87.7914 - val_loss: 36423.5820 - val_mean_absolute_error: 148.0865\n",
      "Epoch 212/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 12678.7324 - mean_absolute_error: 87.4225 - val_loss: 35818.9766 - val_mean_absolute_error: 147.0735\n",
      "Epoch 213/2000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 12589.6631 - mean_absolute_error: 86.7605 - val_loss: 34824.2031 - val_mean_absolute_error: 144.7986\n",
      "Epoch 214/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 12474.0459 - mean_absolute_error: 86.2983 - val_loss: 35463.8906 - val_mean_absolute_error: 146.3489\n",
      "Epoch 215/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 12377.4307 - mean_absolute_error: 85.8675 - val_loss: 34832.4492 - val_mean_absolute_error: 145.2110\n",
      "Epoch 216/2000\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 12213.9590 - mean_absolute_error: 85.8071 - val_loss: 34967.4727 - val_mean_absolute_error: 145.2949\n",
      "Epoch 217/2000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 12174.5859 - mean_absolute_error: 85.5612 - val_loss: 35353.8477 - val_mean_absolute_error: 145.8339\n",
      "Wall time: 20.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = dnn_model.fit(\n",
    "    train_features,\n",
    "    train_label,\n",
    "    validation_split=0.2,\n",
    "    epochs=2000, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='epoch'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 279,
       "width": 374
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist[\"epoch\"] = history.epoch\n",
    "hist.plot(x=\"epoch\", y=\"loss\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 36378.3086 - mean_absolute_error: 142.3578\n",
      "{'linear_baseline': 12721548.0, 'Simple DNN': [36378.30859375, 142.35777282714844]}\n"
     ]
    }
   ],
   "source": [
    "test_results[\"Simple DNN\"] = dnn_model.evaluate(test_features, test_labels)\n",
    "\n",
    "print(test_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = {}\n",
    "test_predictions[\"dnn_model\"] = dnn_model.predict(test_features).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_model(normalizer):\n",
    "    CONV_WIDTH = 3\n",
    "\n",
    "    model = tf.keras.models.Sequential(\n",
    "        [\n",
    "            normalizer,\n",
    "            # tf.keras.layers.Lambda(lambda x: x[:, -CONV_WIDTH:, :]),\n",
    "            tf.keras.layers.Conv1D(\n",
    "                filters=64,\n",
    "                kernel_size=(CONV_WIDTH),\n",
    "                strides=1,\n",
    "                padding=\"causal\",\n",
    "                # activation=\"relu\",\n",
    "            ),\n",
    "            tf.keras.layers.Bidirectional(\n",
    "                tf.keras.layers.LSTM(128, return_sequences=False)\n",
    "            ),\n",
    "            # tf.keras.layers.Bidirectional(\n",
    "            #     tf.keras.layers.LSTM(64, return_sequences=True)),\n",
    "            tf.keras.layers.Dense(128),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Dense(1),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"mse\", optimizer=\"adam\", metrics=[tf.metrics.MeanAbsoluteError()]\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer conv1d is incompatible with the layer: : expected min_ndim=3, found ndim=2. Full shape received: (None, 58)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4020/4047217384.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mconv_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormalizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mconv_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4020/3209314166.py\u001b[0m in \u001b[0;36mconv_model\u001b[1;34m(normalizer)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mCONV_WIDTH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     model = tf.keras.models.Sequential(\n\u001b[0m\u001b[0;32m      5\u001b[0m         [\n\u001b[0;32m      6\u001b[0m             \u001b[0mnormalizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\josephdavis\\Desktop\\underminer\\env\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    528\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\josephdavis\\Desktop\\underminer\\env\\lib\\site-packages\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, layers, name)\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[0mlayers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\josephdavis\\Desktop\\underminer\\env\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    528\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\josephdavis\\Desktop\\underminer\\env\\lib\\site-packages\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    215\u001b[0m       \u001b[1;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m       \u001b[1;31m# refresh its output.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m       \u001b[0moutput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSINGLE_LAYER_OUTPUT_ERROR_MSG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\josephdavis\\Desktop\\underminer\\env\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    974\u001b[0m     \u001b[1;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 976\u001b[1;33m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[0;32m    977\u001b[0m                                                 input_list)\n\u001b[0;32m    978\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\josephdavis\\Desktop\\underminer\\env\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1112\u001b[0m         layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[0;32m   1113\u001b[0m       \u001b[1;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m       outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[0;32m   1115\u001b[0m           inputs, input_masks, args, kwargs)\n\u001b[0;32m   1116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\josephdavis\\Desktop\\underminer\\env\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[1;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[0;32m    846\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    847\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\josephdavis\\Desktop\\underminer\\env\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[1;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[0;32m    884\u001b[0m           \u001b[1;31m# overridden).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    885\u001b[0m           \u001b[1;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 886\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    887\u001b[0m           \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\josephdavis\\Desktop\\underminer\\env\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2631\u001b[0m     \u001b[1;31m# Check input assumptions set before layer building, e.g. input rank.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2632\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2633\u001b[1;33m       input_spec.assert_input_compatibility(\n\u001b[0m\u001b[0;32m   2634\u001b[0m           self.input_spec, inputs, self.name)\n\u001b[0;32m   2635\u001b[0m       \u001b[0minput_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\josephdavis\\Desktop\\underminer\\env\\lib\\site-packages\\keras\\engine\\input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    227\u001b[0m       \u001b[0mndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mndim\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m         raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\u001b[0m\u001b[0;32m    230\u001b[0m                          \u001b[0mlayer_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' is incompatible with the layer: '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m                          \u001b[1;34m': expected min_ndim='\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer conv1d is incompatible with the layer: : expected min_ndim=3, found ndim=2. Full shape received: (None, 58)"
     ]
    }
   ],
   "source": [
    "conv_model = conv_model(normalizer)\n",
    "\n",
    "conv_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "history = conv_model.fit(\n",
    "    train_features,\n",
    "    train_label,\n",
    "    validation_split=0.2,\n",
    "    epochs=2000, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results[\"conv_model\"] = dnn_model.evaluate(test_features, test_labels)\n",
    "\n",
    "print(test_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions[\"conv_model\"] = dnn_model.predict(test_features).flatten()\n",
    "\n",
    "print(test_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(labels, preds):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.scatter(x=labels.index, y=labels, color=\"r\", marker=\".\", label=\"real data\")\n",
    "    plt.scatter(x=labels.index, y=preds, color=\"b\", marker=\"X\", label=\"predictions\")\n",
    "    plt.xlabel(\"time\")\n",
    "    plt.ylabel(\"price\")\n",
    "    plt.title(\"Red is predictions, Blue is real data\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result(test_labels, test_predictions[\"dnn_model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result(test_labels, test_predictions[\"conv_model\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5b28a564d154730cebcf0a77751c471b8962279a1a72eb3cf8cb939e9c4c97bb"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('env': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
