{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "from datetime import datetime, timedelta\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import cbpro\r\n",
    "\r\n",
    "import os\r\n",
    "import shutil\r\n",
    "import urllib\r\n",
    "import zipfile\r\n",
    "from pathlib import Path\r\n",
    "import seaborn as sns\r\n",
    "\r\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\r\n",
    "os.environ[\"TF_GPU_THREAD_MODE\"] = \"gpu_private\"\r\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\r\n",
    "import tensorflow as tf\r\n",
    "\r\n",
    "tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")\r\n",
    "policy = tf.keras.mixed_precision.Policy(\"mixed_float16\")\r\n",
    "tf.keras.mixed_precision.experimental.set_policy(policy)\r\n",
    "np.set_printoptions(suppress=True)\r\n",
    "\r\n",
    "public_client = cbpro.PublicClient()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\n",
      "Your GPU may run slowly with dtype policy mixed_float16 because it does not have compute capability of at least 7.0. Your GPU:\n",
      "  NVIDIA GeForce GTX 1050, compute capability 6.1\n",
      "See https://developer.nvidia.com/cuda-gpus for a list of GPUs and their compute capabilities.\n",
      "If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "class MinerMeta(type):\r\n",
    "    def compile_historic(self, timestamp=False, write_csv=False, read_csv=False):\r\n",
    "        file = Path.cwd() / f\"{self.coin}_histdata.csv\"\r\n",
    "        if read_csv == True:\r\n",
    "            df = pd.read_csv(file, index_col=\"time\", infer_datetime_format=True)\r\n",
    "            return df\r\n",
    "        else:\r\n",
    "            start_date = datetime(2020, 1, 1)\r\n",
    "            end_date = datetime.today()\r\n",
    "            delta = timedelta(hours=300)\r\n",
    "            df = pd.DataFrame()\r\n",
    "\r\n",
    "        while start_date <= end_date:\r\n",
    "            historic = public_client.get_product_historic_rates(\r\n",
    "                f\"{self.coin}-USD\",\r\n",
    "                granularity=3600,\r\n",
    "                start=start_date,\r\n",
    "                end=start_date + delta,\r\n",
    "            )\r\n",
    "            start_date += delta\r\n",
    "            df = df.append(historic, ignore_index=True)\r\n",
    "        df.columns = [\"time\", \"low\", \"high\", \"open\", \"close\", \"volume\"]\r\n",
    "        date_time = pd.to_datetime(df[\"time\"], unit=\"s\")\r\n",
    "\r\n",
    "        timestamp_s = date_time.map(pd.Timestamp.timestamp)\r\n",
    "        day = 24 * 60 * 60\r\n",
    "        year = (365.2425) * day\r\n",
    "        df[\"Day sin\"] = np.sin(timestamp_s * (2 * np.pi / day))\r\n",
    "        df[\"Day cos\"] = np.cos(timestamp_s * (2 * np.pi / day))\r\n",
    "        df[\"Year sin\"] = np.sin(timestamp_s * (2 * np.pi / year))\r\n",
    "        df[\"Year cos\"] = np.cos(timestamp_s * (2 * np.pi / year))\r\n",
    "        df.reset_index(drop=True, inplace=True)\r\n",
    "\r\n",
    "        if timestamp is True:\r\n",
    "            pass\r\n",
    "        else:\r\n",
    "            df[\"time\"] = pd.to_datetime(df[\"time\"], unit=\"s\")\r\n",
    "\r\n",
    "        if write_csv is True:\r\n",
    "            df.to_csv(file, index=False)\r\n",
    "\r\n",
    "        return df\r\n",
    "\r\n",
    "    def get_day_stats(self):\r\n",
    "        result = getattr(self, \"day_stats\", None)\r\n",
    "        if result is None:\r\n",
    "            ticker = public_client.get_product_24hr_stats(f\"{self.coin}-USD\")\r\n",
    "            df = pd.DataFrame.from_dict(ticker, orient=\"index\")\r\n",
    "            self.day_stats = df\r\n",
    "        return df\r\n",
    "\r\n",
    "    def year_day_fft(self, col):\r\n",
    "        df = self.compile_historic()\r\n",
    "        today = datetime.today()\r\n",
    "\r\n",
    "        fft = tf.signal.rfft(df[col])\r\n",
    "        f_per_dataset = np.arange(0, len(fft))\r\n",
    "\r\n",
    "        n_samples_h = 1\r\n",
    "        hours_per_year = 24 * 365.2524\r\n",
    "        years_per_dataset = n_samples_h / (hours_per_year)\r\n",
    "\r\n",
    "        f_per_year = f_per_dataset / years_per_dataset\r\n",
    "        plt.step(f_per_year, np.abs(fft))\r\n",
    "        plt.xscale(\"log\")\r\n",
    "        plt.ylim(1000, 50000)\r\n",
    "        plt.xlim([0.1, max(plt.xlim())])\r\n",
    "        plt.xticks([1, 365.2524], labels=[\"1/Year\", \"1/day\"])\r\n",
    "        plt.xlabel(\"Frequency (log scale)\")\r\n",
    "\r\n",
    "        return plt.show()\r\n",
    "\r\n",
    "    def ttsplit_norm(self, df, split_time=0.7, feature_plot=False):\r\n",
    "        # train_df Test Split\r\n",
    "        n = len(df)\r\n",
    "        train_df = df[0 : int(n * 0.7)]\r\n",
    "        val_df = df[int(n * 0.7) : int(n * 0.9)]\r\n",
    "        test_df = df[int(n * 0.9) :]\r\n",
    "        # Normalize the Data\r\n",
    "        train_df_mean = train_df.mean()\r\n",
    "        train_df_std = train_df.std()\r\n",
    "\r\n",
    "        train_df = (train_df - train_df_mean) / train_df_std\r\n",
    "        val_df = (val_df - train_df_mean) / train_df_std\r\n",
    "        test_df = (test_df - train_df_mean) / train_df_std\r\n",
    "\r\n",
    "        # Create Feature Plot if wanted\r\n",
    "        if feature_plot is True:\r\n",
    "            df_std = (df - train_df_mean) / train_df_std\r\n",
    "            df_std = df_std.melt(var_name=\"Column\", value_name=\"Normalized\")\r\n",
    "            plt.figure(figsize=(12, 6))\r\n",
    "            ax = sns.violinplot(x=\"Column\", y=\"Normalized\", data=df_std)\r\n",
    "            ax.set_xticklabels(df.keys(), rotation=90)\r\n",
    "            ax.set_title(\"train_dfing Data Feature Dist with whole DF Mean\")\r\n",
    "\r\n",
    "            return train_df, val_df, test_df\r\n",
    "\r\n",
    "        return train_df, val_df, test_df\r\n",
    "\r\n",
    "    def __call__(self, *args, **kwargs):\r\n",
    "\r\n",
    "        cls = type.__call__(self, *args)\r\n",
    "\r\n",
    "        # setattr(cls, \"compile_historic\", self.compile_historic)\r\n",
    "        # setattr(cls, \"year_day_fft\", self.year_day_fft)\r\n",
    "        # setattr(cls, \"ttsplit_norm\", self.ttsplit_norm)\r\n",
    "        # setattr(cls, \"get_day_stats\", self.get_day_stats)\r\n",
    "        setattr(cls, \"day_stats\", self.get_day_stats())\r\n",
    "\r\n",
    "        # for key, value in historic.items():\r\n",
    "        #     setattr(cls, \"hist_\" + key, value)\r\n",
    "        # for key, value in ticker.items():\r\n",
    "        #     setattr(cls, \"tick_\" + key, value)\r\n",
    "\r\n",
    "        return cls\r\n",
    "\r\n",
    "\r\n",
    "class eth(metaclass=MinerMeta):\r\n",
    "    coin = \"eth\"\r\n",
    "\r\n",
    "\r\n",
    "df = eth.compile_historic(read_csv=True)\r\n",
    "train_df, val_df, test_df = eth.ttsplit_norm(df)\r\n",
    "\r\n",
    "\r\n",
    "class WindowGenerator:\r\n",
    "    def __init__(\r\n",
    "        self,\r\n",
    "        input_width,\r\n",
    "        label_width,\r\n",
    "        shift,\r\n",
    "        train_df=train_df,\r\n",
    "        val_df=val_df,\r\n",
    "        test_df=test_df,\r\n",
    "        label_columns=None,\r\n",
    "    ):\r\n",
    "        # Store the raw data.\r\n",
    "        self.train_df = train_df\r\n",
    "        self.val_df = val_df\r\n",
    "        self.test_df = test_df\r\n",
    "\r\n",
    "        # Work out the label column indices.\r\n",
    "        self.label_columns = label_columns\r\n",
    "        if label_columns is not None:\r\n",
    "            self.label_columns_indices = {\r\n",
    "                name: i for i, name in enumerate(label_columns)\r\n",
    "            }\r\n",
    "        self.column_indices = {name: i for i, name in enumerate(train_df.columns)}\r\n",
    "\r\n",
    "        # Work out the window parameters.\r\n",
    "        self.input_width = input_width\r\n",
    "        self.label_width = label_width\r\n",
    "        self.shift = shift\r\n",
    "\r\n",
    "        self.total_window_size = input_width + shift\r\n",
    "\r\n",
    "        self.input_slice = slice(0, input_width)\r\n",
    "        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\r\n",
    "\r\n",
    "        self.label_start = self.total_window_size - self.label_width\r\n",
    "        self.labels_slice = slice(self.label_start, None)\r\n",
    "        self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\r\n",
    "\r\n",
    "    def split_window(self, features):\r\n",
    "        inputs = features[:, self.input_slice, :]\r\n",
    "        labels = features[:, self.labels_slice, :]\r\n",
    "        if self.label_columns is not None:\r\n",
    "            labels = tf.stack(\r\n",
    "                [\r\n",
    "                    labels[:, :, self.column_indices[name]]\r\n",
    "                    for name in self.label_columns\r\n",
    "                ],\r\n",
    "                axis=-1,\r\n",
    "            )\r\n",
    "\r\n",
    "        # Slicing doesn't preserve static shape information, so set the shapes\r\n",
    "        # manually. This way the `tf.data.Datasets` are easier to inspect.\r\n",
    "        inputs.set_shape([None, self.input_width, None])\r\n",
    "        labels.set_shape([None, self.label_width, None])\r\n",
    "\r\n",
    "        return inputs, labels\r\n",
    "\r\n",
    "    def make_ds(self, data):\r\n",
    "        data = np.array(data, dtype=np.float32)\r\n",
    "        ds = tf.keras.preprocessing.timeseries_dataset_from_array(\r\n",
    "            data=data,\r\n",
    "            targets=None,\r\n",
    "            sequence_length=self.total_window_size,\r\n",
    "            sequence_stride=1,\r\n",
    "            shuffle=True,\r\n",
    "            batch_size=32,\r\n",
    "        )\r\n",
    "\r\n",
    "        ds = ds.map(self.split_window)\r\n",
    "\r\n",
    "        return ds\r\n",
    "\r\n",
    "    def __repr__(self):\r\n",
    "        return \"\\n\".join(\r\n",
    "            [\r\n",
    "                f\"Total window size: {self.total_window_size}\",\r\n",
    "                f\"Input indices: {self.input_indices}\",\r\n",
    "                f\"Label indices: {self.label_indices}\",\r\n",
    "                f\"Label column name(s): {self.label_columns}\",\r\n",
    "            ]\r\n",
    "        )\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# df = eth.get_day_stats()\r\n",
    "# df.head()\r\n",
    "\r\n",
    "eth.day_stats"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "type object 'eth' has no attribute 'day_stats'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9540/1538772369.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# df.head()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0meth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mday_stats\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'eth' has no attribute 'day_stats'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "w1 = WindowGenerator(\r\n",
    "    input_width=24,\r\n",
    "    label_width=1,\r\n",
    "    shift=24,\r\n",
    "    label_columns=[\"close\"],\r\n",
    "    train_df=train_df,\r\n",
    "    test_df=test_df,\r\n",
    "    val_df=val_df,\r\n",
    ")\r\n",
    "w1\r\n",
    "w2 = WindowGenerator(\r\n",
    "    input_width=6,\r\n",
    "    label_width=1,\r\n",
    "    shift=1,\r\n",
    "    label_columns=[\"close\"],\r\n",
    "    train_df=train_df,\r\n",
    "    test_df=test_df,\r\n",
    "    val_df=val_df,\r\n",
    ")\r\n",
    "w2\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Stack three slices, the length of the total window.\r\n",
    "example_window = tf.stack(\r\n",
    "    [\r\n",
    "        np.array(train_df[: w2.total_window_size]),\r\n",
    "        np.array(train_df[100 : 100 + w2.total_window_size]),\r\n",
    "        np.array(train_df[200 : 200 + w2.total_window_size]),\r\n",
    "    ]\r\n",
    ")\r\n",
    "\r\n",
    "example_inputs, example_labels = w2.split_window(example_window)\r\n",
    "\r\n",
    "print(\"All shapes are: (batch, time, features)\")\r\n",
    "print(f\"Window shape: {example_window.shape}\")\r\n",
    "print(f\"Inputs shape: {example_inputs.shape}\")\r\n",
    "print(f\"Labels shape: {example_labels.shape}\")\r\n",
    "\r\n",
    "w2.example = example_inputs, example_labels\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def plot(self, model=None, plot_col=\"close\", max_subplots=3):\r\n",
    "    inputs, labels = self.example\r\n",
    "    plt.figure(figsize=(12, 8))\r\n",
    "    plot_col_index = self.column_indices[plot_col]\r\n",
    "    max_n = min(max_subplots, len(inputs))\r\n",
    "    for n in range(max_n):\r\n",
    "        plt.subplot(max_n, 1, n + 1)\r\n",
    "        plt.ylabel(f\"{plot_col} [normed]\")\r\n",
    "        plt.plot(\r\n",
    "            self.input_indices,\r\n",
    "            inputs[n, :, plot_col_index],\r\n",
    "            label=\"Inputs\",\r\n",
    "            marker=\".\",\r\n",
    "            zorder=-10,\r\n",
    "        )\r\n",
    "\r\n",
    "        if self.label_columns:\r\n",
    "            label_col_index = self.label_columns_indices.get(plot_col, None)\r\n",
    "        else:\r\n",
    "            label_col_index = plot_col_index\r\n",
    "\r\n",
    "        if label_col_index is None:\r\n",
    "            continue\r\n",
    "\r\n",
    "        plt.scatter(\r\n",
    "            self.label_indices,\r\n",
    "            labels[n, :, label_col_index],\r\n",
    "            edgecolors=\"k\",\r\n",
    "            label=\"Labels\",\r\n",
    "            c=\"#2ca02c\",\r\n",
    "            s=64,\r\n",
    "        )\r\n",
    "        if model is not None:\r\n",
    "            predictions = model(inputs)\r\n",
    "            plt.scatter(\r\n",
    "                self.label_indices,\r\n",
    "                predictions[n, :, label_col_index],\r\n",
    "                marker=\"X\",\r\n",
    "                edgecolors=\"k\",\r\n",
    "                label=\"Predictions\",\r\n",
    "                c=\"#ff7f0e\",\r\n",
    "                s=64,\r\n",
    "            )\r\n",
    "\r\n",
    "        if n == 0:\r\n",
    "            plt.legend()\r\n",
    "\r\n",
    "    plt.xlabel(\"Time [h]\")\r\n",
    "\r\n",
    "\r\n",
    "WindowGenerator.plot = plot\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "w2.plot(plot_col=\"volume\")\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "@property\r\n",
    "def train(self):\r\n",
    "  return self.make_ds(self.train_df)\r\n",
    "\r\n",
    "@property\r\n",
    "def val(self):\r\n",
    "  return self.make_ds(self.val_df)\r\n",
    "\r\n",
    "@property\r\n",
    "def test(self):\r\n",
    "  return self.make_ds(self.test_df)\r\n",
    "\r\n",
    "@property\r\n",
    "def example(self):\r\n",
    "  \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\r\n",
    "  result = getattr(self, '_example', None)\r\n",
    "  if result is None:\r\n",
    "    # No example batch was found, so get one from the `.train` dataset\r\n",
    "    result = next(iter(self.train))\r\n",
    "    # And cache it for next time\r\n",
    "    self._example = result\r\n",
    "  return result\r\n",
    "\r\n",
    "WindowGenerator.train = train\r\n",
    "WindowGenerator.val = val\r\n",
    "WindowGenerator.test = test\r\n",
    "WindowGenerator.example = example"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Each element is an (inputs, label) pair.\r\n",
    "w2.train.element_spec"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "single_step_window = WindowGenerator(\r\n",
    "    input_width=1, label_width=1, shift=1, label_columns=[\"close\"]\r\n",
    ")\r\n",
    "single_step_window\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for example_inputs, example_labels in single_step_window.train.take(1):\r\n",
    "  print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\r\n",
    "  print(f'Labels shape (batch, time, features): {example_labels.shape}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class Baseline(tf.keras.Model):\r\n",
    "    def __init__(self, label_index=None):\r\n",
    "        super().__init__()\r\n",
    "        self.label_index = label_index\r\n",
    "\r\n",
    "    def call(self, inputs):\r\n",
    "        if self.label_index is None:\r\n",
    "            return inputs\r\n",
    "        result = inputs[:, :, self.label_index]\r\n",
    "        return result[:, :, tf.newaxis]\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "column_indices = {name: i for i, name in enumerate(df.columns)}\r\n",
    "\r\n",
    "baseline = Baseline(label_index=column_indices[\"close\"])\r\n",
    "\r\n",
    "baseline.compile(\r\n",
    "    loss=tf.losses.MeanSquaredError(), metrics=[tf.metrics.MeanAbsoluteError()]\r\n",
    ")\r\n",
    "\r\n",
    "val_performance = {}\r\n",
    "performance = {}\r\n",
    "val_performance[\"Baseline\"] = baseline.evaluate(single_step_window.val)\r\n",
    "performance[\"Baseline\"] = baseline.evaluate(single_step_window.test, verbose=0)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "wide_window = WindowGenerator(\r\n",
    "    input_width=24, label_width=24, shift=1, label_columns=[\"close\"]\r\n",
    ")\r\n",
    "\r\n",
    "wide_window\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "wide_window.plot(baseline)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "linear = tf.keras.Sequential([tf.keras.layers.Dense(units=1)])\r\n",
    "\r\n",
    "print(\"Input shape:\", single_step_window.example[0].shape)\r\n",
    "print(\"Output shape:\", linear(single_step_window.example[0]).shape)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "MAX_EPOCHS = 20\r\n",
    "\r\n",
    "\r\n",
    "def compile_and_fit(model, window, patience=2):\r\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\r\n",
    "        monitor=\"val_loss\", patience=patience, mode=\"min\"\r\n",
    "    )\r\n",
    "\r\n",
    "    model.compile(\r\n",
    "        loss=tf.losses.MeanSquaredError(),\r\n",
    "        optimizer=tf.optimizers.Adam(),\r\n",
    "        metrics=[tf.metrics.MeanAbsoluteError()],\r\n",
    "    )\r\n",
    "\r\n",
    "    history = model.fit(\r\n",
    "        window.train,\r\n",
    "        epochs=MAX_EPOCHS,\r\n",
    "        validation_data=window.val,\r\n",
    "        callbacks=[early_stopping],\r\n",
    "    )\r\n",
    "    return history\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "history = compile_and_fit(linear, single_step_window)\r\n",
    "\r\n",
    "val_performance[\"Linear\"] = linear.evaluate(single_step_window.val)\r\n",
    "performance[\"Linear\"] = linear.evaluate(single_step_window.test, verbose=0)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('Input shape:', wide_window.example[0].shape)\r\n",
    "print('Output shape:', baseline(wide_window.example[0]).shape)\r\n",
    "wide_window.plot(linear)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.bar(x = range(len(train_df.columns)),\r\n",
    "        height=linear.layers[0].kernel[:,0].numpy())\r\n",
    "axis = plt.gca()\r\n",
    "axis.set_xticks(range(len(train_df.columns)))\r\n",
    "_ = axis.set_xticklabels(train_df.columns, rotation=90)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.0",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.0 64-bit ('env': venv)"
  },
  "interpreter": {
   "hash": "5b28a564d154730cebcf0a77751c471b8962279a1a72eb3cf8cb939e9c4c97bb"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}